[toc]

# 四. 指令系统

> 即便是对于同一台计算机，所支持的指令类别也是千差万别的。各种各样的指令应该如何设定是这一章重点探讨的内容。

指令的定义(机器指令)：是指示计算机执行某种操作的命令，是计算机运行的最小功能单位。而一台计算机的所有指令的集合构成该机的指令系统，也称为指令集。

注：一台计算机只能执行自己指令系统中的指令，不能执行其他系统的指令。如：x86架构、ARM架构。

## 1. 指令格式

一条指令就是机器语言的一个语句，它是一组有意义的二进制代码。一条指令格式通常要包括操作码字段和地址码字段两部分：

1. 操作码(OP)：想要CPU干什么。如：停机中断、求反求补、加减乘除。

2. 地址码(A)：指明这个操作对谁进行。如：不需要操作对象(停机指令)、需要操作对象(求反求补)、需要两个操作对象(运算)。

由于各种指令所需要的操作不一样，所以地址码的数目也有可能会出现变化。所以一条指令可能包含$0$个、$1$个、$2$个、$3$个、$4$个地址码根据地址码数目不同，可以将指令分为零地址指令、一地址指令、二地址指令等。

- 零地址指令(OP)

  零地址指令只需要指明操作码即可。通常两种情况需要用到零地址指令：

  1. 不需要操作数，如空操作、停机、关中断等指令。

  2. 堆栈计算机，两个操作数隐含存放在栈顶和次栈顶，计算结果压回栈顶。

     这种情况并不是不需要操作数，而是操作数会固定隐含在特定的位置。

     如：后缀表达式，堆栈型计算机在进行算术表达式运算的时候是基于后缀表达式实现的，在计算过程中操作数是隐含在栈中的而不是在指令中。

- 一地址指令(OP$+A_1$)

  需要指明操作码和一个操作对象。通常两种情况会用到一地址指令：

  1. 只需要单操作数，如加$1$、减$1$、取反、求补等
     指令含义：CPU首先会从$A_1$所指向的主存单元当中取出相应的数据，然后对这个数据进行对应的$OP$操作。得到运算结果后再把运算结果放回$A_1$所指向的主存单元。即$OP(A1)\rightarrow A_1$

     所以完成这条指令需要$3$次访存：取指令$\rightarrow$读$A_1\rightarrow$写$A_1$

  2. 需要两个操作数，但其中一个操作数隐含在某个寄存器(如隐含在ACC中)。
     指令含义：将ACC累加寄存器中存放的数据，还有$A_1$所指明地址当中存放的数据进行相应的$OP$操作运算。然后把运算的结果再存放入ACC累加寄存器中。即$(ACC)OP(A_1)\rightarrow ACC$

     所以完成这一条指令需要$2$次访存：取指令$\rightarrow$读$A_1$

  注意：上面$A_1$指某个主存地址，$(A_1)$表示$A_1$所指向的地址中的内容。这里的$A_1$可以类比C语言的指针，$(A_1)$相当于指针所指位置的内容。

- 二地址指令(OP$+A_1$(目的操作数)$+A_2$(源操作数))

  常用于需要两个操作数的算术运算、逻辑运算相关指令。

  指令含义：$A_1$和$A_2$这两个地址码会分别指明要运算的操作数。这两个数进行$OP$操作后，运算的记过会存回$A_1$。即$(A_1)op(A_2)\rightarrow A_1$。

  完成这一次指令需要$4$次访存：取出指令$\rightarrow$读取$A_1\rightarrow$读取$A_2\rightarrow$写$A_1$。

- 三地址指令

  常用于需要两个操作数的算术运算、逻辑运算相关指令。

  指令含义：$A_1$和$A_2$这两个地址码会分别指明要运算的操作数。这两个数进行$OP$操作后，运算的记过会存回$A_3$。即$(A_1)op(A_2)\rightarrow A_3$。

  完成这一次指令需要$4$次访存：取出指令$\rightarrow$读取$A_1\rightarrow$读取$A_2\rightarrow$写$A_3$。

- 四地址指令

  指令含义：$(A_1)op(A_2)\rightarrow A_3$，$A_4=$下一条将要执行指令的地址。

  完成这一次指令需要$4$次访存：取出指令$\rightarrow$读取$A_1\rightarrow$读取$A_2\rightarrow$写$A_3$。

  正常情况下在取指令之后指针$PC+1$，即指向下一条指令，但使用四地址指令后，$PC$的值修改为$A_4$所指的地址。

对于$n$位地址码的直接寻址范围$=2^n$，若指令总长度固定不变，则地址码数量越多，寻址能力越差。

还可以对指令进行其他分类，先来看以下概念：

> 指令字长：一条指令的总长度(可能会变)
>
> 机器字长：与CPU有关，CPU进行一次整数运算所能处理的二进制数据的位数(通常和ALU直接相关)
>
> 存储字长：与主存有关，一个存储单元中的二进制代码位数(通常和MDR位数相同)
>
> 可能会见到半字长指令、单字长指令、双字长指令这些术语。这指的是指令长度是机器字长的多少倍。通常情况下指令字长会影响取指令所需时间。如：机器字长$=$存储字长$=16bit$，则取一条双字长指令($32bit$)需要两次访存。

所以可以对指令按照长度进行分类：

- 有的系统中所有指令的长度都相等，这称作定长指令字结构。

  对于一个定长操作系统，如果操作码是$n$位，意味着这个系统最多支持$2^n$这么多条指令。这种控制系统的译码电路设计简单，但灵活性较低。

- 而有的系统中各种指令的长度不等，这称作变长指令字结构。

  控制器译码电路设计复杂，但灵活性高。

按照操作类型分类：

- 数据传送

  LOAD作用：把存储器中的数据放到寄存器中

  STORE作用：把寄存器中的数据放到存储器中

- 算术逻辑操作

  算术：加减乘除、增$1$、减$1$、求补、浮点运算、十进制运算

  逻辑：与、或、非、异或、位操作、位测试、位清除、位求反

- 移位操作

  算术移位、逻辑移位、循环移位(带进位和不带进位)

- 转移操作

  无条件转义(JMP)

  有条件转义：JZ(结果为$0$)、JO(结果溢出)、JC(结果有进位)

  调用和返回：CALL和RETURN

  陷阱(Trap)与陷阱指令

- 输入输出操作

  CPU寄存器和IO端口之间的数据传送(端口即IO接口中的寄存器)

## 2. 扩展操作码

定长指令字结构$+$可变长操作码$=$扩展操作码指令格式。采用这种操作码意味着对于不同地址数的指令使用不同长度的操作码。

举例：如果指令字长为$16$位，每个地址码占$4$位，对于三地址指令：指令字长的前$4$位为操作码字段$OP$，另外$12$位是三个$4$位长的地址字段$A_1,A_2,A_3$。

<img src="https://image.sybblogs.fun/img-common/202401191756731.png" alt="三地址指令" style="zoom:33%;" />

前$4$位基本操作码用于三地址指令，则可以有$2^4=16$条。但至少要将$1111$留作扩展操作码使用，即三地址指令最多有$15$条。

<img src="https://image.sybblogs.fun/img-common/202401191759416.png" alt="扩展操作码" style="zoom:33%;" />

这么做，CPU可以在取得一条$16$位指令时，如果满足开头$4$位全$1$，并且$5\sim8$位不是全$1$，就可以确定这是一条二地址指令。

同样，如果满足开头$4$位全$1$，并且$5\sim8$位也是全$1$，就可以确定这是一条一地址指令。

接着，如果前$12$位都是$1$，就可以确定这是一条零地址指令。

<img src="https://image.sybblogs.fun/img-common/202401191804127.png" alt="扩展操作码方法" style="zoom:33%;" />

在设计扩展操作码指令格式时，必须注意以下两点：

1. 不允许短码是长码的前缀，即短操作码不能与长操作码的前面部分的代码相同。
2. 各指令的操作码一定不能重复。

通常情况下，对使用频率较高的指令，分配较短的操作码；对使用频率较低的指令，分配较长的操作码。尽可能减少指令译码和分析的时间。如：对于二地址指令操作码是$8$位，三地址指令操作码是$4$位，二地址操作码前四位全$1$，所以三地址指令操作码不能出现全$1$。

例题：设指令字长固定为$16$位，试设计一套指令系统满足：

| 要求                 | 格式                          | 起始指令位$1$  | 指令位$2/$地址位 | 指令位$3/$地址位 | 指令位$4/$地址位 |
| -------------------- | ----------------------------- | -------------- | ---------------- | ---------------- | ---------------- |
| a.有$15$条三地址指令 |                               | $0000\sim1110$ | $A_1$            | $A_2$            | $A_3$            |
| b.有$12$条二地址指令 | $1111\cdots$                  | $1111$         | $0000\sim1011$   | $A_1$            | $A_2$            |
| c.有$62$条一地址指令 | $1111\quad11\cdots$           | $1111$         | $00\sim11$       | $0000\sim1101$   | $A_1$            |
| d.有$32$条零地址指令 | $1111\quad1111\quad111\cdots$ | $1111$         | $1111$           | $1110\sim1111$   | $0000\sim1111$   |

> 对于有$15$条三地址指令：其只要满足前四位不大于$1110$即可。
>
> 有$12$条二地址指令：前四位固定，并且要留八位给两个地址，所以只有$4$位可以当作指令，$0000\sim1011$可以代表$12$个不同二进制数即指令。
>
> 有$62$条一地址指令：前六位要区分指令位，所以全$1$，另外还要留$4$位做地址位，只剩$6$位可以用于做分配的指令位。$000000\sim111101$就可以表示$62$不同二进制位，即指令。
>
> 有$32$条零地址指令：前$11$位区分指令位，所以全$1$，没有地址位，所以剩下的$5$位可以用来表示指令位。$00000\sim11111$可以表示正好可以表示$32$中状态，即指令。

这样设计好后，CPU可以根据开头几位确定是哪种地址指令。如：前$11$位全$1$，就表示这是一条零地址指令。

上面设计方法可以得出一个结论：设地址长度为$n$，上一层留出$m$种状态，下一层可扩展出$m\times2^n$种状态。上面设计中地址长度是$4$位，对于第一层三地址指令设计，共有$2^4=16$种状态，留出一种状态让下一层使用。第二层设计二地址指令，由于上一层留出一种状态，所以这一层状态共有$1\times2^4=16$种，这里只用$12$种状态，留出四种状态给下一层。第三层一地址指令设计共有$4\times2^4=64$种状态，这里只用$62$种状态，留出两种状态给下一层。第四层设计零地址指令共有$2\times2^4=32$种。

<img src="https://image.sybblogs.fun/img-common/202401191909114.png" alt="扩展码设计" style="zoom:33%;" />

## 3. 指令寻址

指令寻址：下一条欲执行指令的指令地址。这个地址始终由程序计数器PC给出。并且有顺序寻址和跳跃寻址两种方式。

### 3.1 顺序寻址

CPU可以通过顺序寻址和跳跃寻址方式，确定下一条指令的存放地址。

程序计数器$PC$可以给出下一条欲被执行的指令地址。

<img src="https://image.sybblogs.fun/img-common/202401191920685.png" alt="顺序寻址" style="zoom:33%;" />

上图给出一个系统，该系统采用定长指令字结构，指令字长$=$存储字长$16Bit=2B$。且主存按字编址。此时$PC$初始值指向$0$，当指令$0$地址内操作执行完成后，$PC+1$。继续执行后面，依次按顺序执行。

<img src="https://image.sybblogs.fun/img-common/202401191930485.png" alt="PC+1" style="zoom:33%;" />

但有的系统会采用按字节编址方式，即每条指令会占两个地址。此时$PC+2$。

当然有的系统也会采用变长的指令字结构：

<img src="https://image.sybblogs.fun/img-common/202401191931002.png" alt="变长指令字结构寻址" style="zoom:33%;" />

如上图，颜色相同的是一个指令。PC会先指向第一个指令地址$0$，由于CPU无法确定当前这条指令占多少个存储字，CPU会先读入第一个操作字内容，由于操作码包含在第一个字中，所以CPU可以根据操作码来判断出这条地址到底是几地址的指令。这样就可以确定这条指令占多少个字节。上面第一个行指令占$4$个字节，即两行，运行完之后PC会$+n$，即$PC+4$，指向$4$指令地址。

<img src="https://image.sybblogs.fun/img-common/202401191936176.png" alt="变长指令字结构寻址1" style="zoom:33%;" />

以上都是按照顺序寻址方式，这种方式$PC+n$就可以确定下条指令位置。这里$n$受定长$/$变长指令字结构、按字$/$字节编址等的影响。

### 3.2 跳跃寻址

给出一个系统，该系统采用定长指令字结构，指令字长$=$存储字长$16Bit=2B$。且主存按字编址。

<img src="https://image.sybblogs.fun/img-common/202401191920685.png" alt="顺序寻址" style="zoom:33%;" />

PC初始值指向$0$指令地址，每完成一个指令都会使$PC+1$。直到$PC$指向指令地址$3$，此时当执行这条指令时，同样$PC+1$会先执行。之后CPU知道$JMP$是一条无条件转移语句类似与C语言的goto语句。所以会把$PC$中的内容改为$7$，即指向$7$指令地址。

<img src="https://image.sybblogs.fun/img-common/202401191942353.png" alt="跳跃寻址" style="zoom:33%;" />

这种通过转移类指令，改变PC的值，即改变程序执行流的方式称为跳跃寻址。

## 4. 数据寻址

数据寻址：确认本条指令码的地址码指明的真实地址。

指令是操作码$+$地址码。数据寻址就是地址码的解析。这个解析方式有十种：隐含寻址、立即寻址、直接寻址、间接寻址、寄存器寻址、寄存器间接寻址、相对寻址、基址寻址、变址寻址、堆栈寻址。由于有十种寻址所以只需要$4$位二进制标识即可。

增加$4$个比特位后新的指令由操作码$+$寻址特征$+$形式地址构成。

<img src="https://image.sybblogs.fun/img-common/202401201307474.png" alt="新的指令码" style="zoom:33%;" />

根据中间寻址特性来确认这个形式地址应该用十种方法哪一种来解析它，得到真正的真实地址，这个真实地址叫有效地址(EA)。

上面是对于一地址指令，二地址指令如下：

<img src="https://image.sybblogs.fun/img-common/202401201311567.png" alt="新的二地址指令" style="zoom:33%;" />

在接下来的介绍中，为了方便，假设指令字长$=$机器字长$=$存储字长。并且假设最终想要得到的操作数为$3$。

### 4.1 直接寻址

直接寻址：指令字中的形式地址$A$就是操作数的真实地址$EA$，即$EA=A$。

<img src="https://image.sybblogs.fun/img-common/202401201315935.png" alt="直接寻址" style="zoom:33%;" />

CPU根据指令的寻址特征知道这是直接寻址，会根据形式地址$A$直接找到对应主存位置中的数据。

这种寻址访存次数：取指令访存$1$次，执行指令访存$1$次，暂不考虑存结果共访存$2$次。

直接寻址优点：简单，指令执行阶段仅访问一次主存，不需专门计算操作数的地址。

直接寻址缺点：$A$的位数决定了该指令操作数的寻址范围。当操作数的地址发生改变时，不易修改。

### 4.2 间接寻址方式

间接寻址：指令的地址字段给出的形式地址不是操作数的真正地址，而是操作数有效地址所在的存储单元的地址，也就是操作数地址的地址，即$EA=(A)$。

<img src="https://image.sybblogs.fun/img-common/202401201322362.png" alt="间接寻址" style="zoom:33%;" />

CPU根据寻址特征知道这是间接寻址，根据形式地址$A$，找到主存对应的位置$A$，而$A$中保存的就是数据所在主存中的有效地址$EA$。即形式地址$A$，指向主存中的某一位置，这个位置中的地址指向就是$EA$。

寻址访存次数：取指令访存$1$次，执行指令访存$2$次，暂不考虑存结果共访存$3$次。

同时还有两次间接寻址：

<img src="https://image.sybblogs.fun/img-common/202401201328899.png" alt="两次间接寻址" style="zoom:33%;" />

根据形式地址$A$找到主存中地址$A_1$，$A_1$前面$1$标明这个地址不是有效地址$EA$，其指向的地址是$EA$，$EA$前面的$0$表示这个地址指向的位置就是真是数据的位置。

间接寻址优势：可扩大寻址范围(有效地址$EA$的位数大于形式地址$A$的位数，所以寻址范围由主存中的有效地址$EA$决定)。并且便于编制程序(用间接寻址可以方便地完成子程序返回)。

缺点：指令在执行阶段要多次访存(一次间址需两次访存，多次寻址需根据存储字的最高位确定几次访存)，导致寻址效率变低。

### 4.3 寄存器寻址

寄存器寻址：在指令字中直接给出操作数所在的寄存器编号，即$EA=R_i$，其操作数在由$R_i$所指的寄存器内。

<img src="https://image.sybblogs.fun/img-common/202401201357628.png" alt="寄存器寻址" style="zoom:33%;" />

CPU根据寻址特征知道这是寄存器寻址，所以形式地址不是指向主存中的位置，而是寄存器中的位置。CPU内部会有很多通用寄存器，根据形式地址$R_i$可以找到寄存器编号。

寻址访存次数：取指令访存$1$次，执行指令访存$0$次，暂不考虑存结果共访存$1$次。

寄存器寻址优点：指令在执行阶段不访问主存，只访问寄存器，由于CPU中寄存器不会太多，所以指令字短且执行速度快，支持向量$/$矩阵运算。

寄存器寻址缺点：寄存器价格昂贵，计算机中寄存器个数有限。

### 4.4 寄存器间接寻址

寄存器间接寻址：寄存器$R$中给出的不是一个操作数，而是操作数所在主存单元的地址，即$EA=(R_i)$。

<img src="https://image.sybblogs.fun/img-common/202401201404322.png" alt="寄存器间接寻址" style="zoom:33%;" />

CPU根据寻址特征知道这是寄存器间接寻址，根据形式地址指明的寄存器编号，而这个寄存器编号中的内容才是有效地址$EA$，其指向主存中的某一位置。

寻址访存次数：取指令访存$1$次，执行指令访存$1$次，暂不考虑存结果共访存$2$次。

寄存器间接寻址特点：与一般间接寻址相比速度更快，但指令的执行阶段需要访问主存(因为操作数在主存中)。

### 4.5 隐含寻址

隐含寻址：不是明显地给出操作数的地址，而是在指令中隐含着操作数的地址。

<img src="https://image.sybblogs.fun/img-common/202401201413877.png" alt="隐含寻址" style="zoom:33%;" />

有的地址显示给出的地址只是指明，其中一个操作数的位置，而另一个操作数会默认在ACC累加寄存器中，但是这个操作数并没有在指令中显示的给出，所以这是隐含寻址。

优点：有利于缩短指令字长。

缺点：需增加存储操作数或隐含地址的硬件。

### 4.6 立即寻址

立即寻址：形式地址$A$就是操作数本身，又称为立即数，一般采用补码形 式。寻址特征位$\#$表示立即寻址特征。

寻址访存次数：取指令访存$1$次，执行指令访存$0$次，暂不考虑存结果共访存$1$次。

立即寻址优点：指令执行阶段不访问主存，指令执行时间最短。

立即寻址缺点：$A$的位数限制了立即数的范围。如$A$的位数为$n$，且立即数采用补码时，可表示的数据范围为$-2^{n-1}\sim2^{n-1}-1$。

六种寻址方式总结：

<img src="https://image.sybblogs.fun/img-common/202401201424675.png" alt="六种寻址方式总结" style="zoom:33%;" />

### 4.7 偏移寻址

以某个地址作为起点，形式地址视为偏移量。偏移寻址有三种：相对寻址、基址寻址和变址寻址。

<img src="https://image.sybblogs.fun/img-common/202401201427180.png" alt="偏移寻址" style="zoom:33%;" />

上图最左边$JMP$会让程序跳转到第$7$行。中间的$JMP$指令会让程序以当前程序的起始位置$100$，往后偏移$7$位，即$107$。最右边$JMP$指令，会以当前程序执行行的位置为起始位置$103$，往后偏移$3$位到$107$。

这三种偏移方式区别在于偏移的起点不一样。

1. 基址寻址：以程序的起始存放地址作为"起点"。

2. 变址寻址：程序员自己决定从哪里作为"起点"。

3. 相对寻址：以程序计数器PC所指地址作为"起点"。

#### 基址寻址

基址寻址：将CPU中基址寄存器(BR)的内容加上指令格式中的形式地址$A$，而形成操作数的有效地址，即$EA=(BR)+A$。

有的计算机会带有基址寄存器：

<img src="https://image.sybblogs.fun/img-common/202401201437093.png" alt="基址寻址" style="zoom:33%;" />

采用这种基址寄存器，则指令中还有形式地址$A$，基址寄存器BR会指向当前程序的起始位置。最终的有效位置，只需要用基址寄存器中存放的地址加上形式地址$A$(偏移量)就可以得到最终的有效地址$EA$。即将$A$和$BR$中存放的地址送往算术逻辑单元$ALU$进行一个加法运算就可以得到$EA$

注：可对比操作系统OS课中的"重定位寄存器"就是"基址寄存器"。

而有的计算机内部不会有专门的基地址寄存器，而是使用某个通用寄存器。

<img src="https://image.sybblogs.fun/img-common/202401201444999.png" alt="基址寻址(无基址寄存器)" style="zoom:33%;" />

CPU根据寻址特征知道这是基址寻址，另外还需要花几个比特位指明基地址存放在通用寄存器哪个位置。上图指明存放在通用寄存器$R_0$位置。之后和之前一样，取出通用寄存器$R_0$地址和$A$地址送到$ALU$算术逻辑单元种进行相加得到$EA$。

其中$R_0$要根据通用寄存器个数判断占多少位。如果通用寄存器有$8$个存储空间，那么$R_0$就需要$3$位，即可。因为$2^3=8$能表示所有情况。

优点：可扩大寻址范围(基址寄存器的位数大于形式地址A的位数)；用户不必考虑自己的程序存于主存的哪一空间区域，故有利于多道程序设计，以及可用于编制浮动程序便于程序"浮动"，可以从内存当中任何一个地址作为程序起始地址，方便实现多道程序并发运行。

注：基址寄存器是**面向操作系统**的，其内容由**操作系统或管理程序**确定。在程序执行过程中，基址寄存器的内容不变(作为基地址)，形式地址可变(作为偏移量)。当采用通用寄存器作为基址寄存器时，可由用户使用汇编语言决定哪个寄存器作为基址寄存器，但其内容仍由操作系统确定。

#### 变址寻址

变址寻址：有效地址$EA$等于指令字中的形式地址$A$与变址寄存器$IX$的内容相加之和，即$EA= (IX)+A$，其中$IX$可为变址寄存器(专用)，也可用通用寄存器作为变址寄存器

如果计算机中有变址寄存器$IX$：

<img src="https://image.sybblogs.fun/img-common/202401201503453.png" alt="变址寄存器IX" style="zoom:33%;" />

采用这种基址寄存器，则指令中还有形式地址$A$，变址寄存器$IX$会指向当前程序的起始位置。最终的有效位置，只需要用变址寄存器中存放的地址加上形式地址$A$(偏移量)就可以得到最终的有效地址$EA$。即将$A$和$IX$中存放的地址送往算术逻辑单元$ALU$进行一个加法运算就可以得到$EA$

可以发现变址寻址和基址寻址方式一样。他们的区别在于，变址寄存器是面向用户的，在程序执行过程中，变址寄存器的内容可由用户改变。另外$IX$作为偏移量，形式地址$A$不变作为基地址，和基址寻址相反。

变址寻址原理：先给出一段程序

~~~c
for(int i=0; i<10; i++){
    sum+=a[i];
}
~~~

该程序存储结构如下：

<img src="https://image.sybblogs.fun/img-common/202401201516199.png" alt="变址寻址原理" style="zoom:33%;" />

- 首先第一条指令，取数指令，地址码前面$\#$代表这是一个立即数，可以直接运算，将这个立即数$0$放入ACC中
- 第二行指令，取数指令，通用将$0$放入$IX$中。
- 第三行指令，加法指令，这个指令采用了变址寻址。也就意味着$EA=(IX)+A$，这里的$A=7$，所以执行$(ACC)+(7+IX)\rightarrow ACC$，就是将$IX=0$加上形式地址$A=7$的结果就是有效地址，这里指向$7$，即$a[0]$。ACC中当前存放的是$0$，所以$a[0]+ACC$运算结果放入ACC中即可。对应代码`sum+=a[i]`。
- 第四行，加法操作，让变址寄存器$IX+1=1$，再放入$IX$中。对应代码`i++`。
- 第五行，比较操作，$10-(IX)$。
- 第六行，跳转操作，如果$10-(IX)>0$，则将程序跳转$2$主存地址，再次循环。对于代码`i<10`
- 跳转回第二行，$A=7,ACC=1$，则$7+(ACC)=8$，在与$ACC$中的值相加。
- 重复书上操作，一直到$10-(IX)<0$，即$IX>10$。此时循环结束。执行第六行，第六行存数操作，将$ACC$中的数放入$sum$变量中。

从上面可以体会到，$A$作为基址，而$IX$作为偏移量即代码中对应的`i`。不断改变变址寄存器$IX$的内容，便可很容易形成数组中任一数据的地址，特别适合编制循环程序。

变址寻址优点：在数组处理过程中，可设定$A$为数组的首地址，不断改变变址寄存器$IX$的内容，便可很容易形成数组中任一数据的地址，特别适合编制循环程序。

复合寻址：

可以采用基址$+$变址复合方式寻址。

如果一个程序在主存中随机存放，就需要一个基地址指向程序的起始位置。此时$EA=(IX)+((BR)+A)$。

注：实际应用中往往需要多种寻址方式复合使用(可理解为复合函数)

#### 相对寻址

相对寻址：把程序计数器$PC$的内容加上指令格式中的形式地址$A$而形成操作数的有效地址，即$EA=(PC)+A$，其中$A$是相对于$PC$所指地址的位移量，可正可负，补码表示。

<img src="https://image.sybblogs.fun/img-common/202401201551431.png" alt="相对寻址" style="zoom:33%;" />

先从主存地址$1000$地方取出指令，当取出指令后CPU会让$PC+1$，若当前指令字长为$2B$，则$PC+2$。因此取出当前指令后$PC$的值为$1002$。那么此时CPU根据寻址特征知道这是相对寻址，所以$EA$的值就是当前$PC$的值再加上形式地址$A$的值。如果$A$值是负，则从当前PC所指行往前偏移，如果是正，则往后偏移。

相对寻址原理：

<img src="https://image.sybblogs.fun/img-common/202401201602778.png" alt="相对寻址原理" style="zoom:33%;" />

当执行到$M+3$主存行地址指令时，如果还按照之前的方式跳转，会跳转到$2$主存行地址，这一行是其他代码显然错误。为了解决这个问题采用相对寻址方式，当执行$M+3$主存行指令时，$PC+1$指向$M+4$，这里修改地址码值为`-4(补码表示)`，此时$PC=M+4-4=M$，所以以后不管这段代码在哪个位置，采用相对寻址方式都会指向$M$主存行位置。

<img src="https://image.sybblogs.fun/img-common/202401201608982.png" alt="相对寻址原理1" style="zoom:33%;" />

同时还能发现一个问题，当程序代码移动时，数组$a[0]$可能不再存放在$7$主存行位置，所以要修改$M$行地址码值，使其与$a[0]$所在主存位置对应，显然每次都要修改很麻烦。所以现实中都是采用分段方式解决：即程序段(只存放指令代码)和数据段(只存放数据)分开存放。

采用相对寻址优点：操作数的地址不是固定的，它随着$PC$值的变化而变化，并且与指令地址之间总是相差一个固定值，因此便于程序浮动(一段代码在程序内部的浮动)。相对寻址广泛应用于转移指令。

注意：基址寻址中的浮动指的是整段程序在内存中的浮动。而相对寻址的浮动指的是一段代码在程序内部的浮动。

三种寻址方式总结：

<img src="https://image.sybblogs.fun/img-common/202401201614332.png" alt="三种寻址方式总结" style="zoom:33%;" />

注意：取出当前指令后，PC会指向下一条指令，相对寻址是**相对于下一条指令**的偏移

### 4.8 堆栈寻址

堆栈寻址：操作数存放在堆栈中，隐含使用堆栈指针(SP)作为操作数地址。这个堆栈指针存放在寄存器$SP$当中。

堆栈是存储器(或专用寄存器组)中一块特定的按后进先出(LIFO)原则管理的存储区，该存储区中被读$/$写单元的地址是用一个特定的寄存器给出的，该寄存器称为堆栈指针(SP)。

这个堆栈可以用两种方式实现：一种是采用专门寄存器存放专门元素。另一种方式是在主存中划出一片区域用作堆栈。

用寄存器实现堆栈原理：

<img src="https://image.sybblogs.fun/img-common/202401201646973.png" alt="堆栈寻址" style="zoom:33%;" />

这里用四个寄存器实现堆栈，系统中会用专门的寄存器$SP$来指向当前栈顶元素的位置。当前$SP\rightarrow R_0$。由于这里只有四个寄存器，所以$SP$只需要用两位就可以表示所有的值。

假设现在要用堆栈里的两个栈顶元素来完成一次加法操作。加数和被加数会先放到$ACC$和$X$中。通过$ALU$计算出结果。具体操作是，用汇编指令$POP$弹出栈顶元素，并将其放入$ACC$累加寄存器中。弹出后将$SP+1$指向弹出后栈顶的元素即$R_1$。同样用$POP$指令弹出栈顶元素放入$X$中。接着$SP+1$指向$R_2$。现在加数和被加数已经有了，之后用汇编语句$ADD$将两个数相加的结果放入$Y$中。最后通过汇编指令$PUSH$将结果$Y$压入栈顶，这个压栈具体做法是，将$SP-1$指向$R_1$。然后再将$Y$的值放入$SP$所指向的$R_1$寄存器中。

汇编指令如下：

<img src="https://image.sybblogs.fun/img-common/202401201656977.png" alt="堆栈寻址汇编语句" style="zoom:33%;" />

上面情况是栈顶在小地址方向，还有的情况是栈顶在大地址方向。栈顶大地址方向的汇编指令：

<img src="https://image.sybblogs.fun/img-common/202401201657762.png" alt="堆栈寻址汇编语句2" style="zoom:33%;" />

上面通过几个寄存器实现的堆栈称为硬堆栈。还有一种方式是软堆栈，即从主存中划出一片区域当堆栈。这种方式通过POP和PUSH对栈进行操作都会进行一次访存，而硬堆栈由于存放在寄存器中所以不用进行访存。

<img src="https://image.sybblogs.fun/img-common/202401201700632.png" alt="软堆栈" style="zoom:33%;" />

显然采用寄存器实现的硬堆栈速度更快，但成本高；而软堆栈访问速度慢，但成本更低。在实际的系统中通常采用软堆栈实现。堆栈可用于函数调用时保存当前函数的相关信息。

十种寻址方式总结：

<img src="https://image.sybblogs.fun/img-common/202401201703189.png" alt="十种寻址方式总结" style="zoom: 33%;" />

## 5. 高级语言与机器级代码之间的对应
机器语言与汇编语言都是机器级代码。考试只考x86汇编语言，如果考察其他汇编语言题中会给出详细注释。

### 5.1 x86汇编语言指令基础

指令作用：要么处理数据，要么改变程序执行流。指令的格式：操作码$+$地址码，操作码指出数据怎么处理，地址码指明了数据存放在哪。而数据可以存放在寄存器中，主存里，指令里。如果是在寄存器中，指令给出寄存器名即可。如果是在主存中，指令给出主存地址即可，同时要指明读写长度。如果在指令中就是立即寻址。

以$mov$指令为例：

|             语法格式             |                    功能                    |
| :------------------------------: | :----------------------------------------: |
| $mov$ 目的操作数$d$，源操作数$s$ | 将源操作数$s$复制到目的操作数$d$所指的位置 |

~~~shell
mov eax,ebx				 	#将寄存器ebx的值复制到寄存器eax
mov eax,5				 	#将立即数5复制到寄存器eax
mov eax,dword ptr[af996h]	#将内存地址af996h所指的32bit值复制到寄存器eax
mov byte ptr[af996h],5		#将立即数5复制到内存地址af996h所指的--字节中
~~~

> 上面中括号表示主存地址。

如何指明内存的读写长度：dword ptr：双字(32bit)；word ptr：单字(16bit)；byte ptr：字节(8bit)

x86架构的CPU，寄存器如下：寄存器$E=Extended=32bit$，所以寄存器都是以$e$开头。

<img src="https://image.sybblogs.fun/img-common/202401201817218.png" alt="x86架构寄存器" style="zoom: 33%;" />

前四个为一组用于存什么数据未知，所以称为通用寄存器。

中间两组$ESI,EDI$是变址寄存器。变址寄存器可用于线性表、字符串的处理。

最后两个寄存器$EBP,ESP$分别指明堆栈的基指针和顶指针。主要用于实现函数的调用。

前四个寄存器使用较为灵活，可以去掉前面的$E$，使用低地址的$16bit$。即$ax$代表使用$EAX$寄存器的低地址$16bit$。

<img src="https://image.sybblogs.fun/img-common/202401201825200.png" alt="寄存器低地址使用" style="zoom:33%;" />

并且可以指定使用$8bit$，如：$ah$表示$EAX$寄存器中的$8bit$。

<img src="https://image.sybblogs.fun/img-common/202401201827911.png" alt="寄存器低地址使用2" style="zoom:33%;" />

当然最常用的还是直接使用$32bit$。

在看几个常见操作：

~~~shell
mov eax,dword ptr [ebx]			#将ebx所指主存地址的32bit复制到eax寄存器中
mov dword ptr [ebx],eax			#将eax的内容复制到ebx所指主存地址的32bit
mov eax, byte ptr [ebx]			#将ebx所指的主存地址的8bit复制到eax
mov eax,[ebx]					#若未指明主存读写长度，默认32 bit
mov [af996h],eax				#将eax的内容复制到af996h所指的地址(未指明长度默认32bit)
mov eax,dword ptr [ebx+8]		#将ebx+8所指主存地址的32bit复制到eax寄存器中
mov eax, dword ptr [af996-12h]	#将af996-12所指主存地址的32bit复制到eax寄存器中
~~~

### 5.2 常用的汇编指令

x86常见的算术运算指令：

|  功能  |      汇编指令       |                             解释                             |
| :----: | :-----------------: | :----------------------------------------------------------: |
|   加   |       add d,s       |                    计算$d+s$，结果存入$d$                    |
|   减   |       sub d,s       |                    计算$d-s$，结果存入$d$                    |
|   乘   | mul d,s<br>imul d,s |  无符号数$d*s$，乘积存入$d$<br/>有符号数$d*s$，乘积存入$d$   |
|   除   |   div s<br>idiv s   | 无符号数除法edx:eax/s， 商存入eax， 余数存入edx<br/>有符号数除法edx:eax/s， 商存入eax， 余数存入edx |
| 取负数 |        neg d        |                   将$d$取负数，结果存入$d$                   |
|  自增  |        inc d        |                    将$d++$， 结果存入$d$                     |
|  自减  |        dec d        |                     将$d--$，结果存入$d$                     |

上面指令后的操作数可能来自寄存器、主存和指令这三个地方。而为了提高运行效率减少主存访问，在x86汇编指令中**两个操作数不能同时来自主存**。由于最终处理的结果要放回到$d$中，所以$d$**不可能是常量**，只可能是寄存器或者主存地址。

注意除法指令，$div\quad s$这里的$s$是除数，而被除数会被提前放在$edx$和$eax$寄存器中。而$edx:eax$指的是在进行除法运算之前，需要对被除数进行位扩展，如：$\frac{32bit}{32bit}$，此时被除数需要扩展到$64bit$，即$\frac{64bit}{32bit}$。而一个寄存器只有$32bit$，所以需要两个寄存器存放，$edx$存放高$32$位，$eax$存放低$32$位。

通常会用`<reg>`代表寄存器、`<mem>`代表内存、`<con>`代表常数。

x86常见的逻辑指令

| 功能 | 汇编指令 |                      解释                       |
| :--: | :------: | :---------------------------------------------: |
|  与  | and d,s  |         将$d$、$s$逐位相与，结果放回$d$         |
|  或  |  or d,s  |         将$d$、$s$逐位相或，结果放回$d$         |
|  非  |  not d   |           将$d$逐位取反，结果放回$d$            |
| 异或 | xor d,s  |         将$d$、$s$逐位异或，结果放回$d$         |
| 左移 | shl d,s  | 将$d$逻辑左移$s$位，结果放回$d$(通常$s$是常量)  |
| 右移 | shr d,s  | 将$d$逻辑右移$s$位，结果放回$d$ (通常$s$是常量) |

其他指令：

用于实现分支结构、循环结构的指令：cmp、test、jmp、jxxx

用于实现函数调用的指令：push、pop、call、ret

用于实现数据转移的指令：mov

### 5.3 AT&T格式的汇编指令

AT&T格式常用于Unix和Linux。intel格式常用于Windows。

AT&T常用格式：

|            功能            |                           汇编指令                           |                         解释                         |                        对应intel格式                         |
| :------------------------: | :----------------------------------------------------------: | :--------------------------------------------------: | :----------------------------------------------------------: |
| 目的操作数$d$、源操作数$s$ |                            op s,d                            |             源操作数在做，目的操作数在右             |                            op d,s                            |
|         寄存器表示         |                        mov %ebx,%eax                         |                寄存器名前必须加"$\%$"                |                         mov eax,ebx                          |
|        立即数的表示        |                       mov $\$$985,%eax                       |                立即数之前必须加"$\$$"                |                         mov eax,985                          |
|       主存地址的表示       |                      mov %eax,(af996h)                       |                 主存地址用小括号表示                 |                       mov [af996h],eax                       |
|       读写长度的表示       | movb $\$$5,(af996h)<br>movw $\$$5,(af996h)<br/>movl $\$$5,(af996h)<br/>addl $\$$5,(af996h)<br/> | 指令后加$b,w,l$分别表示读写<br>长度byte、word、dword | mov byte ptr [af996h],5<br>mov word ptr [af996h],5<br>mov dword ptr [af996h],5<br>add byte ptr [af996h],4 |
|    主存地址偏移量的表示    |       movl -8(%ebx),%eax<br>movl 4(%ebx,%ecx,32),%eax        |                     偏移量(基址)                     |          mov eax,[ebx-8]<br>mov eax,[ebx+ecx*32+4]           |

对于最后`mov eax,[ebx+ecx*32+4]`，做一下详细解释：

<img src="https://image.sybblogs.fun/img-common/202401211508116.png" alt="偏移量复杂例子" style="zoom:33%;" />

对于上图，这是一个结构体数组。要访问数据元素$3$中的变量$1$，需要知道这个结构体数组基址，然后$基址+变址*比例因子$。这里的变址是要访问的索引号，比例因子就是每个数组大小，这里是$32bit$，最后再加上变量$0$的$4B$就是变量$1$的位置。即$ebx+3*32+4$

### 5.4 汇编选择语句

前面已经介绍基本汇编语句，这里会介绍选择语句的汇编方式。

指令存储在主存中，每次取出一条指令$PC$会自动$+1$，指向下一条指令。但是选择语句可能会改变程序的执行流。注意在x86处理器中程序计数器$PC$通常称为$IP$。

改变程序执行流需要用到无条件转义指令：JMP

| 指令名 |    语法    |         功能         |
| :----: | :--------: | :------------------: |
|  jmp   | jmp <地址> | PC无条件转移至地址处 |

这里的`<地址>`可以是常数、寄存器、主存。但最常用还是"标号"锚定：

~~~shell
mov eax,7
mov ebx,6
jmp NEXT
mov ecx, ebx
NEXT :			#用"标号”锚定位置
mov ecx, eax
~~~

当执行到`jmp NEXT`时，程序计数器$PC$会跳转到最后一行，即`NEXT`标记的位置。这里的标号不一定是`NEXT`，可以自定义名字。

JMP指令类似于C语言的goto语句，虽然能实现跳转，但无法实现`if...else..`语句。要实现选择语句需要用到条件转移指令`jxxx`。

常用的`jxxx`语句及功能：

| 语句 |    语法    |      功能      |
| :--: | :--------: | :------------: |
|  je  | je <地址>  | 若`a==b`则跳转 |
| jne  | jne <地址> | 若`a!=b`则跳转 |
|  jg  | jg <地址>  | 若`a>b`则跳转  |
| jge  | jge <地址> | 若`a>=b`则跳转 |
|  jl  | jl <地址>  | 若`a<b`则跳转  |
| jle  | jle <地址> | 若`a<=b`则跳转 |

上面指令通常要搭配CMP指令，CMP指令用于比较两个数。

|  语法   |                        功能                         |
| :-----: | :-------------------------------------------------: |
| cmp a,b | 比较$a$和$b$的值，$a,b$可能是常量、主存地址或寄存器 |

例1：

~~~shell
cmp eax,ebx		#比较寄存器eax和ebx里的值
jg NEXT			#若eax > ebx,则跳转到NEXT:
~~~

例2：将下面C语言转换为汇编语言

~~~c
if(a>b){
    c=a;
}else{
    c=b;
}
~~~

汇编语言：

~~~shell
mov eax,7		#假设变量a=7,存入eax 
mov ebx,6		#假设变量b=6,存入ebx
cmp eax,ebx		#比较变量a和b
jg NEXT		#若a>b,转移到NEXT:
mov ecx,ebx		#假设用ecx存储变量c,令c=b
jmp END			#无条件转移到END :
NEXT:
mov ecx,eax		#假设用ecx存储变量c,令c=a
END:
~~~

扩展：CMP指令的底层原理。

<img src="https://image.sybblogs.fun/img-common/202401211621598.png" alt="运算标志位" style="zoom:33%;" />

之前学习过，每次ALU运算都会产生新的标志位覆盖上次标志位：

- OF (Overflow Flag)溢出标志。溢出时为$1$，否则置$0$。
- SF (Sign Flag) 符号标志。结果为负时置$1$，否则置$0$。
- ZF (Zero Flag)零标志，运算结果为$0$时ZF位置$1$，否则置$0$
- CF (Carry Flag)进位$/$借位标志，进位$/$借位时置$1$，否则置$0$

而跳转指令JMP之前会使用CMP指令，这个指令本质是将做一次$a-b$的运算，这个运算会产生上面几个标志位。这些标志位，会存放到PSW程序状态寄存器中，intel称其为标志寄存器。

<img src="https://image.sybblogs.fun/img-common/202401211624116.png" alt="标志寄存器" style="zoom:33%;" />

`jne`这条指令在`a!=b`时发生跳转，CPU在执行这条指令时，会读取之前CMP产生的标志位$ZF$是否等于$0$，如果等于$0$满足条件进行跳转。其他指令也可以从标志位中得出跳转信息：

~~~shell
je <地址>		#若a==b则跳转,ZF==1?
jne <地址>	#若a!=b则跳转,ZF==0?
jg <地址>		#若a>b则跳转,ZF==0&&SF==OF?
jge <地址>	#若a>=b则跳转,SF==OF?
jl <地址>		#若a<b则跳转,SF!=OF?
jle <地址>	#若a<=b则跳转,SF!=OF||ZF==1?
~~~

### 5.5 循环语句的汇编实现

可以用条件转移指令实现循环。有以下C语言代码：

~~~c
int resul=0;
for(int i=1;i<=100;i++) {
    result +=i;
} //求1+2+3+. . .+100
~~~

转换为汇编语言：

~~~shell
mov eax,0		#用eax保存result,初值为0
mov edx,1		#用edx保存i, 初始值为1
cmp edx,100 	#比较i和100
jg L2			#若i>100，转跳到L2执行
L1:				#循环主体
add eax,edx 	#实现result +=i
inc edx			#inc自增指令,实现i++
cmp edx,100 	#比较i和100
jle L1			#若i<=100,转跳到L1执行
L2:				#跳出循环主体
~~~

所以用条件转移指令实现循环，需要$4$个部分构成：

1. 循环前初始化
2. 是否直接跳出循环
3. 进入循环主体
4. 是否继续循环

除了用条件转移指令实现，还可以用LOOP指令。

|   指令语法    |                     功能                      |
| :-----------: | :-------------------------------------------: |
| loop 循环体名 | 循环计数器$--$，并且若不等于$0$，跳转到循环体 |

实现：有以下一段C语言

~~~c
for(int i=500;i>0;i--){
    //...
}//循环500次
~~~

使用LOOP指令实现循环：

~~~shell
mov ecx,400			#用ecx作为循环计数器
Looptop:			#循环体
#...
#...
loop Looptop		#ecx--,若ecx!=0,则跳转到Looptop循环体
~~~

上面汇编代码可以知道LOOP指令相当于：

~~~shell
dec ecx
cmp ecx,0
jne Looptop
~~~

注意：ecx可以作为循环计数器，其寄存器不能，所以这里必须用ecx寄存器。

理论上能用loop指令实现的功能一定能用条件转移指令实现。而使用loop指令可能会使代码更清晰简洁。

补充：loop指令还有loopx指令。如loopnz,和loopz。其中loopnz是当`ecx!=0&&ZF==0`时，继续循环。而loopz是当`ecx!=0&&ZF==1`时,继续循环。

### 5.6 函数调用汇编实现

高级语言在执行函数如`main()`函数时，会先将其压入函数调用栈，这个压入的函数称为栈帧。如果`main()`函数调用其他函数时，仍会将被调用函数压入函数栈中，称为栈帧。

每个函数的栈帧中包含函数达阔内定义的局部变量和保存函数调用的信息。

<img src="https://image.sybblogs.fun/img-common/202401211708677.png" alt="高级语言函数调用栈帧" style="zoom:33%;" />

其中`caller()`和`add()`函数代码如下：

~~~c
int caller() {
    int temp1=125;
    int temp2=80;
    int sum=add(templ,temp2);
    return sum;
}

int add(int x,int y){
    return x+y;
}
~~~

对应的汇编代码如下：

~~~shell
#caller()
caller:
push ebp
mov ebp,esp
sub esp,24
mov [ebp-12],125
mov [ebp-8],80
mov eax,[ebp-8]
mov [esp+4],eax
mov eax,[ebp-12]
mov esp,eax
call add
mov[ebp-4],eax
mov eax,[ebp-4]
leave
ret
#add()
add:
push ebp
mov ebp,esp
mov eax,[ebp+12]
mov edx,[ebp+8]
add eax,edx
leave
ret
~~~

所以可以知道函数调用指令是：`call 函数名`。函数返回指令是：`ret`。

其调用执行原理本质就是CPU中程序计数器，指向改变过程。当产生函数调用时，就是让$PC$寄存器指向被调用函数的位置。同样`ret`指令也是让$PC$寄存器指向位置发生改变。在x86中通常称$PC$为$IP$。

CALL指令作用：

- 将$IP$指向的旧值压栈保存(保存在函数的栈帧顶部)
- 设置$IP$新值，无条件转移至被调用函数的第一条指令

RET指令作用：从函数的栈帧顶部找到$IP$旧值，将其出栈并恢复$IP$寄存器。

具体执行是：call指令执行时，首先会将$IP$寄存器指向的值压入栈中保存，之后再将$IP$指向被调用起始位置。当被调用函数执行完后，ret指令会从栈顶位置取出刚刚$IP$指向的旧地址，将这个值写回$IP$寄存器。这一就完成函数调用。

#### 栈帧中数据的访问

之前看到的函数调用栈实际在内存中是倒过来存放的。

<img src="https://image.sybblogs.fun/img-common/202401211727518.png" alt="函数调用栈倒置" style="zoom:33%;" />

这是因为在内存中，栈底对应的是内存的高地址，栈顶对应的是低地址。

<img src="https://image.sybblogs.fun/img-common/202401211729728.png" alt="函数调用栈子啊内存中位置" style="zoom: 33%;" />

之前学过x86中的寄存器，其中EBP和ESP寄存器分别用于存储堆栈基指针和堆栈顶指针。并且在一个CPU内部只有一个EBP和ESP。

访问栈帧中的数据需要用到push和pop指令。push、pop指令实现入栈、出栈操作。x86默认以$4$字节为单位。指令格式如下:

| 指令语法 |             功能              |             注意事项              |
| :------: | :---------------------------: | :-------------------------------: |
|  push a  | 先让ESP减$4$，再将$a$压入栈中 | $a$可以是立即数、寄存器或主存地址 |
|  pop b   | 栈顶元素写入$b$，再让ESP加$4$ |     $b$可以是寄存器、主存地址     |

例子：

~~~shell
push eax		#将寄存器eax的值压栈
push 985		#将立即数985压栈
push [ebp+8]	#将主存地址[ebp+8]里的数据压栈
pop eax			#栈顶元素出栈,写入寄存器
pop [ebp+8]		#栈顶元素出栈,写入主存地址[ebp+8]
~~~

假设当前eax寄存器中的值是$211$。内存结构如下(黄色部分是一个函数esp指向栈顶，ebp指向栈底)：

<img src="https://image.sybblogs.fun/img-common/202401211741934.png" alt="push和pop指令原理" style="zoom:33%;" />

`push eax`会先让esp值$-4$，即向下移动四个字节，让后将eax中的值放入esp指向的位置，即栈顶。

<img src="https://image.sybblogs.fun/img-common/202401211744424.png" alt="push和pop指令原理1" style="zoom:33%;" />

`push 985`同样先让esp值$-4$，即向下移动四个字节，让后将立即数$985$值放入esp指向的位置，即栈顶。

<img src="https://image.sybblogs.fun/img-common/202401211745767.png" alt="push和pop指令原理2" style="zoom:33%;" />

`push [ebp+8]`，会先让$ebp+8,esp-4$，然后将此处的值$666$放入栈顶。

<img src="https://image.sybblogs.fun/img-common/202401211827063.png" alt="push和pop指令原理3" style="zoom:33%;" />

`pop eax`会让$esp$所指位置的值放入eax中，再让$esp+4$。

<img src="https://image.sybblogs.fun/img-common/202401211829009.png" alt="push和pop指令原理4" style="zoom:33%;" />

之后的指令执行原理同上。

通过上面例子可以发现push和pop只能对栈顶元素进行操作，这样访问就有限制，还有更灵活的方法mov指令。

可以使用加法指令和减法指令来对esp和edp两个指针进行移动。

例子：

~~~shell
sub esp,12			#栈顶指针-12
mov[ esp+8],eax		#将eax的值复制到主存[esp+8]
mov [esp+4],958		#将985复制到主存[esp+4]
mov eax,[ebp+8] 	#将主存[ebp+8]的值复制到eax
mov [esp],eax		#将eax的值复制到主存[esp]
add esp,8			#栈顶指针+8
~~~

其内存中的结构如下：

<img src="https://image.sybblogs.fun/img-common/202401211833546.png" alt="mov指令" style="zoom:33%;" />

`sub esp,12`这条指令会让esp指针向下移动三位。

<img src="https://image.sybblogs.fun/img-common/202401211835106.png" alt="mov指令1" style="zoom:33%;" />

之后执行原理类似。

因此可以用mov指令，结合esp、ebp指针访问栈帧数据可以用减法$/$加法指令，即sub$/$add修改栈顶指针esp的值。

#### 切换栈帧

当发生函数调用时，需要修改ebp和esp指向，让其指向新的函数顶部和底部。这个切换过程原理如下：

- 当执行`call add`时，会将旧的$IP$压入栈中，并将$IP$跳转至被调用函数开头位置。

  <img src="https://image.sybblogs.fun/img-common/202401211854274.png" alt="切换栈帧" style="zoom:33%;" />

- 被调用函数开头都会有两个指令

  ~~~shell
  push ebp 
  mov ebp,esp
  ~~~

  第一条指令会把栈底基地址压入栈顶，第二条指令会将ebp指向esp当前位置

  <img src="https://image.sybblogs.fun/img-common/202401211857933.png" alt="切换栈帧1" style="zoom:33%;" />

  这么做当一层函数执行结束要返回之前，总能在当前函数的栈底找到上一个函数基地址。这样既可以恢复ebp寄存器的值。

  以上两条指令可以精简为`enter`。

- 之后被调用函数执行对应操作，最函数执行完毕准备`ret`返回指令之前，所有函数都会进行两步操作

  ~~~shell
  mov esp,ebp		#让esp指向当前栈帧的底部
  pop ebp			#将esp所指元素出栈，写入寄存器ebp
  ~~~

  第一个指令会让ebp指向esp位置，即指向栈底。第二个指令会让esp所指的栈顶元素出栈放入ebp寄存器中，同时esp$+4$指向$IP$旧地址值的位置。也就是让ebp指针重新指向上一个函数栈底。

  <img src="https://image.sybblogs.fun/img-common/202401211909526.png" alt="切换栈帧2" style="zoom:33%;" />

  上面两条指令等价于`leave`指令。

- 最后ret指令，由于上一步将esp指向$IP$旧地址，所以ret会将esp中的值写入$IP$寄存器当中。也就是让程序执行流恢复到调用函数之后的一行。

  <img src="https://image.sybblogs.fun/img-common/202401211912036.png" alt="切换栈帧3" style="zoom:33%;" />

总结：

<img src="https://image.sybblogs.fun/img-common/202401211913197.png" alt="函数切换栈帧总结" style="zoom:33%;" />

每个被调用函数在执行前都会有`enter`部分，最后都会有`leave`部分。

#### 栈帧中包含的内容

当前有一段代码

~~~c
int caller() {
    int temp1=125;
    int temp2=80;
    int sum=add(templ,temp2);
    return sum;
}

int add(int x,int y){
    return x+y;
}
~~~

假设当前运行的是`caller()`函数，根据之前内容，可以知道栈帧中通常包含以下内容：

- 栈帧底部一定是上一层函数栈帧的基址，即edp旧址。

- 栈帧最顶部一定是返回地址(当前函数的栈帧除外)，也就是$IP$寄存器旧址

- 通常将局部变量集中存储在栈帧底部区域。C语言中越靠前定义的局部变量越靠近栈顶。

  所以只需要将**$edp-4$就可以找到第一个局部变量**，$edp-8$就是第二个局部变量等。

- 通常将调用参数集中存储在栈帧顶部区域

  如果当前运行的是`add`函数，此时`edp`指向`add`函数栈底位置。此时**将$edp+8,edp+4$就可以得到$x$和$y$参数的值**。

所以一个函数栈内容分布如下：

<img src="https://image.sybblogs.fun/img-common/202401211929403.png" alt="函数栈帧" style="zoom:33%;" />

可以看到中间有空闲未使用区域。这是正常现象因为当使用gcc编译器时，编译器会将每个栈帧大小设置为$16B$的整数倍(当前函数的栈帧除外)，因此栈帧内可能出现空闲未使用的区域。

栈帧内容总结：

<img src="https://image.sybblogs.fun/img-common/202401211932114.png" alt="栈帧内容总结" style="zoom: 33%;" />

#### 函数参数与返回值的传递

通过上面学习可以知道函数参数通过$edp$向上移动可以获取。

有以下一段汇编代码

~~~shell
#caller()
caller:
push ebp
mov ebp,esp
sub esp,24
mov [ebp-12],125
mov [ebp-8],80
mov eax,[ebp-8]
mov [esp+4],eax
mov eax,[ebp-12]
mov esp,eax
call add
mov [ebp-4],eax
mov eax,[ebp-4]
leave
ret
~~~

执行完这段汇编程序后，函数栈如下：

<img src="https://image.sybblogs.fun/img-common/202401211947931.png" alt="汇编实战" style="zoom:33%;" />

之后会执行`call add`指令，add函数汇编指令如下：

~~~shell
#add()
add:
push ebp
mov ebp,esp
mov eax,[ebp+12]
mov edx,[ebp+8]
add eax,edx
leave
ret
~~~

执行完`mov ebp,esp`指令后栈帧如下：

<img src="https://image.sybblogs.fun/img-common/202401211948560.png" alt="汇编实战2" style="zoom:33%;" />

之后`mov eax,[ebp+12]`和`mov edx,[ebp+8]`，分别可以访问到$y,x$的值。并将这两个值放入$eax,edx$。`add eax,edx`会将这两个变量相加，相加后的结果再放回$eax$中。

<img src="https://image.sybblogs.fun/img-common/202401211951533.png" alt="汇编实战3" style="zoom:33%;" />

最后执行`leave`指令切换上一层函数栈帧，再执行`ret`指令让程序回到函数调用后的一行继续执行。

可以看到add函数将返回值写到eax寄存器中。所以caller函数中的`mov [ebp-4],eax`就是取返回值的操作。即对应C语言中的`sum=add(temp1,temp2)`操作。之后仍会把`sum`放入eax寄存器，让上一层函数取返回值，即`mov eax [ebp-4]`。由于C语言的返回值只有一个，所以通常会把返回值写入eax中。这样上一层函数直接去eax中取出返回值即可。

至此对函数调用机器级语言进行总结：

<img src="https://image.sybblogs.fun/img-common/202401212000513.png" alt="汇编实战总结" style="zoom:33%;" />

最后还有一个问题，当调用者某些值已经存在$eax$寄存器中，那么调用发生时，被调用者也有可能用到$eax$寄存器，从而会覆盖其中的值。解决方法是在函数调用之前对寄存器$eax$中的值进行压栈保存即可。等函数返回后再将这些值从栈中恢复到寄存器即可。所以函数栈中还可能有一层是保存部分寄存器的值。

<img src="https://image.sybblogs.fun/img-common/202401212003886.png" alt="函数调用栈中寄存器的值" style="zoom: 33%;" />

## 6. CISC和RISC

CISC和RISC是指令设计的两个方向。

CISC(复杂指令集计算机系统)：设计思路是一条指令完成一个复杂的基本功能。代表：x86架构，主要用于笔记本、台式机等。

RISC(精简指令集计算机系统)：设计思路是一条指令完成一个基本动作，多条指令组合完成一个复杂的基本功能。代表：ARM架构、手机、平板等。

可以理解为RISC相当于C语言基本语法，而CISC相当关于提供库函数的C语言。再后来的开发中发现典型程序中$80\%$的语句仅仅使用处理器中的$20\%$的复杂指令。

比如设计一套能实现整数、矩阵加$/$减$/$乘运算的指令集：

- CISC设计思路：

  除了提供整数的加减乘指令除之外，还提供矩阵的加法指令、矩阵的减法指令、矩阵的乘法指令一条指令可以由一个专门的电路完成。所以这里需要$6$套电路实现，其中矩阵乘法的电路设计起来非常困难。

  所以可以采用"存储程序"的设计思想，由多个比较通用的电路配合存储部件来完成更复杂的指令。即可以设计$5$套通用电路，最后的矩阵乘法可以拆解为由$5$个通用基本指令完成的操作，这就是微程序的概念。

- RISC设计思路：

  只提供整数的加减乘指令。

  一条指令一个电路，总共只需要设计$3$套电路即可，所以电路设计相对简单，功耗更低。

  由于RISC设计思路的指令都很简单，所以这些指令执行时间都差不多，这个特性可以很方便实现"并行"、"流水线"。

CISC和RISC对比

|     对比项目     |                 CISC                 |                 RISC                 |
| :--------------: | :----------------------------------: | :----------------------------------: |
|     指令系统     |           复杂、庞大、丰富           |              简单、精简              |
|     指令数目     |           一般大于$200$条            |           一般小于$100$条            |
|     指令字长     |                不固定                |                 定长                 |
|    可访存指令    |               不加限制               |     只有$Load/Store$指令可以访存     |
| 各种指令执行时间 |               相差较大               |       绝大多数在一个周期内完成       |
| 各种指令使用频度 |               相差很大               |              都比较常用              |
|  通用寄存器数量  |                 较少                 |                  多                  |
|     目标代码     | 难以用优化编译生成高效的目标代码程序 | 采用优化的编译程序，生成代码较为高效 |
|     控制方式     |         绝大多数为微程序控制         |   绝大多数为组合逻辑控制(效率更高)   |
|    指令流水线    |         可以通过一定方式实现         |               必须实现               |

# 五. 中央处理器

本章会基于之前的学习进行补充和完善。

CPU基本构成是：ALU(第二章已学)、寄存器(第三章已学)、中断系统(最后一章)、CU控制单元(本章)。

## 1. CPU的功能和基本结构

CPU需要实现以下功能：

1. 指令控制。完成取指令、分析指令和执行指令的操作，即程序的顺序控制。

2. 操作控制。一条指令的功能往往是由若干操作信号的组合来实现的。CPU管理并产生由内存取出的每条指令的操作信号，把各种操作信号送往相应的部件，从而控制这些部件按指令的要求进行动作。

3. 时间控制。对各种操作加以时间上的控制。时间控制要为每条指令按时间顺序提供应有的控制信号。

4. 数据加工。对数据进行算术和逻辑运算。

5. 中断处理。对计算机运行过程中出现的异常情况和特殊请求进行处理。

   正常情况下CPU会顺序执行程序，但计算机内会有一些突发的状况(如鼠标单击其他软件)，因此需要这种中断处理。当CPU检测到特殊的中断信号后，会转而处理中断程序的一系列指令代码，当中断执行完后再回去执行原本的程序指令。

CPU结构如下：

<img src="https://image.sybblogs.fun/img-common/202401221720624.png" alt="CPU结构" style="zoom:33%;" />

从运算器和控制器角度对CPU功能进行分类：

运算器会对程序进行加工操作。

控制器：协调并控制计算机各部件执行程序的指令序列，基本功能包括取指令、分析指令、执行指令

- 取指令：CPU会自动形成下一条指令新地址，即$PC+1$。另外再每一条指令运行结束后，控制器也应该发出下一条取指令的命令。
- 分析指令：将指令的操作码译码(分析本条指令要完成什么操作)，同时会产生操作数的有效地址。

- 执行指令：根据分析指令得致的"操作命令"和"操作数地址"形成操作信号控制序列，控制运算器、存储器以及$I/O$设备完成相应的操作。

- 中断处理：每执行完一条指令，CPU都会检查是否有中短信号需要处理。如果有CPU会对总线及输入输出设备进行应有的响应。同时也会处理异常情况(如掉电)和特殊请求(打印)。

 接下来会详细探讨运算器和控制器基本结构。

### 1.1 运算器基本结构

上面介绍过运算器由两部分构成：算术逻辑单元和通用寄存器组。

算术逻辑单元：主要功能是进行算术$/$逻辑运算。

通用寄存器组：如AX、BX、CX、DX、SP等，用于存放操作数(包括源操作数、目的操作数及中间结果)和各种地址信息等。其中SP是堆栈指针，用于指示栈顶的地址。

<img src="https://image.sybblogs.fun/img-common/202401221805312.png" alt="通用寄存器组" style="zoom:33%;" />

右图中$AH,AL$指的是$AX$寄存器的高位和低位。通用寄存器中保存的数据都有可能成为ALU的输入，由于ALU有两个输入口，所以每个寄存器要提供两个连线，这里的两根连线是泛指，如果一个寄存器$16bit$，那每一边都需要$16$根连线总共$32$根连线连接ALU。

<img src="https://image.sybblogs.fun/img-common/202401221809890.png" alt="ALU连线通路" style="zoom:33%;" />

上面这种连线方式称为**专用数据通路**：根据指令执行过程中的数据和地址的流动方向安排连接线路。显然这种连接方式由于寄存器数目增加连接线路也会越来越多，所以制造成本会提高。

所以专用数据通路优势：性能较高，基本不存在数据冲突现象，但结构复杂，硬件量大，不易实现。

同时还会存在另一个问题：如果直接用导线连接，相当于多个寄存器同时并且一直向ALU传输数据，显然ALU只需要$A,B$只需要两个寄存器提供数据就可以。解决这种问题方法：

- 解决方案一

  使用多路选择器(MUX)。根据控制信号选择一路输出。

  <img src="https://image.sybblogs.fun/img-common/202401221847384.png" alt="多路选择器控制ALU信号" style="zoom:33%;" />

  假如现在要执行加法指令$ADD$，两个加数分别存放在$R_0,R_1$寄存器中。在执行这条指令的时候，控制器会给左边多路选择器$MUX$输入$00$信号，表示$R_0$信号会成为$A$接口读入的数据。控制器右边多路选择器$MUX$会输入$01$信号，表示$R_1$这个寄存器数据通过。

- 解决方法二

  使用三态门。每一个三态门可以控制每一路是否输出。

  <img src="https://image.sybblogs.fun/img-common/202401221852169.png" alt="三态门解决ALU信号输入" style="zoom:33%;" />

  如：$R0out$为$1$时$R_0$中的数据输出到$A$端，$R0out$为$0$时$R_0$中的数据无法输出到$B$端。

上面是**专用数据通路**实现方式，还有另一种连接方式：**CPU内部单总线方式**。

CPU内部单总线方式：将所有寄存器的输入端和输出端都连接到一条公共的通路上。

<img src="https://image.sybblogs.fun/img-common/202401221857848.png" alt="CPU内部单总线方式" style="zoom:33%;" />

假如现在要把$R_0$数据复制到$R_2$中，在$R_2$的输入端$R2in$一个高电平，代表$R_2$输入通路被打通。这样$R_0$数据通过数据总线流入$R_2$寄存器中。

这种内部单总线方式结构简单，容易实现，但数据传输存在较多冲突的现象，性能较低。

冲突现象解释：如果现在用$ADD$指令$R_0,R_2$两个数据相加，这两个寄存器中的数据通过数据总线流入ALU，由于两个寄存器数据都通过一条总线，所以产生数据冲突问题。解决方法是在ALU其中一个输入端增加暂存寄存器。

<img src="https://image.sybblogs.fun/img-common/202401221903295.png" alt="暂存寄存器" style="zoom:33%;" />

这样的话就可以先把$R_0$数据输送到总线上，这样$R_0$数据会先放入暂存寄存器中，之后撤销$R_0$的有效信号，$R_0$对应的三态门信号失效。之后让$R_2$所在的总线导通，$R_2$会通过另一条总线输入到$B$端口。最后运算的结果通过ALU输出端口输送到数据总线上，最后存放在$R_0$寄存器中。

<img src="https://image.sybblogs.fun/img-common/202401221912721.png" alt="运算器内部结构" style="zoom:33%;" />

由于$B$端口输入的电信号可能不稳定，而不稳定信号也会被ALU通过数据总线放回$R_0$。所以还需要在ALU输出端再加入一个暂存寄存器。这样计算结果会先放入暂存寄存器，等信号稳定后，再让暂存寄存器上边的三态门导通，从而将结果通过数据总线放入$R_0$中。

<img src="https://image.sybblogs.fun/img-common/202401221916734.png" alt="运算器内部完整结构" style="zoom:33%;" />

同时为了方便某些复杂运算的实现，ALU输出端的暂存寄存器还可以增加一些。如：移位功能变为移位寄存器，累加功能变为累加寄存器。不过最常用的做法是在数据总线上多增加一个ACC累加寄存器。

<img src="https://image.sybblogs.fun/img-common/202401221919751.png" alt="运算器内部完整结构1" style="zoom:33%;" />

除了以上结构，在寄存器端还会增加一个$PSW$标志寄存器，作用是保留由算术逻辑运算指令或测试指令的结果而建立的各种状态信息，如溢出标志(OP)、符号标志(SF) 、零标志(ZF) 、进位标志(CF)等。$PSW$中的这些标志位参与并决定微操作的形成。

<img src="https://image.sybblogs.fun/img-common/202401221923378.png" alt="运算器内部完整结构2" style="zoom:33%;" />

除了以上寄存器之外还需要有移位器，对运算结果进行移位操作。如二进制乘法就是加法操作$+$移位操作。因此ALU输出端寄存器通常用作移位使用。

<img src="https://image.sybblogs.fun/img-common/202401221925774.png" alt="移位寄存器" style="zoom:33%;" />

最后运算器内部还需要提供计数器，用于控制乘除运算的操作步数。

所以运算器内部结构总结如下：

1. 算术逻辑单元：主要功能是进行算术$/$逻辑运算。
2. 通用寄存器组：如AX、BX、CX、DX、SP等，用于存放操作数(包括源操作数、目的操作数及中间结果)和各种地址信息等。SP是堆栈指针，用于指示栈顶的地址。
3. 暂存寄存器：用于暂存从主存读来的数据，这个数据不能存放在通用寄存器中，否则会破坏其原有内容。
4. 累加寄存器：它是一个通用寄存器，用于暂时存放ALU运算的结果信息，用于实现加法运算。
5. 程序状态字寄存器：保留由算术逻辑运算指令或测试指令的结果而建立的各种状态信息。如：溢出标志(OP)、符号标志(SF)、零标志(ZF) 、进位标志(CF)等。PSW中的这些位参与并决定微操作的形成。
6. 移位器：对运算结果进行移位运算。
7. 计数器：控制乘除运算的操作步数。

<img src="https://image.sybblogs.fun/img-common/202401221925774.png" alt="移位寄存器" style="zoom:33%;" />

### 1.2 控制器内部基本结构

控制器内部总结构：

1. 程序计数器：用于指出下一-条指令在主存中的存放地址。CPU就是根据PC的内容去主存中取指令的。因程序中指令(通常)是顺序执行的，所以PC有自增功能。
2. 指令寄存器：用于保存当前正在执行的那条指令。
3. 指令译码器：仅对操作码字段进行译码，向控制器提供特定的操作信号。
4. 微操作信号发生器:根据IR的内容(指令)、PSW的内容(状态信息)及时序信号，产生控制整个计算机系统所需的各种控制信号，其结构有组合逻辑型和存储逻辑型两种。
5. 时序系统：用于产生各种时序信号，它们都是由统，一时钟(CLOCK)分频得到。
6. 存储器地址寄存器：用于存放所要访问的主存单元的地址。
7. 存储器数据寄存器：用于存放向主存写入的信息或从主存中读出的信息。

第一个重要部件$PC$，其有自增功能，而有的计算机是送给ALU实现自增的。

<img src="https://image.sybblogs.fun/img-common/202401221935688.png" alt="控制器基本结构" style="zoom:33%;" />

之后取出一条指令后会把这个指令放入指令寄存器$IR$当中。一个指令由操作码和地址码构成，地址码可以有多个。地址码指明了操作数的存放地址。所以地址码会输送到内部总线上，而操作码部分会送给控制单元。

<img src="https://image.sybblogs.fun/img-common/202401221938960.png" alt="控制器基本结构1" style="zoom:33%;" />

首先这个指令码会送给指令译码器，输入后这个译码器根据操作会将某一段打通。根据译码器输出信号就可以决定接下来是哪些微操作。所以译码器的输出信号会作为微操作信号发生器的输入信号，用来判断该指令对应的微操作序列应该是什么。

<img src="https://image.sybblogs.fun/img-common/202401221941726.png" alt="控制器基本结构2" style="zoom:33%;" />

由于这些微操作序列执行需要一个先后次序。因此还需要一个时序系统，用于产生时序信号。微操作信号发生器每接受到一个节拍信号就会执行下一个微操作，会发出下一个微操作对应的信号。除了指令信号还需要根据$PSW$标志信息决定接下来的微操作。

<img src="https://image.sybblogs.fun/img-common/202401221945113.png" alt="控制器基本结构3" style="zoom:33%;" />

最后还需要存储器地址寄存器(MAR)，指令的地址码通过给$AdIr_{out}$一个有效的信号打通内部总线，同时给$MAR_{in}$一个有效信号，这样这个地址信息会输入到寄存器MAR当中。之后MAR会将地址信息通过地址总线传送给主存，主存根据信号地址取出数据放回MDR中。

<img src="https://image.sybblogs.fun/img-common/202401221950935.png" alt="控制器基本结构4" style="zoom:33%;" />

上面MDR的$MDR_{in}E$指的是从外部数据总线输入数据的通路是否有效。而$MDR_{in}$指的是从CPU内部的总线输入数据通路是否有效。

<img src="https://image.sybblogs.fun/img-common/202401221953474.png" alt="控制器基本结构5" style="zoom:33%;" />

CPU内部完整结构总结：

<img src="https://image.sybblogs.fun/img-common/202401221954484.png" alt="CPU内部完整结构" style="zoom: 33%;" />

上面橙色寄存器是可用于编程的，灰色是不可以编程使用的。

## 2. 指令执行过程

指令周期：CPU从主存中每取出并执行一条指令所需的全部时间。

<img src="https://image.sybblogs.fun/img-common/202401231341248.png" alt="指令周期" style="zoom:33%;" />

一个指令周期可以被划分为：取值周期和执行周期两个部分。

- 取值周期：取出当前所要执行的指令，并让$PC+1$。之后对指令进行译码，这个译码过程很快。

- 执行周期：执行指令。这个过程有可能需要访存，所以时间差别很大。执行完成后就可以进入下一个指令周期。

指令周期常常用若干机器周期来表示，机器周期又叫CPU周期。一个机器周期又包含若干时钟周期(也称为节拍、T周期或CPU时钟周期，它是CPU操作的**最基本单位**)。

<img src="https://image.sybblogs.fun/img-common/202401231349172.png" alt="定长时钟周期" style="zoom:33%;" />

上图三个周期所需要的时钟周期都为$4(T_0,T_1,T_2,T_3,T_4)$。所以被称为定长机器周期。但事实上对于取指令和执行指令时间很大概率是各不相同的，时间和访问主存有关，通常情况下都是不定长的机器周期。

<img src="https://image.sybblogs.fun/img-common/202401231352377.png" alt="不定长机器周期" style="zoom:33%;" />

### 2.1 CPU处理各种指令的周期

**每个指令周期内机器周期数可以不等，每个机器周期内的节拍数也可以不等**。看下边几个例子可以加深对这句话理解。

- 空指令：CPU在没有任务时候会执行空指令$NOP$。这个周期CPU会先取指令，之后分析指令发现是空指令，所以什么都不用做，接着取下一条指令。

  <img src="https://image.sybblogs.fun/img-common/202401231356775.png" alt="空指令执行周期" style="zoom:33%;" />

  因此空指令周期只做了取指令这一个操作。所以只包含一个机器周期。

- 加法指令：首先CPU要取出指令，并分析。之后经过几步微操作实现执行指令。

  <img src="https://image.sybblogs.fun/img-common/202401231358479.png" alt="加法指令执行周期" style="zoom:33%;" />

  所以这条指令包含了两个机器周期：取值周期和执行周期。并且这两个机器周期长度可能不一样。

- 乘法指令：同样CPU要先取指令，之后经过更长时间的微操作执行指令。

  <img src="https://image.sybblogs.fun/img-common/202401231401806.png" alt="乘法指令" style="zoom:33%;" />

  所以乘法指令执行周期要比加法执行周期长。

- 具有间接寻址的指令：CPU取指令，之后很具形式地址取得有效地址称为间址周期。最后再执行指令操作。

  <img src="https://image.sybblogs.fun/img-common/202401231405280.png" alt="具有间接寻址的指令" style="zoom:33%;" />

- 带有中断周期的指令：很多指令再取值周期、间址周期和执行周期结束后还有一个中断周期。这个时期CPU会检查是否有中断信号要进行处理。

  <img src="https://image.sybblogs.fun/img-common/202401231407890.png" alt="带有中断周期的指令" style="zoom:33%;" />

指令周期执行流程：

<img src="https://image.sybblogs.fun/img-common/202401231409562.png" alt="指令周期执行流程" style="zoom:33%;" />

CPU可以通过触发器判断现在位于哪个周期。上面四个周期可以设置四个触发器。

<img src="https://image.sybblogs.fun/img-common/202401231411852.png" alt="周期触发器" style="zoom:33%;" />

一个触发器可以存放$1$个二进制位。如果处于取值周期，会把$FE$取值$1$，剩下取值都是$0$。之后在哪一个周期，这个周期的触发器就设置为$1$，其余为$0$。

四个工作周期都有CPU访存操作，只是访存的目的不同。取指周期是为了取指令，间址周期是为了取有效地址，执行周期是为了取操作数，中断周期是为了保存程序断点。

### 2.2 四个执行周期执行原理

上面介绍了CPU四个执行周期：取址周期、间址周期，执行周期和中断周期。

#### 取址周期

这个周期执行流程有以下几个阶段：

1. 当前指令地址送至存储器地址寄存器，记做：$(PC)\rightarrow MAR$
2. CU发出控制信号，经控制总线传到主存，这里是读信号，记做：$1\rightarrow R$
3. 将MAR所指主存中的内容经数据总线送入MDR，记做：$M(MAR)\rightarrow MDR$ 
4. 将MDR中的内容(此时是指令)送入IR，记做：$(MDR)\rightarrow IR$
5. CU发出控制信号，形成下一条指令地址，记做：$(PC)+1\rightarrow PC$

<img src="https://image.sybblogs.fun/img-common/202401231427013.png" alt="取址周期" style="zoom:33%;" />

#### 间址周期

间址周期执行流程有以下几个阶段：

1. 将$IR$或MDR种的指令的地址码送入MAR，记做：$Ad(IR)\rightarrow MAR$或$Ad(MDR)\rightarrow MAR$

2. CU发出控制信号，启动主存做读操作，记做：$1\rightarrow R$
3. 将MAR所指主存中的内容经数据总线送入MDR，记做：$M(MAR)\rightarrow MDR$
4. 将有效地址送至指令的地址码字段，记做：$(MDR)\rightarrow Ad(IR)$

<img src="https://image.sybblogs.fun/img-common/202401231434152.png" alt="间址周期" style="zoom:33%;" />

#### 中断周期

执行周期的任务是根据IR中的指令字的操作码和操作数通过ALU操作产生执行结果。不同指令的执行周期操作不同，因此没有统一的数据流向。所以之后做讨论。

所谓中断就是暂停当前任务取完成其他任务。为了能够恢复当前任务，需要保存断点。一般使用堆栈来保存断点，这里用SP表示栈顶地址，假设SP指向栈顶元素，进栈操作是先修改指针，后存入数据。这个保存断点过程具体实现如下：

1. CU控制将SP减$1$，修改后的地址送入MAR记做：$(SP)-1\rightarrow SP$，$(SP)\rightarrow MAR$
本质上是将断点存入某个主存存储单元，假设其地址为$a$，故可记做：$a\rightarrow MAR$
2. CU发出控制信号，启动主存做写操作，记做：$1\rightarrow W$
3. 将断点(PC内容)送入MDR，记做：$(PC)\rightarrow MDR$
4. CU控制将中断服务程序的入口地址(由向量地址形成部件产生)送入PC，即PC指向中断程序第一行。各个中断处理程序的存放地址称为向量地址。记做：$向量地址\rightarrow PC$

<img src="https://image.sybblogs.fun/img-common/202401231506495.png" alt="中断周期" style="zoom:33%;" />

### 2.3 指令执行方案

显然不同指令指令周期长度不同，当希望可以连续执行多条指令的时候有以下几个方案：

- 方案一：单指令周期

  对所有指令都选用相同的执行时间来完成。即将周期短的指令，增加周期，使其和最长指令执行周期对齐。

  指令之间串行执行。指令周期取决于执行时间最长的指令的执行时间。

  缺点：对于那些本来可以在更短时间内完成的指令，要使用这个较长的周期来完成，会降低整个系统的运行速度。

- 方案二：多指令周期

  对不同类型的指令选用不同的执行步骤来完成。

  指令之间串行执行；可选用不同个数的时钟周期来完成不同指令的执行过程。

  缺点：需要更复杂的硬件设计。

- 方案三：流水线方案

  在每一个时钟周期启动一条指令，尽量让多条指令同时运行，但各自处在不同的执行步骤中。

  这种方案指令之间并行执行。这种方案最常用会在后面详细介绍。

## 3. 数据通路

数据通路：数据在功能部件之间传送的路径。

数据通路的基本结构：

1. CPU内部单总线方式：将所有寄存器的输入端和输出端都连接到一条公共的通路上。在同一时刻只允许两个部件之间进行数据交换。

   <img src="https://image.sybblogs.fun/img-common/202401221857848.png" alt="CPU内部单总线方式" style="zoom:33%;" />

2. CPU内部多总线方式：将所有寄存器的输入端和输出端都连接到多条公共的通路上。

3. 专用数据通路方式：由于ALU有两个输入口，所以每个寄存器要提供两个连线，这里的两根连线是泛指，如果一个寄存器$16bit$，那每一边都需要$16$根连线总共$32$根连线连接ALU。

   <img src="https://image.sybblogs.fun/img-common/202401221809890.png" alt="ALU连线通路" style="zoom:33%;" />

下面对单总线方式和专用数据通路方式做详细探讨。

### 3.1 CPU内部单总线方式

无论哪种方式其目的都是为了实现数据流动，这要是数据通路存在本质。一般来说数据流动可以分为三类：

1. 寄存器与寄存器之间的流动
2. 寄存器与主存之间的数据流动
3. 寄存器与ALU算术逻辑单元之间的流动

之前提到过内部总线和系统总线概念：

- 内部总线是指同一部件，如CPU内部连接各寄存器及运算部件之间的总线；
- 系统总线是指同一台计算机系统的各部件，如CPU、内存、通道和各类$I/O$接口间互相连接的总线。

单总线连接方式如下：

<img src="https://image.sybblogs.fun/img-common/202401231546086.png" alt="单总线方式" style="zoom:33%;" />

注意：上图中$in$和$out$信号都与$CU$控制总线相连，CU控制总线给一个对应信号，就可以执行对应的$in/out$操作。

#### 寄存器之间的数据传送

如果将上图PC内容送到MAR中，实现传送操作流程及控制信号为：

1. 首先让CU与$PCout$相连接的信号发出高电平信号，让其有效。这样PC线路数据被打通，其数据输出到内部总线上。记作$PC\rightarrow BUS$。这里的BUS即内部总线。
2. 之后通过CU控制信号将$MARin$打通，在总线上的数据会输送到MAR中。记作$Bus\rightarrow MAR$

标准答题流程：

<img src="https://image.sybblogs.fun/img-common/202401231553883.png" alt="标准答题流程" style="zoom:33%;" />

也可以写为：$(PC)\rightarrow Bus\rightarrow MAR$。有的教材也写作$PC\rightarrow Bug\rightarrow MAR$

其他寄存器之间的数据流通原理类似。先让$out$信号有效留出，再让$in$信号有效输入。

#### 主存与寄存器之间的数据传送

比如IR从主存读取指令，实现传送操作的流程及控制信号为：

<img src="https://image.sybblogs.fun/img-common/202401231623733.png" alt="主存从寄存器中读取信息" style="zoom:33%;" />

<img src="https://image.sybblogs.fun/img-common/202401231628063.png" alt="单总线方式1" style="zoom:33%;" />

执行算术或逻辑运算，比如一条加法指令，微操作序列及控制信号为：

<img src="https://image.sybblogs.fun/img-common/202401231629628.png" alt="加法指令执行过程" style="zoom:33%;" />

<img src="https://image.sybblogs.fun/img-common/202401231629995.png" alt="单总线方式2" style="zoom:33%;" />

上面CU单元通过不同控制信号完成每一次的微操作。上面每一个微操作都至少消耗一个时钟周期。

#### 单总线方式例题

设有如图所示的单总线结构，分析指令ADD (R0), R1的指令流程和控制信号。其中(R0)代表R0寄存器中存放的是形式地址。

<img src="https://image.sybblogs.fun/img-common/202401231658240.png" alt="单总线方式例题" style="zoom:33%;" />

上图中MemR表示主存读信号，MemW表示主存写信号。

操作分三个周期：取址周期、间址周期、执行周期

- 取址周期

  | 时序 |         微操作          |     有效控制信号     |
  | :--: | :---------------------: | :------------------: |
  |  1   |  (PC)$\rightarrow$MAR   |     PCout，MARin     |
  |  2   | M(MAR)$\rightarrow$MDR  | MARout，MemR，MDRinE |
  |  3   |  (MDR)$\rightarrow$IR   |     MDRout，IRin     |
  |  4   |        指令译码         |                      |
  |  5   | (PC)$+1$$\rightarrow$PC |                      |

- 间址周期

  | 时序 |         微操作         |     有效控制信号     |
  | :--: | :--------------------: | :------------------: |
  |  1   |  (R0)$\rightarrow$MAR  |     R0out，MARin     |
  |  2   | M(MAR)$\rightarrow$MDR | MemR，MARout，MDRinE |
  |  3   |  (MDR)$\rightarrow$Y   |     MDRout，Yin      |

  这里的$Y$表示暂存寄存器。

- 执行周期

  | 时序 |          微操作          |            有效控制信号            |
  | :--: | :----------------------: | :--------------------------------: |
  |  1   | (R1)$+$(Y)$\rightarrow$Z | R1out，ALUin，CU向ALU发ADD控制信号 |
  |  2   |   (Z)$\rightarrow$MDR    |            Zout，MDRin             |
  |  3   | (MDR)$\rightarrow$M(MAR) |       MemW，MDRoutE，MARout        |

### 3.2 专用数据通路

在任何两个需要流通数据的部件之间都建立专用的数据通路。

<img src="https://image.sybblogs.fun/img-common/202401231745625.png" alt="专用数据通路" style="zoom:33%;" />

上图中的$C_{n}$指的是控制信号。基于这种方式取出指令周期如下：

- 首先指令在PC中，所以给$C_0$一个控制信号，让PC传入MAR当中。记作$(PC)\rightarrow MAR\quad C_0$有效。
- 控制单元向主存发送读信号。记作$1\rightarrow R$

- 之后主存通过外部数据总线将信息传送给MDR，记作$M(MAR)\rightarrow MDR\quad C_2$有效。
- MDR内存放指令送给IR，记作$(MDR)\rightarrow IR\quad C_3$有效。
- 取指令后$PC+1\rightarrow PC$。
- 之后将指令操作码部分送给CU进行译码。记作$Op(IR)\rightarrow CU\quad C_4$有效。

例题：下图是一个简化了的CPU与主存连接结构示意图(图中省略了所有的多路选择器)。其中有一个累加寄存器(ACC)、一个状态数据寄存器和其他$4$个寄存器：主存地址寄存器(MAR) 、主存数据寄存器(MDR) 、程序寄存器(PC) 和指令寄存器(IR) ，各部件及其之间的连线表示数据通路，箭头表示信息传递方向。

<img src="https://image.sybblogs.fun/img-common/202401231842626.png" alt="专用数据通路例题" style="zoom:33%;" />

1. 写出上图中$a,b,c,d$四个寄存器的名称。

   $d$能自动$+1$，所以是$PC$

   PC输送的是地址，所以送给MAR，故$c$是MAR

   $b$与微操作信号发生器直接连接，所以$b$是指令寄存器$IR$

   只有MDR与主存会发生读$/$写的操作，所以$a$是MDR

   <img src="https://image.sybblogs.fun/img-common/202401231849592.png" alt="专用数据通路例题1" style="zoom:33%;" />

2. 简述图中取指令的数据通路

   $PC\rightarrow MAR$。由于指令地址放在PC中，所以PC数据送给MAR。

   M(MAR)$\rightarrow$MDR

   (MDR)$\rightarrow$IR

   OP(IR)$\rightarrow$微操作发生器。将IR中的指令送给微操作发生器进行解析

   $(PC)+1\rightarrow PC$

3. 简述数据在运算器和主存之间进行存$/$取访问的数据通路。即存$/$取数据放入ACC中。

   设数据地址已经在MAR中

   取：$M(MAR)\rightarrow MDR$

   $(MDR)\rightarrow ALU\rightarrow ACC$

   存：$(ACC)\rightarrow MDR$

   $(MDR)\rightarrow M(MAR)$

4. 简述完成指令LDA X的数据通路(X为主存地址，LDA的功能为(X)$\rightarrow$ACC)

   X$\rightarrow$MAR

   M(MAR)$\rightarrow$MDR

   (MDR)$\rightarrow$ALU$\rightarrow$ACC

5. 简述完成指令ADD Y的数据通路(Y为主存地址，ADD的功能为(ACC)$+$(Y)$\rightarrow$ACC)

   Y$\rightarrow$MAR

   M(MAR)$\rightarrow$MDR

   (MDR)$\rightarrow$ALU，(ACC)$\rightarrow$ALU

   ALU$\rightarrow$ACC

   由于上一题ACC中已经有$X$，所以这里直接放入ALU完成加法操作。

6. 简述完成指令STA Z的数据通路(Z为主存地址，STA的功能为(ACC)$\rightarrow$Z)

   Z$\rightarrow$MAR

   (ACC)$\rightarrow$MDR

   (MDR)$\rightarrow$M(MAR)

## 4. 控制器的设计

通过之前学习知道高级语言编写的代码会翻译成与之对应的指令。而每条指令的执行会被分为四个周期：取址周期($FE=1$)、间址周期($IND=1$)、执行周期($EX=1$)、中断周期($INT=1$)。

<img src="https://image.sybblogs.fun/img-common/202401241411274.png" alt="高级语言指令周期" style="zoom:33%;" />

在一个机器周期内需要通过若干个机器序列来完成这一个周期内需要完成的事情。而每一个机器周期又有若干个时钟周期组成，每个时钟周期又称为节拍。控制单元CU会在每一个节拍内发出一个微命令(信号)，用来完成对应的操作。如：微命令$1$使得$PCout,MARin$有效，从而完成微操作$1(PC)\rightarrow MAR$。

所以微命令和微操作概念是一一对应的。微操作更多是在描述工作要完成什么内容；而微命令是指要完成这个工作所需要发出的控制信号。所以每发出一条微命令就会完成与之对应的一个微操作。并且有的微操作是有可能并行进行的，比如采用专用通路方式，在这种结构下可以完全让多个寄存器之间的数据同时进行并行的流动。因此每个节拍可以完成并行的不冲突的操作。

<img src="https://image.sybblogs.fun/img-common/202401241424381.png" alt="四个周期对应微操作" style="zoom:33%;" />

上图从上到下依次对应四个周期。每一个周期都有三个节拍，在第一个取址周期内第一个节拍$T_0$可以完成两个微操作，也就是让CU同时发出两个微命令，让这两个微操作并行进行。并且可以看到在执行周期和中断周期$T_0$节拍内什么都没做，即这两个周期只需要两个节拍就可以完成工作，但还是有三个节拍，这也就意味着在这个例子中采用了定长机器周期这样一个策略，可以让电路设计更简单。

这个例子有以下特质：

1. 一个节拍内可以并行完成多个"相容的"微操作。即如果两个微操作执行不会相互冲突，不会相互制约，那么就可以把多个微操作安排在一起。这样可以使CU在一个节拍内完成更多的事情。
2. 同一个微操作可能在不同指令的不同阶段被使用。如上图的黄色部分间址周期内的$T_0$部分，微操作$2$在上一个取址周期内$T_0$节拍也使用到。如：$M(MAR)\rightarrow MDR$这个操作在很多周期内都会重复使用到。
3. 不同指令的执行周期所需节拍数各不相同。为了简化设计，选择定长的机器周期，以可能出现的最大节拍数为准(通常以**访存所需节拍数**作为参考)。上面例子中节拍数是$3$。
4. 若实际所需节拍数较少，可将微操作安排在机器周期末尾几个节拍上进行。如上面的执行周期和中断周期。

### 4.1 硬布线控制器设计

综上所述设计控制器核心思想是：根据指令操作码、目前的机器周期、节拍信号、机器状态条件，即可确定现在这个节拍下应该发出哪些"微命令"。

#### 设计思路

硬布线控制器是是控制当中的一种，即用纯硬件的方式设计控制器。

设计思路：

- 首先要将指令寄存器IR的$n$为操作码送到操作码译码器中

  <img src="https://image.sybblogs.fun/img-common/202401241444978.png" alt="硬步线控制器设计1" style="zoom:33%;" />

  控制单元CU通过译码器连线中的哪一根输入信号有效来判断执行指令是哪一条指令。这样CU就得到了**指令操作码**。

- 之后还需要知道执行到哪一个机器周期，因此需要把$FE,IND,EX,INT$这几个触发器对应得周期二进制信息送到CU中。CU可以根据当前触发器哪个值为$1$确定当前处于哪个机器周期。

  <img src="https://image.sybblogs.fun/img-common/202401241449493.png" alt="硬步线控制器设计2" style="zoom:33%;" />

  事实上这四个触发器集成在CU内部。

- 接着还需要让CU判断出当前处于机器周期内的第几个节拍，即要给CU一个节拍信号。

  <img src="https://image.sybblogs.fun/img-common/202401241451690.png" alt="硬步线控制器设计3" style="zoom:33%;" />

  节拍信号是由一个节拍发生器发出的。时钟部件会有规律发出脉冲部件，每个脉冲信号就是一个时钟周期，节拍发生器接收到时钟部件发送的脉冲信号之后，都会选择让$T_0,T_1\cdots$中的某一跟输出线导通。这样CU就可以根据节拍发生器与之相连的哪一根线知道当前处于哪个节拍。之前规定采用定长的机器周期。所以节拍数在每个周期都是固定数量的。并且节拍信号是循环发出的，如现在已经在最后一个节拍$T_m$，接下来再接受下一个脉冲信号又会回到$T_0$，即进入下一个机器周期。

- 最后还需要给CU提供机器状态条件信息。这些状态条件统称为标志，这些标志来自执行单元的反馈信息。如：PSW中的标志位、ACC累加寄存器中的符号位、$I/O$设备、主存等。

  <img src="https://image.sybblogs.fun/img-common/202401241459697.png" alt="硬步线控制器设计4" style="zoom:33%;" />

接着CU可以根据指令操作码、目前的机器周期、节拍信号、机器状态条件，即可确定现在这个节拍下应该发出哪些"微命令"。所以控制单元每个输出的控制信号对应一个微命令，也就是对应一个操作。

<img src="https://image.sybblogs.fun/img-common/202401241503884.png" alt="硬步线控制器设计5" style="zoom:33%;" />

如：要让$C_1$对应微操作$(PC)\rightarrow MAR$，则将其接到$PCout,MARin$上即可。接下来要解决的问题是什么情况下CU会发出对应的命令。

实际上所有指令的取址周期，$T_0$节拍下一定要完成$(PC)\rightarrow MAR$这个操作。所以可知逻辑表达式$C_1=FE·T_0$。之后可以得到这个门电路：

<img src="https://image.sybblogs.fun/img-common/202401241515917.png" alt="硬步线控制器设计6" style="zoom:33%;" />

接着将这个门电路集成在CU中，节拍发生器$T_0$连接与门一段，$FE$触发器连接在另一端。与门输出端连接上$C_1$。这样在$T_0=1\&\&FE=1$时，$C_1$会发出一个高电平信号。即发出$(PC)\rightarrow MAR$微操作所对应的微命令。

所以只要可以写出某个微命令所对应的逻辑表达式，就能确定这个微命令所对应的电路怎么设计。前面$(PC)\rightarrow MAR$这个逻辑表达式很简单可以得到，实际情况下会有很复杂的情况如：$M(MAR)\rightarrow MDR$。

$M(MAR)\rightarrow MDR$对应的微命令逻辑表达式：
$$
FE·T_1+IND·T_1(ADD+STA+LDA+JMP+BAN)+EX·T_1(ADD+LDA)
$$
该逻辑表达式对应的电路：最右边$\ge$是一个或门。

<img src="https://image.sybblogs.fun/img-common/202401241531788.png" alt="逻辑表达式对应的电路" style="zoom:33%;" />

$FE·T_1$：当$FE$与$T_1$进行与操作表示在取址阶段的$T_1$节拍需要进行$M(MAR)\rightarrow MDR$微操作对应的命令。

$EX·T_1(ADD+LDA)$：当$EX=1$表示指令处于执行阶段，$(ADD+LDA)$表示加法或这取数(取到ACC中)指令。如果当前处于加法指令或者取数指令的执行阶段，并且处于$T_1$节拍，就执行对应的$M(MAR)\rightarrow MDR$微操作对应的命令。

#### 设计方式

接下来要探讨的是如何得到与一个微操作所对应的电路，知道这个过程就能知道硬布线控制器如何设计。

其设计步骤可以分为四步：

1. 分析每个阶段的微操作序列(取值、间址、执行、中断四个阶段)。确定哪些指令在什么阶段、在什么条件下会使用到的微操作。
2. 选择CPU的控制方式。假设采用同步控制方式(定长机器周期)，一个机器周期内安排$3$个节拍。
3. 安排微操作时序。如何用$3$个节拍完成整个机器周期内的所有微操作?
4. 电路设计。确定每个微操作命令的逻辑表达式，并用电路实现。

第一步：分析每个阶段的微操作序列

- 取址周期(所有指令都一样)

  $PC\rightarrow MAR$

  $1\rightarrow R$

  ==$M(MAR)\rightarrow MDR$==

  $MDR\rightarrow IR$

  $OP(IR)\rightarrow ID$。$ID$是指令译码器的缩写，其实就是之前的操作码译码器。

  $(PC+1)\rightarrow PC$

- 间址周期(所有的指令都一样)

  $Ad(IR)\rightarrow MAR$

  $1\rightarrow R$

  ==$M(MAR)\rightarrow MDR$==

  $MDR\rightarrow Ad(IR)$。将形式地址替换为有效地址

- 执行周期(各个指令执行各不相同，这里取$四$个有代表性的分析，其他类似)

  1. CLA：clear ACC指令，ACC清零

     $0\rightarrow ACC$

  2. LDA X：取数指令，把X所指内容取到ACC

     $AD(IR)\rightarrow MAAR$

     $1\rightarrow R$

     ==$M(MAR)\rightarrow MDR$==

     $MDR\rightarrow AC$

  3. JMP X：无条件转义指令

     $Ad(IR)\rightarrow PC$

  4. BAN X：条件转义指令，当ACC为负时转移到X

     $A_0·Ad(IR)+\overline{A_0}·(PC)\rightarrow PC$

     $A_0$指的是ACC中的符号位为负，即$1$。

中断周期微操作不再分析，原理类似。

第二步：采用定长机器周期，为$T_0,T_1,T_2$。

第三步：安排微操作时序。将以上指令每个周期安排在三个节拍内完成。

安排微操作时序原则：

1. 微操作的先后顺序不得随意更改。取数之前必须将地址放入$MAR$。
2. 被控对象不同的微操作尽量安排在一个节拍内完成。如：$(PC)\rightarrow MAR,1\rightarrow R$，第一个指令控制对象是$MAR$，第二个指令控制对象是主存。所以这两个指令控制对象不同，可以安排在一个节拍内完成。
3. 占用时间较短的微操作尽量安排在一个节拍内完成，并允许有先后顺序。因为CPU速度很快，因此一个时钟周期内就算两个指令有先后顺序，也可以几乎同时完成。

- 取址周期

  $T_0$：$PC\rightarrow MAR$，$1\rightarrow R$

  $T_1$：$M(MAR)\rightarrow MDR$，$(PC)+1\rightarrow PC$

  $T_2$：$MDR\rightarrow IR$，$OP(IR)\rightarrow ID$

- 间址周期

  $T_0$：$Ad(IR)\rightarrow MAR$，$1\rightarrow R$

  $T_1$：$M(MAR)\rightarrow MDR$

  $T_2$：$MDR\rightarrow Ad(IR)$

  由于$M(MAR)\rightarrow MDR$涉及到访存操作，需要时间较长，所以不能和$MDR\rightarrow Ad(IR)$在一个节拍内完成。

- 执行周期

  1. CLA：ACC清零

     $T_0$

     $T_1$

     $T_2:0\rightarrow ACC$

  2. LDA X：取数指令

     $T_0$：$Ad(IR)\rightarrow MAR$，$1\rightarrow R$

     $T_1$：$M(MAR)\rightarrow MDR$

     $T_2$：$MDR\rightarrow ACC$

  3. JMP X：无条件转移指令

     $T_0$

     $T_1$

     $T_2$：$Ad(IR)\rightarrow PC$

  4. BAN X：条件转移

     $T_0$

     $T_1$

     $T_2$：$A_0·Ad(IR)+\overline{A_0}·(PC)\rightarrow PC$

第四步：电路设计。设计步骤：

1. 列出操作时间表。列出在取指、间址、执行、中断周期，$T_0$、$T_1$、$T_2$节拍内有可能用到的所有微操作。
2. 写出微操作命令的最简表达式。
3. 画出逻辑图

- 列出操作时间表

  取址周期

  <img src="https://image.sybblogs.fun/img-common/202401241642564.png" alt="FE取址阶段" style="zoom:33%;" />

  $I$表示如果当前地址采用间接寻址，CU会把$1\rightarrow IDX$这个触发器当中，接下来会进入间接寻址阶段。而$\overline{I}$表示当前没有间接寻址，此时会把$1\rightarrow EX$，即直接进入执行阶段。

  间址周期

  <img src="https://image.sybblogs.fun/img-common/202401241644902.png" alt="IND间址周期" style="zoom:33%;" />

  $\overline{IND}$表示多级间接寻址。只有当$\overline{IND}=0$才能进入执行阶段$1\rightarrow EX$

  执行周期

  <img src="https://image.sybblogs.fun/img-common/202401241645730.png" alt="EX执行周期" style="zoom:33%;" />

- 写出微操作命令的最简表达式。

  将以上三个周期内使用到$M(MAR)\rightarrow MDR$操作全部罗列

  <img src="https://image.sybblogs.fun/img-common/202401241648649.png" alt="微操作信号综合" style="zoom:33%;" />

  可以得到微操作命令$M(MAR)\rightarrow MDR$的逻辑表达式：
  $$
  FE·T_1+IND·T_1(ADD+STA+LDA+JMP+BAN)+EX·T_1(ADD+LDA)
  $$
  可以化简为：
  $$
  T_1\{FE+IND(ADD+STA+LDA+JMP+BAN)+EX(ADD+LDA)\}
  $$
  当以上逻辑表达式为$1$时，就需要进行$M(MAR)\rightarrow MDR$微操作。

- 画出逻辑图

  <img src="https://image.sybblogs.fun/img-common/202401241531788.png" alt="逻辑表达式对应的电路" style="zoom:33%;" />

设计硬布线控制器步骤总结：

1. 分析每个阶段的微操作序列
2. 选择CPU的控制方式
3. 安排微操作时序
4. 电路设计
   (1)列出操作时间表
   (2)写出微操作命令的最简表达式
   (3)画出逻辑图

硬布线控制器特点：

指令越多，设计和实现就越复杂，因此一般用于RISC(精简指令集系统)。

如果扩充一条新的指令，则控制器的设计就需要大改，因此扩充指令较困难。

由于使用纯硬件实现控制，因此执行速度很快。微操作控制信号由组合逻辑电路即时产生。

### 4.2 微程序控制器的基本原理

用高级语言写的代码会被翻译成一系列对等的指令。而每条指令执行可以被细分为一个个微操作。可以把一个时序之内同时进行的微操作用一个微指令来指令

<img src="https://image.sybblogs.fun/img-common/202401241707925.png" alt="微指令" style="zoom:33%;" />

如上图微指令$a$，可以完成微操作$1,2$。由一整个微指令序列就构成了一个微程序。

所以程序是由指令序列构成的。微程序是由微指令序列组成，每一种指令对应一个微程序。

要注意的是机器指令是对程序执行步骤的描述而微指令是对指令执行步骤的描述。

可以借鉴之前采用"存储程序"的思想，CPU出厂前将所有指令的"微程序"存入"控制器存储器"中。

注意：微命令与微操作一一对应。而微指令中可能包含多个微命令。

另外微程序和机器指令也是一一对应的，一种机器指令会对应一个微程序，而一个微程序有多个指令序列构成。所以可以说机器指令是对微指令功能的封装。

所以微指令格式是：用$n$个bit表示当前微指令所对应的微操作是哪几个；另外还需要$m$bit的顺序控制字段，指明下一条微指令的地址。

<img src="https://image.sybblogs.fun/img-common/202401241718966.png" alt="微指令格式" style="zoom:33%;" />

#### 微程序控制器基本结构

CU控制单元内部引入控制寄存器(CM)。这个CM用于存放各指令对应的微程序，控制存储器可用只读存储器ROM构成，通常在CPU出厂时就把所有微程序写入。每一种机器指令会对应一个微程序，而一个微程序会与一系列微指令序列构成。这些微指令序列在CM中会顺序存放。

<img src="https://image.sybblogs.fun/img-common/202401241743653.png" alt="微指令序列存放" style="zoom:33%;" />

为了指明接下来要执行的微指令存放在什么位置，要引入地址寄存器$CMAR$。别名叫$μPC$，微地址寄存器，接收微地址形成部件送来的微地址，为在CM中读取微指令作准备。

<img src="https://image.sybblogs.fun/img-common/202401241747790.png" alt="CU内部结构" style="zoom:33%;" />

对于CMAR来说，同样也需要将内部地址送给地址译码器。其功能是将地址码转化为存储单元控制信号。

之后从CM中取出一条微指令，也需要放到CMDR中，别名叫μIR，用于存放从CM中取出的微指令，它的位数同微指令字长相等。

还需要一个微地址形成部件，它的作用是产生初始微地址和后继微地址，以保证微指令的连续执行。根据机器指令操作码部分来确定它所对应的微指令序列对应的首地址。

最后需要一个顺序逻辑，因为微指令序列不一定是顺序的执行。如果有中断发生，微指令序列执行顺序会发生变化。

<img src="https://image.sybblogs.fun/img-common/202401241754456.png" alt="CU构成" style="zoom:33%;" />

所以执行一条指令过程是，首先把指令的操作码送给微地址形成部件，用来确定这条指令所对应的微指令序列的起始地址。接着根据顺序逻辑的标志信息确定接下来执行微指令的存放地址，将微指令地址放入CMAR中。之后经过地址译码器译码之后选中CMAR所指向的那条微指令。之后取出这条微指令将其放入CMDR中，而CMDR中包含微指令两个部分信息，第一部分用来描述微指令对应的控制信号，第二部分用于描述接下来要执行的微指令地址，称为下地址。所以执行完这条微指令后，需要把下地址信息送给顺序逻辑，之后顺序逻辑根据标志信息，再决定下一条微指令的存放地址。之后循环。

<img src="https://image.sybblogs.fun/img-common/202401241802227.png" alt="CU执行流程" style="zoom:33%;" />

当前CU会发出什么信号是根据CMDR中的控制字段决定的。如果所有指令的取址周期、间址周期、中断周期所对应的微指令序列都一样，那么可以共享使用。基于这个原因在CM存储器中存储的微指令序列，通常来说取址周期所对应的微程序断只有一份，因为所有机器指令执行在取址阶段要做的微操作都是一样的。所以间址周期和中断周期也都是只存一份。只有执行周期所对应的微程序每个机器指令都是不一样的。

<img src="https://image.sybblogs.fun/img-common/202401241849217.png" alt="微程序控制器的工作原理" style="zoom:33%;" />

分析取数指令LAD X的执行流程：

- 首先进入取址周期

  执行$0,1,2$三个微指令操作码。

  $PC\rightarrow MAR$，$1\rightarrow R$

  $M(MAR)\rightarrow MDR$

  $T_2$：$MDR\rightarrow IR$

  当执行完$2$号地址对应的微指令后，取址周期结束。下地址是$3$也就是要进入间址周期，但是指令的地址码部分会有标志位指明这个地址码是采用直接寻址还是间接寻址。这个寻址特征位被顺序逻辑接收后，如果发现这个指令地址码并不需要间接寻址，那么虽然刚刚微指令的下地址是$3$，但是根据顺序逻辑处理仍会直接跳到执行周期。所以根据指令的操作码通过微地址形成部件的处理之后，微地址形成部件会向顺序逻辑发送信息，现在执行这条指令的执行周期所对应的微指令序列首地址是$13$，所以CMAR中保存$13$这个地址信息，指令会直接进入执行周期。

- 当执行周期执行完毕后，最后一条微指令的下地址是$0$，所以会进入下一条指令的取址周期。但是如果顺序逻辑检测到中断信号，那么接下来执行的微指令地址就不是$0$，而是中断周期内的一系列微指令序列。

<img src="https://image.sybblogs.fun/img-common/202401241906645.png" alt="取数指令执行周期" style="zoom:33%;" />

考试常考点：

之前说过取址周期、间址周期、中断周期都是一样的，所以微程序是公用共享的。故对于**取址周期**来说如果某条指令系统中有$n$条机器指令，则CM中微程序段的个数至少是$n+1$个。

> 因为$n$条指令对应的执行周期微程序序列都不一样，因此需要设计$n$个微程序来分别描述这$n$条指令执行周期要做的事情。另外还需要一个公用的取址周期，所以是$n+1$。z

这里没算间址周期和中断周期是因为一些早期的CPU、物联网设备的CPU可以不提供间接寻址和中断功能，因此这类CPU可以不包含间址周期、中断周期的微程序段。

注意：物理上取指周期、执行周期看起来像是两个微程序，但逻辑上应该把它们看作一个整体。因此，**一条指令对应一个微程序**的说法是正确的。故取址、间址、执行和中断四个周期组成的微程序段看作逻辑上的一个整体，即微程序。

指令周期：从主存取出并执行一条机器指令所需的时间。用于描述指令的执行速度。

微周期(微指令周期)：从控制器存储器取出一条微指令并执行相应微操作所需的时间。用于描述微指令执行速度。

#### 微指令设计

如何根据一条微指令来发出相应的控制信号。通过之前的学习可以知道微命令与微操作是一一对应的，一个微命令对应一根输出线。并且有的微命令是可以并行执行的，因此一条微指令可以包含多个微命令。

引入两个概念：

1. 相容性微命令：可以并行完成的微命令

2. 互斥性微命令：不允许并行完成的微命令。

微指令的格式有三种：水平型微指令、垂直型微指令和混合型微指令。

- 水平型微指令

  一条微指令能定义多个可并行的微命令。

  <img src="https://image.sybblogs.fun/img-common/202401251335169.png" alt="水平型微指令基本格式" style="zoom:33%;" />

  操作控制字段较长，采用这种指令格式会导致指令的条数较少，因为一条指令可以完成多个操作。所以指令条数少，但每个指令较长，整体来看横向发展。

  <img src="https://image.sybblogs.fun/img-common/202401251341091.png" alt="水平型微指令" style="zoom:33%;" />

  优点：微程序短，执行速度快;

  缺点：微指令长，编写微程序较麻烦。

- 垂直型微指令

  一条微指令只能定义一个微命令，由微操作码字段规定具体功能。

  <img src="https://image.sybblogs.fun/img-common/202401251339361.png" alt="垂直型微指令基本格式" style="zoom:33%;" />

  微操作码字段较短，要完成更多同样功能需要更多的指令，因为每条微指令只能完成一个微操作。所以指令条数多，但每个指令较短。

  <img src="https://image.sybblogs.fun/img-common/202401251343253.png" alt="垂直型微指令" style="zoom:33%;" />

  优点：微指令短、简单、规整，便于编写微程序;

  缺点：微程序长，执行速度慢，工作效率低。

- 混合型指令

  在垂直型的基础，上增加一些不太复杂的并行操作。

  微指令较短，仍便于编写;微程序也不长，执行速度加快。

### ==4.3 微指令的编码方式==

重点探讨水平型微指令格式如何设计操作控制字段。即如何用若干个二进制信息表示一系列控制信号。

微指令的编码方式又称为微指令的控制方式，它是指如何对微指令的控制字段进行编码，以形成控制信号。编码的目标是在保证速度的情况下，尽量缩短微指令字长。

#### 直接编码方式

又称为直接控制方式。即在微指令的操作控制字段中，每一位代表一个微操作命令。可以某位为$1$表示该控制信号有效。

<img src="https://image.sybblogs.fun/img-common/202401251352993.png" alt="直接编码" style="zoom:33%;" />

如上图如果像完成$(PC)\rightarrow MAR$和$1\rightarrow R$两个指令，只需要将其对应的控制字段第一位和最后一位为$1$，其他全部为$0$即可。

优点：简单、直观，执行速度快，操作并行性好。

缺点：微指令字长过长，$n$个微命令就要求微指令的操作字段有$n$位，造成控存容量极大。

#### 字段直接编码

将微指令的控制字段分成若干"段"，每段经译码后发出控制信号。

微命令字段分段的原则：

1. 互斥性微命令分在同一段内，相容性微命令分在不同段内。
2. 每个小段中包含的信息位不能太多，否则将增加译码线路的复杂性和译码时间。
3. 一般每个小段还要留出一个状态，表示本字段不发出任何微命令。因此，当某字段的长度为$3$位时，最多只能表示$7$个互斥的微命令，通常用$000$表示不操作。

<img src="https://image.sybblogs.fun/img-common/202401251359365.png" alt="字段直接编码" style="zoom:33%;" />

上图$(PC)\rightarrow MAR$和$1\rightarrow R$这两个微操作是可以并行执行的。所以需要将这两个微操作放到不同的段中，这两个微操作在与之相对应的段中会有一个特定的编码，这个编码经过译码器的编码后就会发出与这两个微操作相对应的控制信号。并且这两个微命令的控制信号是并行发出的。

<img src="https://image.sybblogs.fun/img-common/202401251403332.png" alt="字段直接编码2" style="zoom:33%;" />

上图$(PC)+1\rightarrow PC$与$(PC)\rightarrow MAR$是互斥操作，所以可以放在同一段中，所以对第二个操作$(PC)+1\rightarrow PC$进行一个不一样的编号，如$010$。所以对于这两个操作信号不可能同时由译码器发出。

使用这种编码方式可以有效的将微指令总体长度变短。

例：某计算机的控制器采用微程序控制方式，微指令中的操作控制字段采用字段直接编码法，共有$33$个微命令，构成$5$个互斥类，分别包含$7、3、12、5$和$6$个微命令，则操作控制字段至少有多少位?

第$1$个互斥类有$7$个微命令，要留出$1$个状态表示不操作，所以要有$2^3=8$种不同的状态，故需要$3$个二进制位。依次类推，后面$4$个互斥各需要表示$4,13,6,7$种不同的状态，分别对应$2,4,3,3$个二进制位。所以操作控制字段的总位数为$3+2+4+3+3=15$位。如果采用第一种直接编码方式，则需要$33$个位，所以显然字段直接编码比直接编码方式所需要的指令字段更少。

所以字段直接编码优点：可以缩短微指令字长。缺点：要通过译码电路后再发出微命令，因此比直接编码方式慢。

#### 字段间接编码方式

一个字段的某些微命令需由另一个字段中的某些微命令来解释，由于不是靠字段直接译码发出的微命令，故称为字段间接编码，又称隐式编码。

<img src="https://image.sybblogs.fun/img-common/202401251435132.png" alt="字段间接编码方式" style="zoom:33%;" />

如上图，当字段$2$经过译码器译码之后，并不是直接发出这个字段所对应的控制信号，而是会把这个译码信号输送给下一级的译码器。经过下一级的译码器在经过一次处理后才发出最终的控制信号。

优点:：可进一步缩短微指令字长。

缺点：削弱了微指令的并行控制能力，故通常作为字段直接编码方式的一种辅助手段。

#### 微指令地址形成方式

一个微地址由控制字段和下地址两个部分构成，上面介绍了控制字段的设计，接下来介绍下地址的形成方式。

- ==微指令的下地址字段指出==

  微指令格式中设置一个下地址字段，由微指令的下地址字段直接指出后继微指令的地址，这种方式又称为断定方式。

- 根据机器指令的操作码形成

  当机器指令取至指令寄存器后，微指令的地址由操作码经微地址形成部件形成。

- ==增量计数法==

  类似于$(PC)+1\rightarrow PC$，这里需要将$(CMAR)+1\rightarrow CMAR$，用这种方式可以顺序找到下一条指令。

- 分支转移法

  <img src="https://image.sybblogs.fun/img-common/202401251451087.png" alt="分支转移" style="zoom:33%;" />

  转移方式：指明判别条件；

  转移地址：指明转移成功后的去向。

- 通过测试网络

  即顺序逻辑会接受标志信息，根据这个标志信息再结合当前正在执行微指令的标志信息，来决定接下来应该执行微指令的存放地址。

- 由硬件直接产生微程序入口地址

  第一条微指令地址会由专门硬件产生(用专门的硬件记录取指周期微程序首地址)
  中断周期由硬件产生中断周期微程序首地址(用专门的硬件记录)

例题：某计算机采用微程序控制器，共有$32$条指令，公共的取指令微程序包含$2$条微指令，各指令对应的微程序平均由$4$条微指令组成，采用断定法(下地址字段法)确定下条微指令地址，则微指令中下地址字段的位数至少是多少位?

即总共需要存储多少条微指令，由于每条指令对应的微程序由$4$条微指令组成，并且有$2$条公共的取指令程序。所以总共需要存储
$$
32\times4+2=130条
$$
由于$2^7=128$，不够存放，所以需要$8$个二进制位。即下地址字段的位数至少是$8$位。

### 4.4 微程序控制单元的设计

步骤和硬布线控制器设计思路类似。

设计步骤：

1. 分析每个阶段的微操作序列

2. 写出对应机器指令的微操作命令及节拍安排

   - 写出每个周期所需要的微操作(参照硬布线)

   - 补充微程序控制器特有的微操作：

     取指周期：$Ad (CMDR)\rightarrow CMAR$，$OP(IR)\rightarrow 微地址形成部件\rightarrow CMAR$

     执行周期：$Ad(CMDR)\rightarrow CMAR$

3. 确定微指令格式

   根据微操作个数决定采用何种编码方式，以确定微指令的操作控制字段的位数。
   根据CM中存储的微指令总数，确定微指令的顺序控制字段的位数。
   最后按操作控制字段位数和顺序控制字段位数就可确定微指令字长。

4. 编写微指令码点

   根据操作控制字段每-位代表的微操作命令，编写每- -条微指令的码点。

第一步，以取址周期为例：

取指周期微程序控制器的节拍安排
$T_0$：$PC\rightarrow MAR$

$T_0$：$1\rightarrow R$

$T_1$：$M(MAR)\rightarrow MDR$

$T_1$：$(PC)+1\rightarrow PC$

$T_2$：$MDR\rightarrow IR$

$T_2$：$OP(IR)\rightarrow 微地址形成部件$

硬布线与微程序控制器设计对比：

<img src="https://image.sybblogs.fun/img-common/202401251506353.png" alt="硬布线与微程序控制器设计对比" style="zoom:33%;" />

唯一区别在最后对于硬布线控制器是把指令的操作码部分送给指令译码器ID，之后ID会发出与操作码相对应那根线的选通信号。

而对于微程序控制器来说只需要把操作码送给微地址形成部件，之后由微地址形成部件来指明这条指令在接下来的执行周期所对应的微程序的起始地址。

<img src="https://image.sybblogs.fun/img-common/202401251520655.png" alt="微程序控制单元设计" style="zoom:33%;" />

以上给出的三条操作指令并不完善，还需要考虑如何读出这三条微指令，及如何转入下一个机器周期。

对于取址周期第一条微指令会固定存放在$0$号地址单元，所以第一条微指令是由硬件自动给出的。而之后指令地址会记录在当前指令的下地址中。所以在执行完微指令后还需要穿插一个微操作，将当前微指令的下地址信息送到CMAR中$Ad(CMDR)\rightarrow CMAR$。这样一个微操作执行也需要消耗一个节拍。

另一方面还需要考虑如何转入下一个机器周期。假设取址周期结束后会直接进入执行周期，由于不同指令在执行阶段微程序各不相同，所以在取址阶段的执行结束后，还需要根据当前指令的操作码确定这个指令所对应的微程序的起始地址。因此把指令操作码送给微地址形成部件后，还需要消耗一个节拍，把微地址形成部件指明的地址信息放入CMAR中，即$OP(IR)\rightarrow 微地址形成部件\rightarrow CMAR$。

所完整取指周期微程序控制器的节拍安排如下：

<img src="https://image.sybblogs.fun/img-common/202401251538307.png" alt="微程序控制单元设计3" style="zoom:33%;" />

显然微程序控制器需要$5$个节拍，而硬布线控制器只需要$3$个节拍，所以微程序控制器的速度比硬布线控制器更慢。

第二步：在第一步得到的微操作序列基础上，把可以并行的微操作安排在一个节拍内进行。

之后由于采用微程序控制器，需要加入几个特有的微操作：

- 在取址周期内

  每条微指令结束之后都需要根据当前执行的微指令的下地址信息，来指明接下来要执行的这条微指令的存放地址，即$Ad (CMDR)\rightarrow CMAR$

  另外在取址周期最后一条微指令结束后，还需要指明当前执行的机器指令所对应的执行周期的微程序首地址。即$OP(IR)\rightarrow 微地址形成部件\rightarrow CMAR$

- 执行周期内

  每条微指令结束之后都需要根据当前执行的微指令的下地址信息，来指明接下来要执行的这条微指令的存放地址，即$Ad (CMDR)\rightarrow CMAR$

第三步：需要确定微指令的格式

第四步：编写微指令码点。如采用直接编码方式，可以根据第一步每条微指令所需要执行的微操作信息确定每条微指令的控制码部分哪一位需要为$1$。

接下来把这些微指令序列放到CM中即可。

### 4.5 微程序设计分类与两种设计方式对比

静态微程序设计和动态微程序设计：

- 静态设计

  微程序写入CM中就无需改变，采用ROM

- 动态设计

  通过改变微指令和微程序改变机器指令。

  有利于仿真，采用EPROM。

毫微程序设计：微程序设计用微程序解释机器指令。而毫微程序设计用毫微程序解释微程序。

硬布线与微程序设计比较

| 对比项目 |                         微程序控制器                         |                         硬布线控制器                         |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 工作原理 | 微操作控制信号以微程序的形式<br/>存放在控制存储器中，执行指令时<br/>读出即可 | 微操作控制信号由组合逻辑电路<br/>根据当前的指令码、状态和时序，<br/>即时产生 |
| 执行速度 |                              慢                              |                              快                              |
|  规整性  |                            较规整                            |                         繁琐、不规整                         |
| 应用场合 |                           CISC CPU                           |                           RISC CPU                           |
| 易扩展性 |                          易扩充修改                          |                             困难                             |

## 5. 指令流水线

指令流水线可以对指令的执行过程进行优化。

一条指令的执行过程可以分成多个阶段(或过程)。根据计算机的不同，具体的分法也不同。最简单划分方法是划分为三个阶段：取指阶段、分析阶段、执行阶段。

<img src="https://image.sybblogs.fun/img-common/202401251614153.png" alt="三个阶段" style="zoom:33%;" />

一条指令在不同的阶段所需要使用到的硬件部件是不一样的：

1. 取指阶段：根据PC内容访问主存储器，取出一条指令送到IR中。

2. 分析阶段：对指令操作码进行译码，按照给定的寻址方式和地址字段中的内容形成操作数的有效地址EA，并从有效地址EA中取出操作数。

3. 执行阶段：根据操作码字段，完成指令规定的功能，即把运算结果写到通用寄存器或主存中。

特点是每个阶段用到的硬件不一样。

为了方便分析，设取指、分析、执行$3$个阶段的时间都相等，用$t$表示，按以下几种执行方式分析$n$条指令的执行时间：

- 顺序执行方式

  一条指令三个阶段完成后，才会进入下一个阶段。

  <img src="https://image.sybblogs.fun/img-common/202401251618280.png" alt="顺序执行方式" style="zoom:33%;" />

  总耗时：$T=n\times3t=3nt$。

  传统冯诺依曼机采用顺序执行方式，又称串行执行方式。

  优点：控制简单，硬件代价小。

  缺点：执行指令的速度较慢，在任何时刻，处理机中只有条指令在执行，各功能部件的利用率很低。

引入指令流水线：

- 一次重叠执行方式

  第二条指令第一个阶段和上一条指令的最后一个阶段重叠。

  <img src="https://image.sybblogs.fun/img-common/202401251621464.png" alt="一次重叠执行方式" style="zoom:33%;" />

  总耗时：$T=3t+(n-1)\times2t=(1+2n)t$

  优点：程序的执行时间缩短了$1/3$，各功能部件的利用率明显提高。

  缺点：需要付出硬件上较大开销的代价，控制过程也比顺序执行复杂了。

- 二次重叠执行方式

  <img src="https://image.sybblogs.fun/img-common/202401251624104.png" alt="二次重叠执行方式" style="zoom:33%;" />

  总耗时：$T=3t+(n-1)\times t=(2+n)t$

  与顺序执行方式相比，指令的执行时间缩短近$2/3$。但这是一种理想的指令执行方式，在正常情况下，处理机中同时有$3$条指令在执行。如果分为四个阶段，那么处理机中同时有$4$条指令在执行。

  注：也可以把每条指令的执行过程分成$4$个或$5$个阶段，分成$5$个阶段是比较常见的做法。

上图是指令执行过程图。

<img src="https://image.sybblogs.fun/img-common/202401251628389.png" alt="指令执行过程图" style="zoom:33%;" />

横坐标是指令执行时间$t$，纵坐标是指令序列。这种图主要用于分析旨令执行过程以及影响流水线的因素。

还有另一种描述指令执行过程的图，时空图：

<img src="https://image.sybblogs.fun/img-common/202401251630461.png" alt="时空图" style="zoom:33%;" />

横坐标表示时间$t$，纵坐标表示不同的执行阶段。这种图主要用于分析流水线的性能。

大体上可以用**吞吐率、加速比、效率**三个指标评价流水线的性能。

- 吞吐率是指在单位时间内流水线所完成的任务数量，或是输出结果的数量。

  对于指令流水线来说，吞吐率就是单位时间内能完成多少条指令。

  设指令任务数为$n$，处理完成$n$个任务所用的时间为$T_k$，则计算流水线吞吐率(TP) 的最基本的公式为：
  $$
  TP=\frac{n}{T_k}
  $$
  理想情况下，流水线的时空图如下：

  <img src="https://image.sybblogs.fun/img-common/202401251638319.png" alt="流水线时空图" style="zoom:33%;" />

  一条指令执行$k$个阶段总耗时就是$k·\Delta t$。从$k\Delta t$开始之后每隔$\Delta t$时间就会有一条指令结束，所以后序的$n-1$条指令就需要花$(n-1)\Delta t$执行。所以$n$条指令的执行时间就是$T_k=(k+n-1)\Delta t$。故流水线吞吐率为：
  $$
  TP=\frac{n}{(k+n-1)\Delta t}
  $$
  当连续输入的任务$n\rightarrow \infty$时，得最大吞吐率为$TP_{max}=\frac{1}{\Delta t}$。

  注意：一条指令的执行分为$k$个阶段，每个阶段耗时$\Delta t$，一般取$\Delta t=$一个时钟周期。

  这里还需要补充装入时间和排空时间的概念：

  <img src="https://image.sybblogs.fun/img-common/202401251649976.png" alt="装入时间和排空时间" style="zoom:33%;" />

  装入时间：第一条指令从取指一直到结束所需要的时间。

  排空时间：最后一条指令从执行到结束所需要的时间。

- 加速比：完成同样一批任务， 不使用流水线所用的时间与使用流水线所用的时间之比。

  设$T_0$表示不使用流水线时的执行时间，即顺序执行所用的时间；$T_k$表示使用流水线时的执行时间。则计算流水线加速比$(S)$的基本公式为：
  $$
  S=\frac{T_0}{T_k}
  $$
  理想情况下，流水线的时空图如下：

  <img src="https://image.sybblogs.fun/img-common/202401251638319.png" alt="流水线时空图" style="zoom:33%;" />

  单独完成一个任务耗时为$k\Delta t$，则顺序完成$n$个任务耗时$T_0=nk\Delta t$。实际加速比是
  $$
  S=\frac{kn\Delta t}{(k+n-1)\Delta t}=\frac{kn}{k+n-1}
  $$
  当连续输入的任务$n\rightarrow\infty$时，最大加速比为$S_{max}=k$。

- 效率：流水线的设备利用率称为流水线的效率。

  设备利用率是硬件设备处于忙碌时间占总时间比例。在时空图上，流水线的效率定义为完成$n$个任务占用的时空区有效面积与$n$个任务所用的时间与$k$个流水段所围成的时空区总面积之比。

  <img src="https://image.sybblogs.fun/img-common/202401251707758.png" alt="效率指标" style="zoom:33%;" />
  $$
  \frac{红框面积}{蓝框面积}
  $$
  流水线效率$(E)$的一般公式为
  $$
  E=\frac{n个任务占用k时空区域有效面接}{n个任务所用的时间与k个流水段所围成的时空区总面积}=\frac{T_0}{kT_k}
  $$
  $T_k$指的是整体时间消耗，$k$是纵坐标的高，即分为$k$个阶段。

  当连续输入的任务$n\rightarrow\infty$时，最高效率为$E_{max}=1$。即硬件几乎随时都在忙碌。所以引入流水线后硬件利用率大大提升。

### 5.1 影响指令流水线的因素

上面介绍指令流水线的时，各个阶段都是理想情况，这些导致不完美因素就是要探讨的内容。

为了方便讨论先引入五段式指令流水线：<a id="5-5.1-1"></a>

<img src="https://image.sybblogs.fun/img-common/202401251728183.png" alt="五段式指令流水线" style="zoom:33%;" />

即一条指令执行分为$IF,ID,EX,M,WB$五个阶段。

- IF阶段：指的式取指令阶段，控制器内部会有一个触发器叫IF。
- ID阶段：指令译码阶段
- EX阶段：指令执行阶段
- M阶段：需要进行访存阶段
- WB阶段：把最终运算结果写回到通用寄存器组

这种五段式指令流水线是考试最常考结构，这种流水线被称为$MIPS$架构所提出的指令流水线，是世界上第一个精简指令集(RISC)系统。

总之在MIPS架构下一条指令执行会被划分为五个阶段，有的指令可能会跳过某些阶段(如访存阶段)。然而为了方便指令流水线安排，所有指令都会安排为五个这样的机器周期。所以在MIPS架构下一定都是五个机器周期。

另一个方面每个周期花费时间不一样。

<img src="https://image.sybblogs.fun/img-common/202401251736782.png" alt="五段式指令流水线耗时" style="zoom:33%;" />

各个部件耗时假设为上图所示时间。为方便流水线的设计，将每个阶段的耗时取成一样，以最长耗时为准。即此处应将机器周期设置为$100ns$。所以在MIPS架构下包含的周期数相同都是五个机器周期，并且每个机器周期长度都相同，这样可以方便安排指令流水线。

现在产生一个问题，如上图中EX阶段应该是在$200ns$时，才能获得需要的数据。但由于前面的ID阶段实际只需要的$80ns$，所以为了让第三阶段EX能赶在$200ns$时候流出，就需要在各个阶段之间添加暂存寄存器。

<img src="https://image.sybblogs.fun/img-common/202401251751453.png" alt="五段式指令流水线耗时2" style="zoom:33%;" />

上面蓝色方框的部件就是暂存寄存器其称为缓冲寄存器，流水线每一个功能段部件后面都要有一个缓冲寄存器，或称为锁存器，其作用是保存本流水段的执行结果，提供给下一流水段使用。

另外需要注意的是上图CPU中的Cache分为两个模块Instruction Cache(存放指令)和Data Cache(存放数据)。指令和数据用两个独立的Cache模块存放是很有意义的，可以使第一阶段和第四阶段所需要使用的硬件部件可以并行工作。

上图含义是：取指阶段根据PC所指向的位置去Instruction Cache中取出数据，取出的数据放入锁存器中。接着进入第二指令译码阶段，这个阶段除了完成指令译码的工作外，还会完成取数的工作，取数指的是将这条指令所需要的操作数从通用寄存器中取出放入锁存器$A,B$中。接着第三个执行阶段需要用算术逻辑单元ALU处理前一个阶段取出的操作数$A,B$。上图中第二阶段还有一个锁存器$Imm$，是用来存放立即数的。第三个阶段ALU计算后会将输出的结果放到锁存器当中，这个运算结果可能会写入主存或者直接写入寄存器。如果直接写入寄存器第五个阶段写回阶段会将运算结果写回到通用寄存器中。

第二个阶段有可能对某个通用寄存器进行读操作，最后一个阶段有可能会把某个数据写回到通用寄存器。这两个阶段对寄存器的读和写两个操作可能造成一些问题，即影响流水线的因素。

因素可以分为三类：

1. 结构相关(资源冲突)

2. 数据相关(数据冲突)

3. 控制相关(控制冲突)

#### 结构相关因素

又叫资源冲突。由于多条指令在同一时刻争用同一资源而形成的冲突称为结构相关。

<img src="https://image.sybblogs.fun/img-common/202401251906945.png" alt="结构相关" style="zoom:33%;" />

上图$Load$指令在第四个阶段读取主存会和$Instr3$第一阶段取指阶段读取主存发生冲突。同样第一条指令第五个阶段会对某个寄存器写回操作，而$Instr3$指令的第二个阶段读是取寄存器，如果两个指令访问是一个寄存器就会产生冲突。

解决方法：

1. 后一相关指令暂停一周期

2. 资源重复配置：数据存储器$+$指令存储器

   即如果将指令和数据分别放到两个不同的存储器中，那么第一阶段取指阶段和第四个阶段访存阶段所需要访问的寄存器一定是不相同的。

#### 数据相关

又叫数据冲突。数据相关指在一个程序中，存在必须等前一条指令执行完才能执行后一条指令的情况，则这两条指令即为数据相关。

<img src="https://image.sybblogs.fun/img-common/202401251918722.png" alt="数据相关" style="zoom:33%;" />

上图第一条执行一个加法操作，将$r2+r3$的结果放回$r1$。后面四个操作分别是减法、与、或、异或操作。可以观察到第二三四条指令会用到第一条指令中$r1$内存放的数据，所以必须要等到第一条指令执行完后面的才能执行，这就是同步问题，必须保证两个工作一前一后地完成。上面第二三四条指令都在第一条指令没有完成前先读取$r1$中地数据，所以会失败。而最后一条指令在第一条指令完成后进行，所以不会失败。

解决方法：

1. 把遇到数据相关的指令及其后续指令都暂停一至几个时钟周期，直到数据相关问题消失后再继续执行。可分为硬件阻塞(stall)和软插
   入"NOP"两种方法。

   采用硬件阻塞：

   <img src="https://image.sybblogs.fun/img-common/202401251928323.png" alt="数据冲突解决方法" style="zoom:33%;" />

   如果两个指令之间存在数据冲突使用硬件阻塞方式，硬件系统会添加如上图所示地"气泡"。将第二条指令执行时间往后拖三个节拍。此时后面指令就不会造成数据冲突。

   同时也可以用软件NOP指令地方式解决。

   <img src="https://image.sybblogs.fun/img-common/202401251930520.png" alt="数据冲突解决方法2" style="zoom:33%;" />

   执行指令时，编译器发现两个指令之间会有数据冲突关系，那么编译器会在这两条指令中间插入三条空指令。每一个空指令的执行也会经过五个周期。之后的指令就不会造成数据冲突问题。

2. 数据旁路技术

   又叫做转发机制。其大致思路是在第一条指令ALU进行加法运算结果就已经出来了，此时会连出一个数据旁路，让结果直接送回ALU的其中一个输入端，作为下一条指令的输入。这样就不需要等待上一条指令的写回操作。

   <img src="https://image.sybblogs.fun/img-common/202401251935702.png" alt="数据冲突解决方法3" style="zoom:33%;" />

3. 编译优化

   可以通过编译器调整指令顺序来解决数据相关。

   第一条指令结果会被后面指令使用到，如果第五条指令的后面还有其他指令，而这些其他指令又不需要前面几条指令的运算结果，此时就可以将后面几条指令安排在第一条指令之后运行。这样当第二个指令执行时，系统其实已经将第一条指令五个周期全部执行完毕，所以就不会产生数据冲突了。

#### 控制相关

又叫控制冲突。当流水线遇到转移指令和其他改变PC值的指令而造成断流时，会引起控制相关。

<img src="https://image.sybblogs.fun/img-common/202401251943726.png" alt="控制相关" style="zoom:33%;" />

假如现在要执行的是条件转移指令，这条指令存放在上图地址为$12$的位置，下一条指令是$16$位置。但是现在由于条件转移指令生效，此时跳转到地址为$1000$的地方，即$PC\rightarrow1000$。这样前面三条指令，即地址$16,20,24$的指令是不应该执行的，这就是控制相关问题。出来转移类指令会造成断流，CALL(函数调用)、函数返回、中断程序等都会造成程序的断流，都会产生控制相关的问题。

解决方法：

1. 转移指令分支预测。与两种预测方式：简单预测(永远猜true或false)、动态预测(根据历史情况动态调整)。

2. 预取转移成功和不成功两个控制流方向上的目标指令

   由于条件转移指令，有可能导致程序执行流往两个方向走，那么将两个方向所用到的指令都预取出来。采用这种方法可能会改变硬件，如多增加两个寄存器等。

3. 加快和提前形成条件码。

4. 提高转移方向的猜准率

   是对第一种方法优化。

### 5.2 指令流水线的分类

根据流水线使用的级别的不同，流水线可分为部件功能级流水线、处理机级流水线和处理机间流水线。

- 部件功能级流水就是将复杂的算术逻辑运算组成流水线工作方式。例如，可将浮点加法操作分成求阶差、对阶、尾数相加以及结果规格化等$4$个子过程。

  指令每个阶段所用到的部件不一样，部件级的流水线是把某一阶段用到的功能部件再进一步的细分。如果连续多个同样功能，细分部件可以流水线处理这多个同样功能。

- 处理机级流水是把一条指令解释过程分成多个子过程，如前面提到的取指、译码、执行、访存及写回$5$个子过程。

- 处理机间流水是一种宏流水， 其中每一个处理机完成某一专门任务， 各个处理机所得到的结果需存放在与下一个处理机所共享的存储器中。

  让多个CPU，分任务处理。

按流水线可以完成的功能，流水线可分为单功能流水线和多功能流水线。

- 单功能流水线是指只能实现一种固定的专门功能的流水线。
- 多功能流水线指通过各段间的不同连接方式可以同时或不同时地实现多种功能的流水线。如指令流水线。

按同一时间内各段之间的连接方式，流水线可分为静态流水线和动态流水线。

- 静态流水线指在同一时间内，流水线的各段只能按同一种功能的连接方式工作。
- 动态流水线指在同一时间内，当某些段正在实现某种运算时，另-些段却正在进行另一种运算。这样对提高流水线的效率很有好处，但会使流水线控制变得很复杂。

按流水线的各个功能段之间是否有反馈信号，流水线可分为线性流水线与非线性流水线。

- 线性流水线中，从输入到输出，每个功能段只允许经过一次，不存在反馈回路。

- 非线性流水线存在反馈回路，从输入到输出过程中，某些功能段将数次通过流水线，这种流水线适合进行线性递归的运算。

  如一个ALU计算乘法，但ALU本身不支持乘法，所以只能进行多次加法，并且运算输出端会直接连接到另一个输入端。

### 5.3 流水线的多发技术

1. 超标量技术

   每个时钟周期内可并发多条独立指令，即同一时刻同时执行多条指令，是一种空分技术。要想不出现冲突问题，就要配置多个功能部件。并且不能调整指令的执行顺序。

   <img src="C:\Users\Acid\OneDrive\图片\本机照片\408\计算机组成原理\超标量技术.png" alt="超标量技术" style="zoom:33%;" />

   通过编译优化技术，把可并行执行的指令搭配起来。

   由于指令的排列是由编译器确定的，因此编译器在得到编译序列的时候要考虑到哪些指令可以并行执行。可以将其搭配在一起。因此对编译优化要求很高。

2. 超流水技术

   在一个机器周期内再分段。一个机器周期内一个功能部件使用多次，是一种时分复用技术。

   <img src="https://image.sybblogs.fun/img-common/202401261345996.png" alt="超流水技术" style="zoom:33%;" />

   同样不能调制指令的执行顺序。要靠编译程序解决优化问题。上图将每一个机器周期又分为三段，所以速度上提升$3$倍。

3. 超长指令字技术

   由编译程序挖掘出指令间潜在的并行性，将多条能并行操作的指令组合成一条超长指令，具有多个操作码字段的超长指令字(可达几百位)

   <img src="https://image.sybblogs.fun/img-common/202401261348863.png" alt="超长指令字" style="zoom:33%;" />

   显然多种操作想要同时进行就必须提供多个相互独立的部件。

### ==5.4 五段式指令流水线==

前面<a href="#5-5.1-1">影响指令流水线的因素</a>介绍过五段式指令流水线基本概念。

这里会介绍常见五类指令：运算类指令、LOAD指令、STORE指令、条件转移指令、无条件转移指令详细分析这五类指令如何根据五个功能段完成相应的工作。

#### 运算类指令

运算类指令在不同阶段工作：

<img src="https://image.sybblogs.fun/img-common/202401251736782.png" alt="五段式指令流水线耗时" style="zoom:33%;" />

指令举例：

|             功能             |  汇编格式   |          具体描述          |
| :--------------------------: | :---------: | :------------------------: |
|   加法指令(两个寄存器相加)   |  ADD Rs,Rd  | (Rs)$+$(Rd)$\rightarrow$Rd |
| 加法指令(寄存器与立即数相加) | ADD #996,Rd | 996$+$(Rd)$\rightarrow$Rd  |
|         算术左移指令         |   SHL Rd    |  (Rd)$<<<2\rightarrow$Rd   |

上面指令在五个阶段执行如下：

- 取指阶段(IF)

  根据PC从指令Cache中取指令至IF段的锁存器中

- 译码阶段(ID)

  先对指令操作码进行译码。还需要将指令所用到的操作数取到ID段的锁存器中。这一阶段有三个锁存器$A,B,Imm$，其中$Imm$是存放立即数的。

- 执行阶段(EX)

  ALU算术逻辑单元根据上个阶段得到得操作数进行运算。运算结果放入EX阶段锁存器中。

- 访存(M)

  在精简系统指令集(RISC)中，运算阶段不需要进行访存，即在这一阶段是空阶段。但是时间仍然需要消耗。

- 写回阶段(WB)

  将执行阶段锁存器中的值放到第四阶段锁存器中，写回阶段会将锁存器中的内容写回到控制器中。

#### LOAD指令

|                功能                |    汇编格式     |          具体描述           |
| :--------------------------------: | :-------------: | :-------------------------: |
| 将指定地址中的数据放到某个寄存器中 | LOAD Rd,996(Rs) | (996$+$(Rs))$\rightarrow$Rd |

上面指令在五个阶段执行如下：

- 取指阶段(IF)

  根据PC从指令Cache中取指令至IF段的锁存器中

- 译码阶段(ID)

  将$RS$基址寄存器中的值放入锁存器$A$中，同时将偏移量的值放到$Imm$锁存器中

- 执行阶段(EX)

  将偏移量和基址相加，相加后的结果放入EX段的锁存器中，锁存器中的值就是有效地址EA。

- 访存阶段(M)

  根据刚才锁存器中的有效地址EA从数据Cache中取数并放入访存阶段的锁存器中

- 写回阶段(WB)

  将上一阶段锁存器中的值写回到目的寄存器Rd中。

为了保证流水线的流畅工作，通常访问主存时候，大概率都能在Cache中找到想要的数据。

通常在RISC处理器只有==取数指令LOAD==和==存数指令STORE==才能访问主存。

#### STORE指令

|           功能           |     汇编格式     |          具体描述           |
| :----------------------: | :--------------: | :-------------------------: |
| 寄存中的值存放会回主存中 | STORE Rs,996(Rd) | Rs$\rightarrow$(996$+$(Rd)) |

上面指令在五个阶段执行如下：

- 取指阶段(IF)

  根据PC从指令Cache中取指令至IF段的锁存器中

- 译码阶段(ID)

  将基址寄存器的值放到锁存器$A$，将偏移量的值放到$Imm$锁存器中。将要存放的数放到$B$锁存器中

- 执行阶段(EX)

  根据基地址和偏移量计算出有效地址EA，将其放到当前阶段锁存器中。另外还需要将要存放的数即上一阶段$B$锁存器中的值转存到当前阶段锁存器$Store$中。

- 访存阶段(M)

  根据有效地址EA将被存的数据放到数据Cache中。随后Cache回同步到主存。

- 写回阶段(WB)

  空阶段

#### 条件转移指令

|              功能              |     汇编格式      |                           具体描述                           |
| :----------------------------: | :---------------: | :----------------------------------------------------------: |
| 两个寄存器值相等就需要进行转移 | beq Rs,Rt,#偏移量 | 若(Rs)$==$(Rt)，则(PC)$+$指令字长$+$(偏移量$\times$指令字长)$\rightarrow$PC<br>否则(PC)$+$指令字长$\rightarrow$PC |
|  两个寄存器值不相等就需要转移  | bne Rs,Rt,#偏移量 | 若(Rs)$!=$(Rt)，则(PC)$+$指令字长$+$(偏移量$\times$指令字长)$\rightarrow$PC<br/>否则(PC)$+$指令字长$\rightarrow$PC |

上面指令在五个阶段执行如下：

- 取指阶段(IF)

  根据PC从指令Cache中取指令至IF段的锁存器中

- 译码阶段(ID)

  进行比较的两个数放入锁存器$A,B$中，偏移量放入$Imm$锁存器中。

- 执行阶段(EX)

  通过ALU计算将比较结果放入输出端锁存器中

- 访存阶段(M)

  将目标PC值写回PC

  很多教材把写回PC的功能段称为"WrPC段"其耗时比M段更短，可安排在M段时间内完成。

- 写回阶段(WB)

  空阶段。这一阶段通常是将值写回寄存器。所以修改PC值不会在这里写回。

#### 无条件转移指令

|                功能                |       汇编格式        |                         具体描述                          |
| :--------------------------------: | :-------------------: | :-------------------------------------------------------: |
| 根据下一条指令的位置转移到指定位置 | jmp #偏移量(补码表示) | (PC)$+$指令字长$+$(偏移量$\times$指令字长)$\rightarrow$PC |

上面指令在五个阶段执行如下：

- 取指阶段(IF)

  根据PC从指令Cache中取指令至IF段的锁存器中

- 译码阶段(ID)

  将偏移量放入$Imm$锁存器中

- 执行阶段(EX)

  这一阶段用不到ALU算术逻辑单元。而是回直接根据偏移量将目标的PC值直接写回到PC寄存器中。

  "WrPC段"耗时比EX段更短，可安排在EX段时间内完成。WrPC段越早完成，就越能避免控制冲突。当然也有的地方会在WB段时间内才修改PC的值。

- 访存阶段(M)

  空阶段

- 写回阶段(WB)

  空阶段

例题：假设某指令流水线采用"按序发射，按序完成"方式，没有采用转发技术处理数据相关，并且同一寄存器的读和写操作不能在同一个时钟周期内进行。若高级语言程序中某赋值语句为$x=a+b$，$x、a$和$b$均为$int$型变量，它们的存储单元地址分别表示为$[x]、[a]和[b]$。该语句对应的指令序列及其在指令流中的执行过程如下图所示。

<img src="https://image.sybblogs.fun/img-common/202401261549893.png" alt="五段式指令例题" style="zoom:33%;" />

则这$4$条指令执行过程中$I3$的$ID$段和$I4$的$IF$段被阻塞的原因各是什么

<img src="https://image.sybblogs.fun/img-common/202401261550938.png" alt="五段式指令例题2" style="zoom:33%;" />

> 答案：$I3$与$I1$和$I2$存在数据相关；所以要在$I2$取数指令完成后才能进行编码阶段(ID)。
>
> $I4$的$IF$段必须在$I3$进入ID段后才能开始，否则会覆盖$IF$段锁存器的内容。

## 6. 多处理器系统

### 6.1 SISD、SIMD、MIMD的基本概念

基于指令流的数量和数据流的数量，对计算机体系结构分为SISD、SIMD、MISD和MIMD四类。常规的单处理器属于SISD,而常规的多处理器属于MIMD。

1. 单指令流单数据流(SISD)结构

   SISD是传统的串行计算机结构，这种计算机通常仅包含一个处理器和一个存储器，处理器在一段时间内仅执行一条指令，按指令流规定的顺序串行执行指令流中的若干条指令。为了提高速度，有些SISD计算机采用流水线的方式，因此，SISD 处理器有时会设置多个功能部件，并采用多模块交叉方式组织存储器。前面介绍的内容多属于SISD结构。

   所以其特点是各指令序列只能并发、不能并行，每条指令处理一两个数据。

   <img src="https://image.sybblogs.fun/img-common/202401261559252.png" alt="SISD" style="zoom:33%;" />

   这总系统不支持数据级并行技术。即在同一时刻只能处理一两个特定数据，不可能并行处理很多数据。

   若要提升效率可以引入指令流水线，并且需设置多个功能部件，采用多模块交叉存储器。

2. 单指令流多数据流(SIMD)结构

   SIMD是指一个指令流同时对多个数据流进行处理，一般称为数据级并行技术。这种结构的计算机通常由一个指令控制部件、多个处理单元组成。每个处理单元虽然都执行的是同一条指令，但每个单元都有自己的地址寄存器，这样每个单元都有不同的数据地址，因此，不同处理单元执行的同一条指令所处理的数据是不同的。一个顺序应用程序编译后，可能按SISD组织并运行于串行硬件上，也可能按SIMD组织并运行于并行硬件上。

   SIMD在使用for 循环处理数组时最有效，比如，一条分别对$16$对数据进行运算的SIMD指令如果在$16$个ALU中同时运算，则仅需一次运算时间就能完成运算。SIMD在使用case或switch语句时效率最低，此时每个执行单元必须根据不同的数据执行不同的操作。

   其特点是各指令序列只能并发、不能并行，但每条指令可同时处理很多个具有相同特征的数据。

   <img src="https://image.sybblogs.fun/img-common/202401261609639.png" alt="SIMD" style="zoom: 33%;" />

   该系统是一种数据级的并行技术。

3. 多指令流单数据流(MISD)结构

   MISD是指同时执行多条指令，处理同一个数据，实际上不存在这样的计算机。

4. 多指令流多数据流(MIMD)结构

   其特点是各指令序列并行执行，分别处理多个不同的数据。是一种线程级并行(每个内核可以运行各自的进程，多个线程并行执行)、甚至是线程级以上并行(进程级并行)技术。

   进一步分类可以分为：多处理器系统(共享内存多处理器)和多计算机系统

   - 多处理器系统

     其特征是各个处理器之间，可以通过$LOAD/STORE$指令，访问同一个主存储器，可以通过主存相互传送数据。

     <img src="https://image.sybblogs.fun/img-common/202401261616991.png" alt="MIMD" style="zoom:33%;" />

     硬件之间多个处理器共享单一的物理地址空间。

   - 多计算机系统

     各个计算机之间主存是独立的，不能通过$LOAD/STORE$指令直接访问对方的存储器，只能通过"消息传递"相互传送数据。

     <img src="https://image.sybblogs.fun/img-common/202401261620446.png" alt="MIMD2" style="zoom: 33%;" />

     每台计算机拥有各自的私有存储器，物理地址空间相互独立。

5. 向量处理机(SIMD思想的进阶应用)

   其特点是条指令的处理对象是"向量"。擅长对向量型数据并行计算、浮点数运算，常被用于超级计算机中，处理科学研究中巨大运算量。

   <img src="https://image.sybblogs.fun/img-common/202401261626018.png" alt="向量处理器" style="zoom:33%;" />

   其硬件在成采用多个处理单元，多组"向量寄存器"。主存储器应采用"多个端口同时读取"的交叉多模块存储器。主存储器大小限定了机器的解题规模，因此要有大容量的、集中式的主存储器。

总结：

<img src="https://image.sybblogs.fun/img-common/202401261630762.png" alt="总结" style="zoom:33%;" />

<img src="https://image.sybblogs.fun/img-common/202401261631784.png" alt="总结2" style="zoom:33%;" />

### 6.2 硬件多线程概念

先来看一下不支持多线程的普通处理器：

<img src="https://image.sybblogs.fun/img-common/202401261640317.png" alt="不支持硬件多线程处理器" style="zoom:33%;" />

这个处理器只包含一个同寄存器组和一个PC程序计数器，这就意味着在同一时间段内，在这个处理器当中只可能运行一段程序。如果现在两个线程的代码需要同时运行，那么对于线程$A$，PC指向该线程，现在要切换到线程$B$由于线程$B$与线程$A$指令代码都不一样，同时线程$B$也有可能用到寄存器，可能回覆盖掉线程$A$之前的运算结果。所以当从线程$A$切换到线程$B$时，需要将通用寄存器的值和PC值全部放到主存中，这样当切换回线程$A$时，才可能将线程$A$的信息进行恢复。这个保存和恢复过程给线程切换带来了不小的代价。

再看可以支持硬件多线程的处理器：

<img src="https://image.sybblogs.fun/img-common/202401261645493.png" alt="支持硬件多线程的处理器" style="zoom:33%;" />

可以看到处理器中设置两个线程寄存器组，这样就可以把线程$A$和线程$B$的同时存储，这一切换时候就不需要把内容数据保存到主存中。

接着看三种硬件多线程实现方式：

|     功能     |                    细粒度多线程                    |                         粗粒度多线程                         |            同时多线程(SMT)             |
| :----------: | :------------------------------------------------: | :----------------------------------------------------------: | :------------------------------------: |
|   指令发射   | 轮流发射各线程的指令<br>(每个时钟周期发射一个线程) | 连续几个时钟周期，都发射同一线程的指令序列<br>当流水阻塞时，切换另一个线程 | 一个时钟周期内，同时发射多个线程的指令 |
| 线程切换频率 |              每个时钟周期切换一次线程              |                只有流水线阻塞时才切换一次线程                |                  NULL                  |
| 线程切换代价 |                         低                         |                      高，需要重载流水线                      |                  NULL                  |
|    并行性    |              指令级并行，线程间不并行              |                   指令级并行，线程间不并行                   |         指令级并行，线程级并行         |

# 六. 总线

总线常常分为：地址总线、数据总线和控制总线。

<img src="https://image.sybblogs.fun/img-common/202401261720281.png" alt="总线" style="zoom:33%;" />

地址总线可以给硬件发送地址信息。数据总线可以传输数据。控制总线可以给部件发送控制信号。

一个总线可以并行传递很多数据是因为每个总线中可能包含多根信号线。

<img src="https://image.sybblogs.fun/img-common/202401261723000.png" alt="数据总线结构图" style="zoom:33%;" />

上图是一根数据总线，内部有四根连线，所以可以同时传输$4$bit的信息。如果想要传输$32bit$信息，就要$32$根信号线。同时一时刻只能有一个部件通过数据总线发送数据，但是可以有多个部件接受数据。

## 1. 总线的概述

总线是一组能为多个部件**分时共享**的公共信息传送线路。

共享是指总线上可以挂接多个部件，各个部件之间互相交换的信息都可以通过这组线路分时共享。

分时是指同一时刻只允许有一个部件向总线发送信息，如果系统中有多个部件，则它们只能分时地向总线发送信息。

<img src="https://image.sybblogs.fun/img-common/202401261729306.png" alt="总线定义" style="zoom:33%;" />

早期计算机外部设备少时大多采用分散连接方式，即增加一个外部设备就要建立一条专门数据传送线路，这种方式不易实现随时增减外部设备。为了更好地解决$I/O$设备和主机之间连接的灵活性问题，计算机的结构从分散连接发展为总线连接，即每增加一个外部设备只需要将外部设备连接到总线上即可。

当设计总线的时候需要关注以下特性：

1. 机械特性：尺寸、形状、管脚数、排列顺序

2. 电气特性：传输方向和有效的电平范围

   传输方向是指，CPU可以通过地址总线给主存指明此时要读写的地址。显然这个地址总线传输方向只能是由CPU传向主存。对于数据总线来说CPU要往主存中写数据都是通过数据总线传输，所以对于数据总线来说方向是双向的。

   有效电平范围：即高低电平在什么样范围内有效。

3. 功能特性：每根传输线的功能(地址、数据、控制)

4. 时间特性：信号的时序关系

总线数据传输格式可以分为串行总线和并行总线。<a id="6-1-1"></a>

- 串行总线

  <img src="https://image.sybblogs.fun/img-common/202401261738872.png" alt="串行总线" style="zoom:33%;" />

  采用串行总线意味设备$A$只能一个一个比特给设备$B$传送信息。

  优点：只需要一条传输线，成本低廉，广泛应用于长距离传输；应用于计算机内部时，可以节省布线空间。

  缺点：在数据发送和接收的时候要进行拆卸和装配，要考虑串行与并行转换的问题。

- 并行总线

  <img src="https://image.sybblogs.fun/img-common/202401261739693.png" alt="并行总线" style="zoom:33%;" />

  采用并行总线设备$A$可以同时并行给设备$B$发送多个比特的数据。

  优点：总线的逻辑时序比较简单，电路实现起来比较容易。

  缺点：信号线数量多，占用更多的布线空间；远距离传输成本高昂；由于工作频率较高时，并行的信号线之间会产生严重干扰，对每条线等长的要求也越高，所以无法持续提升工作频率。

显然CPU与主存之间传送数据的总线式并行总线。串行规范常常用于USB。由于各个信号线之间的干扰问题，在发送数据的时候并行总线并不一定比串行要快。

按总线功能(连接的部件)可以分为三类：片内总线、系统总线、通信总线。

- 片内总线

  片内总线是芯片内部的总线。它是CPU芯片内部寄存器与寄存器之间、寄存器与ALU之间的公共连接线。

- ==系统总线== 

  系统总线是计算机系统内各功能部件(CPU、主存、$I/O$接口)之间相互连接的总线。

  按系统总线传输信息内容的不同，又可分为$3$类：数据总线、地址总线和控制总线。这里需要重点了解三种总线数据传输方向及每一种总线应该包含多少根信息线的问题。

  <img src="https://image.sybblogs.fun/img-common/202401261729306.png" alt="总线定义" style="zoom:33%;" />

  数据总线：传输各功能部件之间的数据信息，包括指令和操作数。其位数(总线的根数)与机器字长、存储字长有关。如果数据总线的宽度和机器字长一致，此时CPU可以进行一次数据读入就可以直接取得数据。信息传递方向是双向的。

  地址总线：传输地址信息，包括主存单元或$I/O$端口的地址。其位数(总线的根数)与主存地址空间大小及设备数量有关，当$I/O$设备与主存采用统一编址的策略时，设备数量会影响总线的宽度(根数)。信息传递方向是单向的。

  控制总线：传输控制信息。内部的一根控制线可以传输一个信号。对于一根控制线来说，控制信号的传输方向是单向的。对于整个控制总线来说，有出：CPU送出的控制命令。有入：主存(或外设)返回CPU的反馈信号。

- 通信总线

  通信总线是用于迁算机系统之间或计算机系统与其他系统(如远程通信设备、测试设备)之间信息传送的总线，通信总线也称为外部总线。如网线。

注意：数据通路表示的是数据流经的路径。而数据总线是承载的媒介。

按时序控制方式可以分为两类：同步总线、异步总线

- 同步总线
- 异步总线

本章重点探讨系统总线，系统总线经典结构有三种：单总线结构、双总线结构、三总线结构。

- 单总线结构

  只会在计算机内部设置一种系统总线。CPU、$I/O$设备等都是连在同一组系统总线上。

  <img src="https://image.sybblogs.fun/img-common/202401261846044.png" alt="单总线结构" style="zoom:33%;" />

  这里的系统总线包含数据总线地址总线和控制总线。

  优点：结构简单，成本低，易于接入新的设备。

  缺点：带宽低、负载重，多个部件只能争用唯一的总线， 且不支持并行传送操作。并且$I/O$设备读取很慢，CPU执行速度很快，显然这种连接在同一个系统总线方式不科学。

- 双总线结构

  会让主存、CPU和通道统一的连到一根主存总线上。$I/O$设备会连接到$I/O$总线上。

  <img src="https://image.sybblogs.fun/img-common/202401261851760.png" alt="双总线结构" style="zoom:33%;" />

  通道是具有特殊功能的处理器，专门对$I/O$设备进行统一管理。通道也需要运行管理相关的程序，而处理通道程序放在主存中。所以通道也可以通过主存总线从主存取出数据。

  这里的主存总线支持突发(猝发)传送：即送出一个地址，收到多个地址连续的数据。正常来说CPU每指明一个地址，可以从主存当中读出一个字的信息，但是由于主存当中信息很多时候都是需要被连续访问(如指令序列)，显然CPU指明地址后如果能从主存当中连续读出多个字的数据，这样系统的效率可能更高。

  优点：将较低速的$I/O$设备从单总线上分离出来，实现存储器总线和$I/O$总线分离。

  缺点：需要增加通道等硬件设备。

- 三总线结构

  CPU与主存之间通过主存总线连接。高速外设(磁盘等)可以通过DMA总线有主存进行连接。低速外设(键盘等)通过$I/O$总线与CPU连接。

  <img src="https://image.sybblogs.fun/img-common/202401261857082.png" alt="三总线结构" style="zoom:33%;" />

  对磁盘读写是以块为单位的，让磁盘和主存通过DMA总线交换数据就可以很快完成整块数据的传递。这样做的好处在于CPU不需要通过慢速的$I/O$总线与磁盘进行交互，而是可以把CPU需要的数据先从磁盘通过DMA总线读入主存，之后CPU再从快速的主存总线上取走主存中的数据，这样可以缓和CPU与磁盘之间的矛盾。CPU可以通过慢速$I/O$总线与慢速的外设进行交互，慢速外设可以更快相应CPU发出的命令。

  优点：提高了$I/O$设备的性能，使其更快地响应命令，提高系统吞吐量。

  缺点：系统工作效率较低。原因在于这三个总线同一时间只能有一个总线进行工作。

- 四总线结构

  <img src="https://image.sybblogs.fun/img-common/202401261906296.png" alt="四总线结构" style="zoom:33%;" />

  上面四个总线中，CPU总线最快；其次是系统总线和高速总线；最慢的是扩充总线。所以越靠近CPU的总线速度越快。

  由于不同总线之间有速度的差异，因此需要增加一个桥接器部件。桥接器作用是用于连接不同的总线，具有数据缓冲、转换和控制功能。

## 2. 评价总线性能的指标

评价总线性能指标有八种：总线的传输周期(总线周期)、总线时钟周期、总线的工作频率、总线的时钟频率、总线宽度、总线带宽、总线复用、信号线数。

- 总线传输周期(总线周期)

  一次总线操作所需的时间(包括申请阶段、寻址阶段、传输阶段和结束阶段)，通常由若干个总线时钟周期构成。有的时候，一个总线周期就是一个总线时钟周期。还有的时候，一个总线时钟周期可包含多个总线周期。

  > 其中申请阶段要做的是总线仲裁，决定是否把总线分配给某个设备使用。寻址阶段是两个设备通过总线进行数据的交互，主设备会通过地址总线将它要读写的地址单元传递给从设备。传输阶段是通过数据总线往从设备中写入数据或读出数据。结束阶段会释放总线的使用权。

  经过一个总线周期后可以完成一组数据的传输。假如一组数据总线宽度是$32bit$，也就意味着经过一个总线周期可以通过这组数据总线来传出$32bit$的数据。

- 总线时钟周期

  即机器的时钟周期。计算机有一个统一的时钟，以控制整个计算机的各个部件，总线也要受此时钟的控制。现在的计算机中，总线时钟周期也有可能由桥接器提供。

  总线周期与时钟周期的关系可以是一对一、一对多、多对多。

- 总线的工作频率

  总线上各种操作的频率，为总线周期的倒数。若总线周期$=N$个时钟周期，则总线的工作频率$=\frac{时钟频率}{N}$。

  实际上指一秒内传送几次数据。

- 总线的时钟频率

  即机器的时钟频率，为时钟周期的倒数。若时钟周期为$T$，则时钟频率为$\frac{1}{T}$。

  实际上指一秒内有多少个时钟周期。

- 总线的宽度

  又称为总线位宽，它是总线上同时能够传输的数据位数，通常是指数据总线的根数，如$32$根称为$32$位(bit)总线。

- 总线带宽

  可理解为总线的数据传输率，即单位时间内总线上可传输数据的位数，通常用每秒钟传送信息的字节数来衡量，单位可用字节$/$秒$(B/s)$表示。

- 总线复用

  总线复用是指一种信号线在不同的时间传输不同的信息。可以使用较少的线传输更多的信息，从而节省了空间和成本。

  <img src="C:\Users\Acid\OneDrive\图片\本机照片\408\计算机组成原理\总线复用.png" alt="总线复用" style="zoom:33%;" />

  采用这种复用技术，传递地址信息和数据信息时需要两个总线周期，需要两次数据的传送。所以虽然节约成本但是速度有所下降。

- 信号线数

  地址总线、数据总线和控制总线这$3$种总线数的总和称为信号线数。假如地址总线有$32$根，数据总线有$64$根，控制总线有$100$根那么总的信号线数$=32+64+100=196$

通过上面概念可以得到总线带宽公式
$$
总线带宽=总线工作频率\times总线宽度(bit/s)=总线工作频率\times(总线宽度/8)(B/s)
$$
由于总线工作频率和总线周期之间是倒数关系，所以
$$
总线带宽=\frac{总线宽度}{总线周期}(bit/s)=\frac{总线宽度/8}{总线周期}(B/s)
$$
注：总线带宽是指总线本身所能达到的最高传输速率。在计算实际的有效数据传输率时，要用实际传输的数据量除以耗时(校验位等)。

例题：某同步总线采用数据线和地址线复用方式，其中地址$/$数据线有$32$根，总线时钟频率为$66$MHz，每个时钟周期传送两次数据(上升沿和下降沿各传送一次数据)。

1. 该总线的最大数据传输率(总线带宽)是多少?

   每个时钟周期传送两次数据，所以工作频率是时钟频率的两倍，即总线工作频率$=2\times66$MHz=$132$MHz

   总线宽度$=32bit=4$B

   总线宽度$=$总线工作频率$\times$总线宽度$=132\times4$MB$/$s$=528$MB$/$s

2. 若该总线支持突发(猝发)传输方式，传输一个地址占用一个时钟周期，则一次"主存写"总线事务传输$128$位数据所需要的时间至少是多少?

   发送首地址占用$1$个时钟周期，$128$位数据需传输$4$次，占用$2$个时钟周期，且一个时钟周期$=1/66$MHz$\approx15$ns

   故总耗时$=(1+2)\times15$ns$=45$ns

由公式$总线带宽=总线工作频率\times总线宽度(bit/s)$联系之前讲过<a href="#6-1-1">串行与并行总线</a>可知并行总线中为了保证数据的正确传输通常并行总线的工作频率不能太高，因为有信号干扰。而串行中线没有数据干扰，所以工作频率可以很高。所以两种线速度情况有以下两种：

1. 工作频率相同时，串行总线传输速度比并行总线慢。
2. 并行总线的工作频率无法持续提高，而串行总线可以通过不断提高工作频率来提高传输速度，最终超过并行总线。

## 3. 总线的操作和定时

总线同一时刻只能提供给一组设备使用。当一个设备获得总线控制权后，就可以利用总线对某一个从设备发出一定的命令，比如读写数据等。这对主设备和从设备之间怎么用电信号进行数据交流和时序安排就是这一节探讨的内容。

用总线传一次数据，即总线周期需要四个阶段：

1. 申请分配阶段：由需要使用总线的主模块(或主设备)提出申请，经总线仲裁机构决定将下一传输周期的总线使用权授予某一申请者。也可将此阶段细分为传输请求和总线仲裁两个阶段。
2. 寻址阶段：获得使用权的主模块通过总线发出本次要访问的从模块的地址及有关命令，启动参与本次传输的从模块。

3. 传输阶段：主模块和从模块进行数据交换，可单向或双向进行数据传送。
4. 结束阶段：主模块的有关信息均从系统总线上撤除，让出总线使用权。

而总线定时指的是总线在双方交换数据的过程中需要时间上配合关系的控制，这种控制称为总线定时，它的实质是一种协议或规则。即主模块与从模块在总线周期内进行四个阶段需要时间上的配合进行协调工作，如何进行它们在时间上有条不紊的配合这就是总线定时要探讨的问题。事实上总线定时就是要指定某一种协议或规则让数据的放松方和接受方都能按照统一规则进行数据交互。

总线定时方案(协议)有四种：同步通信(同步定时方式)、异步通信(异步定时方式)、半同步通信、分离式通信。

- 同步定时方式(读命令)

  总线控制器采用一个统一的时钟信号来协调发送和接收双方的传送定时关系。

  假设CPU是主设备，某个输入设备作为从设备。假设一个总线传输周期包含$T_1,T_2,T_3,T_4$四个阶段

  1. 第一个阶段CPU在$T1$时刻的上升沿给出地址信息

     <img src="https://image.sybblogs.fun/img-common/202401271505791.png" alt="同步定时周期" style="zoom:33%;" />

  2. 第二阶段在$T2$的上升沿给出读命令(低电平有效)，与地址信息相符合的输入设备按命令进行一系列的内部操作，且必须在$T3$的上升沿来之前将CPU所需的数据送到数据总线上。

     <img src="https://image.sybblogs.fun/img-common/202401271507124.png" alt="同步定时周期2" style="zoom:33%;" />

  3. CPU在$T3$时钟周期内，将数据线上的信息传送到其内部寄存器中。

     <img src="https://image.sybblogs.fun/img-common/202401271508186.png" alt="同步定时周期3" style="zoom:33%;" />

  4. CPU在$T4$的上升沿撤销读命令，输入设备不再向数据总线上传送数据，撤销它对数据总线的驱动。

     <img src="https://image.sybblogs.fun/img-common/202401271508826.png" alt="同步定时周期4" style="zoom:33%;" />

  接着就可以进入下一个总线周期。如果从设备速递较慢，在$T3$阶段给不出数据，这种同步定时方式就会出现问题。

  所以同步定时方式特点是由若干个时钟产生相等的时间间隔，每个间隔构成一个总线周期。在一个总线周期中，发送方和接收方可进行一次数据传送。因为采用统一的时钟，每个部件或设备发送或接收信息都在固定的总线传送周期中，一个总线的传送周期结束，下一个总线传送周期开始。

  优点：传送速度快，具有较高的传输速率;总线控制逻辑简单。

  缺点：主从设备属于强制性同步；不能及时进行数据通信的有效性检验，可靠性较差。

  因此同步通信方式适用于总线长度较短及总线所接部件的存取时间比较接近的系统。

- 异步通信方式

  在异步定时方式中，没有统一的时钟，也没有固定的时间间隔，完全依靠传送双方相互制约的"握手"信号来实现定时控制。

  主设备提出交换信息的"请求"信号，经接口传送到从设备；从设备接到主设备的请求后，通过接口向主设备发出"回答"信号。

  可以根据请求和回答信号的撤销是否互锁，进一步细分为以下三类

  1. 不互锁方式

     当主设备获得主控权之后会发出请求信号(地址信息，读命令)后，不必等到接到从设备的"回答"信，而是经过一段时间便撤销请求信号。

     而从设备在接受到"请求"信号后，发出"回答"信号，并经过一段时间，自动撤销"回答"信号。双方不存在互锁关系。

     <img src="https://image.sybblogs.fun/img-common/202401271622078.png" alt="不互锁方式" style="zoom:33%;" />

     可以看出这种方式信号的撤销不存在相互制约的关系。

  2. 半互锁方式

     主设备发出"请求"信号后，必须待接到从设备的"回答"信号后，才撤销"请求"信号，有互锁的关系。

     而从设备在接到"请求"信号后，发出"回答"信号，但不必等待获知主设备的"请求"信号已经撤销，而是隔一段时间后自动撤销回答"信号"，不存在互锁关系。

     所以请求信号的撤销动作会收到回答信号的制约，但是回答信号的撤销动作并不会受到请求信号的制约，因此这种方式称为半互锁方式。

     <img src="https://image.sybblogs.fun/img-common/202401271624367.png" alt="半互锁方式" style="zoom:33%;" />

  3. 全互锁方式

     主设备发出"请求"信号后，必须待从设备"回答"后，才撤销"请求"信号。

     从设备发出"回答"信号，必须待获知主设备"请求"信号已撤销后，再撤销其"回答"信号。双方存在互锁关系。

     <img src="https://image.sybblogs.fun/img-common/202401271626551.png" alt="全互锁方式" style="zoom:33%;" />

  显然第一种不互锁方式速度最快，可靠性最差。第三种全互锁方式最可靠，但速度最慢。

  这种异步定时方式优点是总线周期长度可变，能保证两个工作速度相差很大的部件或设备之间可靠地进行信息交换，目动适应时间的配合。

  缺点：比同步控制方式稍复杂一些，由于需要等待回应，所以速度比同步定时方式慢。

- 半同步通信

  是同步与异步结合。即在统一时钟的基础上，增加一个"等待"响应信号$\overline{WAIT}$

  <img src="https://image.sybblogs.fun/img-common/202401271632558.png" alt="半同步通信" style="zoom:33%;" />

  如上图，比起同步定时方式，半同步通信方式会增加一个反馈信号$\overline{WAIT}$。首先主设备在$T1$时间内发出地址信号，在$T2$节拍的前沿也就是上升沿部分又会发出读命令，如果是之前的同步定时方式$T2$再往后的一个节拍从设备需要准备数据，但有的从设备可能跟不上速度，但使用半同步通信此时可以通过控制线路$\overline{WAIT}$给总线控制器一个反馈，让总线控制器等几个节拍，即$T_w$。经过$T_w$个节拍的等待，从设备准备好数据，记下来在$T3$节拍内，从设备就可以将准备好的数据通过数据总线发送给主设备。最后$T4$节拍主设备会撤销读命令和地址信息。这样就完成一个总线传输工作。

  可以看出之前的同步定时方式每个总线传输周期都是定长的，是四个时钟周期。但是这种半同步通信结合异步通信方式优点，增加一个等待反馈信号，这样总线控制器可以根据这个反馈信号来动态调节传输周期种包含的时钟周期数。

- 分离式通信方式

  具有上述三种通信方式共同点。结合刚才的例子，主设备要从从设备读出一个数据，那么主设备获得总线控制权后首先会发出地址和读命令，接下来从设备接收到命令后需要准备数据，数据准备好后才会通过数据总线给主设备发送数据。所以整个数据传输过程有三步：

  1. 主模块发地址、命令
  2. 从模块准备数据
  3. 从模块向主模块发数据

  这三个过程当中第一个过程需要使用到总线，第二个过程准备数据所以不需要使用总线。但这个时间段内这对主从设备依然会占据总线的使用权。最后一个阶段发送数据需要用到总线。所以优化的阶段是第二个阶段，当慢速的从设备在准备数据的时候，总线是空闲状态。所以分离式通信思想就是把总线的传输周期分离为两个独立的子周期：

  子周期$1$：主模块申请占用总线，使用完后放弃总线的使用权。当主设备申请发出请求信号后会立即放弃总线使用权。

  子周期$2$：从模块申请占用总线，将各种信息送至总线上。当从设备准备好数据后会主打申请占用主线，将信息传送到主线上。

  所以这种分离式通信可以充分利用第二阶段准备数据时间，这个阶段把主线的使用权分配给其他设备使用，这样就能让总线传输效率更高。

  这种方式特点：

  1. 各模块均有权申请占用总线
  2. 采用同步方式通信，不等对方回答
  3. 各模块准备数据时，不占用总线
  4. 总线利用率提高

# 七. 输入$/$输出系统

常见的输入设备有鼠标和键盘。常见的输出设备有显示器和打印机。而硬盘和光盘是即可输入又可输出的设备。这些所有的$I/O$设备可以统称为外部设备。

在总线那一章中介绍过单总线结构：

<img src="https://image.sybblogs.fun/img-common/202401281139459.png" alt="单总线结构关于IO设备" style="zoom:33%;" />

$I/O$接口：又称$I/O$控制器、设备控制器，负责协调主机与外部设备之间的数据传输，这个控制器就是一块芯片，会被集成在主板上。

<img src="https://image.sybblogs.fun/img-common/202401281141046.png" alt="USB控制器" style="zoom:33%;" />

如上图外部设备通过$I/O$接口与CPU进行数据交互，这个$I/O$接口就是$I/O$控制器。上图又可以称为USB接口，因为通过USB连接线连接的，而电脑可以连接的设备多种多样因此控制不同的接口用到的$I/O$控制器也不一样。

所以$I/O$控制器多种多样，也会制定相应的标准，如：用于控制USB设备的$IO$接口、用于控制$SATA$ $3.0$硬盘的$I/O$接口等。

CPU是如何通过$I/O$接口与外设进行交互的：<a id="7-1-1"></a>

<img src="https://image.sybblogs.fun/img-common/202401281226934.png" alt="IO控制方式简介" style="zoom:33%;" />

上面$I/O$接口内的功能部件有数据寄存器、控制寄存器和状态寄存器。

数据寄存器：存放主机要输出到外设数据，或者外设要输入回主机的数据。

控制寄存器：这个寄存器中存储的内容可以直接反映某一个外设具体要做什么动作，如键盘灯亮灭。

状态寄存器：反映了当前外设状态，比如说这个外设是否处于忙碌状态，是否损坏灯。CPU可以根据状态寄存器内部的标志位判断。

## 1. $I/O$控制方式<a id="7-1.1-1"></a>

有以下代码：

~~~c
int main(void){
    char i;
    scanf("&C",&i);
    printf("i = %c\n",i);
    return 0 ;
}
~~~

了解这三个寄存器大致功能后CPU在处理`scanf("&C",&i)`这段代码时，CPU会先通过控制总线向$I/O$接口发出读命令，同时可以通过地址总线来指明要读的是哪个设备，地址总线还有一个作用是可以用于指明此次要从这个设备读入的数据应该放在哪一个寄存器。如果当前已经输入一个字符，那判断该字符是否输入方法有以下几种：

- 程序查询方式

  CPU不断轮询检查$I/O$控制器中的"状态寄存器"，检测到状态为"已完成"之后，再从数据寄存器取出输入数据。

  如果状态寄存器现实已经完成，此字符数据会放在数据寄存器中，CPU可以通过数据总线取走数据寄存器中的值。

  这种方式显然很低效，因为当读取$I/O$设备数据时，CPU不能去做其他事情，而是要不断检查状态寄存器。

  <img src="https://image.sybblogs.fun/img-common/202401281320762.png" alt="程序查询方式" style="zoom:33%;" />

- 程序中断方式

  程序中断方式：等待键盘$I/O$时CPU可以先去执行其他程序，键盘$I/O$完成后$I/O$控制器向CPU发出中断请求，CPU响应中断请求，并取走输入数据。 

  <img src="https://image.sybblogs.fun/img-common/202401281321846.png" alt="程序中断方式" style="zoom:33%;" />

上面两种方式的数据流是：键盘$\rightarrow I/O$接口的数据寄存器$\rightarrow$数据总线$\rightarrow$CPU某寄存器$\rightarrow$主存(变量$i$的对应位置)。

上面慢速设备用程序中断方式，向CPU发出中断请求次数较少，可以使用。但是一些快速的$I/O$设备，如磁盘，没准备好一个字就给CPU发送一次中断请求，会导致CPU接收到中断请求频率变高，每次接收到中断请求都会执行中断程序，CPU需要花大量的时间来处理中断服务程序，CPU利用率严重下降。

### 1.1 DMA控制方式

为了让这些快速的外部设备与主机间的数据交互更有效率，一般采用DMA控制方式：

<img src="https://image.sybblogs.fun/img-common/202401281325295.png" alt="DMA控制" style="zoom:33%;" />

这是一种三总线结构，上面的DMA总线连接了DMA接口，这个DMA接口是专门由于管理高速的$I/O$设备。这里的DMA接口，即DMA控制器，也是一种特殊的$I/O$控制器。

DMA控制方式：主存与高速$I/O$设备之间有一条直接数据通路(DMA总线)。CPU向DMA接口发出"读$/$写"命令，并指明主存地址、磁盘地址、读写数据量等参数。当CPU想要往磁盘读写数据时，可以通过$I/O$总线指明此次是要进行读写命令，如果是读命令CPU还会指明应该要把数据读到主存哪个位置，另外也要指明此时要读的数据在磁盘中的位置，最后还要指明此次要读的数据量，指明之后CPU就可以去执行其他任务。

DMA控制器自动控制磁盘与主存的数据读写，每完成一整块数据读写(如$1$KB为一整块)，才向CPU发出一次中断请求。

<img src="https://image.sybblogs.fun/img-common/202401281344994.png" alt="DMA方式" style="zoom:33%;" />

DMA控制器与主存每次传送$1$个字。当传送完一整块数据后才向CPU发出中断请求。

因此引入DMA方式，如果此时有个某个程序需要进行数据读写，那么CPU会通过$I/O$指令向DMA接口，指明此次要读写数据的主存地址、磁盘地址、读写数据量等参数，发出这些指令后，CPU就可以去执行其他任务。而$I/O$设备可以慢慢准备数据，准备好的数据会先存入DMA控制器中，每准备好一个字DMA控制器就会发出DMA请求，接着DMA控制器会占用一个存取周期，往主存对应位置写入一个字的数据。如果在这个存取周期内，CPU也想访问主存则必须等待DMA控制器写好这一个字的数据之后，CPU才可以继续往后执行访问主存。因为这里主存是被CPU和DMA控制器同时共享的。所以每次DMA往主存中写入数据时，都需要占用过一个存取周期。而一个存取周期肯定要比CPU处理一个中断程序时间短。因此DMA控制方式又比程序中转方式效率快不少。

### 1.2 通道控制方式

这种DMA控制方式已经足够满足普通用户，但是对于商用中型机、大型机可能会接上超多的$I/O$设备，如果都让CPU来管理，那么CPU效率还是会变低。此时要用到通道控制方式：

<img src="https://image.sybblogs.fun/img-common/202401281406608.png" alt="通道控制方式" style="zoom:33%;" />

通道是具有特殊功能的处理器，能对$I/O$设备进行统一管理。通道也是处理器的一种，可以执行一些特定的通道指令这些通道指令种类、功能通常比较单一，通过通道指令的执行就可以管理各种各样的$I/O$设备。由上图可以看出引入通道之后，CPU已经不会和$I/O$设备进行直接交互了，而是由通道通过$I/O$总线来管理的。

<img src="https://image.sybblogs.fun/img-common/202401281411266.png" alt="通道控制方式2" style="zoom:33%;" />

CPU、主存和通道可以通过总线进行连接，如果此时CPU想要操作某一个$I/O$设备，CPU会通过$I/O$指令给通道指明一个具体的任务，指明要处理的$I/O$设备是哪一个。另外当通道管理这些$I/O$设备时，应该执行的程序(通道程序)在内存种的哪个位置。接下里通道就可以根据CPU的指示去内存当中一条一条取出这些通道指令。每一条通道指令的执行都会对应给一个$I/O$设备发出具体的命令。所以通道在执行通道指令序列时，就是在对$I/O$设备进行操作，并且具体要进行什么操作可以用编程方式通过通道指令灵活进行调整。当通道执行完这一系列指令后才会向CPU发出中断请求，最后CPU在对中断请求执行相应的处理即可。因此引入通道之后，CPU对$I/O$设备繁杂的管理工作可以进一步得到优化。

对于之前的DMA方式来说，只能连续读入或写出一整块数据，每传送完一整块的数据都需要CPU介入，而引入通道之后对数据的存取位置输入输出这些控制，可以通过通道指令变得灵活，只需要提前编址好通道指令程序即可。只有通道完成所有工作之后，才需要CPU介入一次。

### 1.3 $I/O$系统基本组成

一般来说， $I/O$系统由$I/O$软件和$I/O$硬件两部分构成。

$I/O$硬件包括外部设备、$I/O$接口、$I/O$总线等。

<img src="https://image.sybblogs.fun/img-common/202401281426197.png" alt="IO硬件" style="zoom:33%;" />

$I/O$软件包括驱动程序、用户程序、管理程序、升级补丁等。通常采用$I/O$指令和通道指令实现主机和$I/O$设备的信息交换。

- $I/O$指令格式是：操作码$+$命令码$+$设备码

  CPU执行的指令。

  操作码指明了CPU要对$I/O$接口做什么，命令码指明了$I/O$接口要对设备做什么，设备码指明了对哪个设备进行操作。

- 通道指令：

  通道执行的指令。通道程序提前编制好放在主存中。

  在含有通道的计算机中，CPU执行$I/O$指 令对通道发出命令，由通道执行一系列通道指令，代替CPU对$I/O$设备进行管理。

## 2. 外部设备

外部设备也称外围设备，是除了主机以外的、能直接或间接与计算机交换信息的装置。可以分为输入设备、输出设备和外存设备。

- 输入设备

  用于向计算机系统输入命令和文本、数据等信息的部件。键盘和鼠标是最基本的输入设备。

- 输出设备

  用于将计算机系统中的信息输出到计算机外部进行显示、交换等的部件。显示器和打印机是最基本的输出设备。

- 外存设备

  是指除计算机内存及CPU缓存等以外的存储器。硬磁盘、光盘等是最基本的外存设备。

常见设备工作原理：

1. 键盘

   键盘是最常用的输入设备，通过它可发出命令或输入数据。每个键相当于一个开关，当按下键时，电信号连通；当松开键时，弹簧把键弹起，电信号断开。

   键盘输入信息可分为$3$个步骤：

   ①查出按下的是哪个键。用硬件电路确定。

   ②将该键翻译成能被主机接收的编码，如ASCII码。

   ③将编码传送给主机。需要使用到$I/O$接口。

2. 鼠标

   鼠标是常用的定位输入设备，它把用户的操作与计算机屏幕上的位置信息相联系。常用的鼠标有机械式和光电式两种。

   工作原理：
   当鼠标在平面上移动时，其底部传感器把运动的方向和距离检测出来，从而控制光标做相应运动。

3. ==显示器==

   按显示设备所用的显示器件分类：阴极射线管(CRT) 显示器、液晶显示器(LCD)、LED显示器

   按所显示的信息内容分类：字符显示器、图形显示器、图像显示器

   性能指标：

   屏幕大小：以对角线长度表示，常用的有$12\sim29$英寸等。

   分辨率：所能表示的像素个数，屏幕上的每一个光点就是一个像素，以宽、高的像素的乘积表示，例如：$800\times 600$、$1024\times768$和$1280\times 1024$等。

   灰度级：灰度级是指黑白显示器中所显示的像素点的亮暗差别，在彩色显示器中则表现为颜色的不同，灰度级越多，图像层次越清楚逼真，典型的有$8$位($256$级)、$16$位等。$n$位可以表示$2^n$种不同的亮度或颜色。

   刷新率：光点只能保持极短的时间便会消失，为此必须在光点消失之前再重新扫描显示一遍，这个过程称为刷新。刷新频率是单位时间内扫描整个屏幕内容的次数，按照人的视觉生理，刷新频率大于$30$Hz时才不会感到闪烁，通常显示器刷新频率在$60\sim120$Hz。

   现实存储器(VRAM)：也称刷新存储器，为了不断提高刷新图像的信号，必须把一帧图像信息存储在刷新存储器中。其存储容量由图像分辨率和灰度级决定，分辨率越高，灰度级越多，刷新存储器容量越大。==VRAM容量计算公式==如下：
   $$
   VRAM容量=分辨率\times 灰度级位数
   $$
   考虑刷新率，一秒钟要往VRAM中写入$60$帧的数据。因此对VRAM的写入速度会有一个最低要求：
   $$
   VRAM带宽=分辨率\times灰度级位数\times 帧频
   $$
   假如一个计算机分辨率为$1440\times900$，灰度级位数是$24$位彩色。那么VRAM容量是$1440\times900\times3B\approx3.7MB$(一帧的大小即为显存的理论最小值)。如果显示器刷新率为$60$Hz，则VRAM带宽至少要$3.7\times60=222MB/S$。

   注：现代计算机中，显存除了作为当前显示帧的缓存，还会用于保存即将渲染的图像数据，所以一般比容量最小值大很多倍。

   如果是集成显卡计算机，通常分配一片内存作为显存。

4. 阴极射线管(CRT)显示器

   CRT显示器主要由电子枪、偏转线圈、荫罩、高压石墨电极和荧光粉涂层及玻璃外壳5部分组成。具有可视角度大、无坏点、色彩还原度高、色度均匀、可调节的多分辨率模式、响应时间极短等且前LCD已经超过。

   <img src="https://image.sybblogs.fun/img-common/202401281517121.png" alt="阴极射线管显示器" style="zoom:33%;" />

5. 液晶显示器(LCD)

   原理：利用液晶的电光效应，由图像信号电压直接控制薄膜晶体管，再间接控制液晶分子的光学特性来实现图像的显示。
   特点：体积小、重量轻、省电、无辐射、绿色环保、画面柔、不伤眼等。

6. LED(发光二极管)显示器

   原理：通过控制半导体发光二极管进行显示，用来显示文字、图形、图像等各种信息。

LCD与LED是两种不同的显示技术，LCD是由液态晶体组成的显示屏，而LED则是由发光二极管组成的显示屏。与LCD相比，LED显示器在亮度、功耗、可视角度和刷新速率等方面都更具优势。

下面重点介绍CRT(阴极射线管)显示器。按照现实内容的不同可以分为一下几种：

- 字符显示器

  显示字符的方法以点阵为基础。点阵是指由$m\times n$个点组成的阵列。点阵的多少取决于显示字符的质量和字符窗口的大小。字符窗口是指每个字符在屏幕上所占的点数，它包括字符显示点阵和字符间隔。将点阵存入由ROM构成的字符发生器中，在CRT进行光栅扫描的过程中，从字符发生器中依次读出某个字符的点阵，按照点阵中$0$和$1$代码不同控制扫描电子束的开或关，从而在屏幕上显示出字符。对应于每个字符窗口，所需显示字符的ASCII代码被存放在视频存储器VRAM中，以备刷新。

  现实字符原理：

  <img src="https://image.sybblogs.fun/img-common/202401281530444.png" alt="CRT显示器" style="zoom:33%;" />

  上图的接口电路即$I/O$接口，通过接口处理可以把键盘或者主机想要显示的字符信息，先把这些字符信息的ASCII码写入到显示存储器中，接着在CRT控制器的控制之下，显存里的字符会用电信号的方式送给字符发生器，在这个字符发生器中除了控制电路之外，也会又一个ROM用来存放每一个ASCII码所对应的字形码。

  <img src="https://image.sybblogs.fun/img-common/202401281535977.png" alt="CRT显示器2" style="zoom:33%;" />

  也就是上图右边的点阵信息，根据字符的ASCII码和CRT控制器信息选中某一个字符的字形码所存储的ROM存储单元，在这个单元中就存储了要显示字符的字形信息。之后把字形信息送到输出缓冲寄存器中，然后再通过另一个电路的控制把这个字符信息通过CRT将电子射向屏幕。最后屏幕会显示出该字符样子。这就是字符显示器显示字符原理。

  ==注意：==一个字大小是$m\times n$，那么每个字的字形码就是$m\times n$位。这个字形码信息是存放在字符发生器ROM，而显存中存放的是ASCII信息。

- 图形显示器

  将所显示图形的一组坐标点和绘图命令组成显示文件存放在缓冲存储器中，缓存中的显示文件传送给矢量(线段)产生器，产生相应的模拟电压，直接控制电子束在屏幕上的移动。为了在屏幕上保留持久稳定的图像，需要按一定的频率对屏幕进行反复刷新。

  这种显示器的优点是分辨率高且显示的曲线平滑。目前高质量的图形显示器采用这种随机扫描方式。缺点是当显示复杂图形时，会有闪烁感。

  对于图形显示来说按照扫描方式的不同可以分为光栅扫描显示器和随机扫描显示器。

  这种图形显示器特点是显示图形不复杂很规则，如股票涨跌图。

- 图像显示器

  就是电脑手机采用的显示器，可以显示丰富多彩图像信息。

还有一种常用输出设备是打印机，打印机是计算机的输出设备之一，用于将计算机处理结果打印在相关介质上。其按照印字原理不同可分为击打式打印机和非击打式打印机。

- 击打式打印机：利用机械动作使印字机构与色带和纸相撞而打印字符。如：机打发票、银行回执单(防伪性好)

  击打式打印机优点是设备成本低、印字质量好。缺点是噪声大、速度慢。

- 非击打式打印机：采用电、磁、光、喷墨等物理、化学方法来印刷字符

  非击打式打印机优点是速度快、噪声小。缺点是成本高。

按照打印机工作方式不同可分为：串行打印机：逐字打印、速度慢；行式打印机：逐行打印、速度快。

<img src="https://image.sybblogs.fun/img-common/202401281601479.png" alt="打印机" style="zoom: 33%;" />

## 3. $I/O$接口

之前介绍过$I/O$接口：又称$I/O$控制器($I/O$ Controller)、设备控制器，负责协调主机与外部设备之间的数据传输。

通过之前的<a href="#7-1-1">$I/O$接口交互</a>例子

<img src="https://image.sybblogs.fun/img-common/202401281226934.png" alt="IO控制方式简介" style="zoom:33%;" />

可以知道$I/O$接口有以下作用：

1. 数据缓冲：通过数据缓冲寄存器(DBR)达到主机和外设工作速度的匹配。CPU和外设速度差距很大，所以需要数据寄存器$/$数据缓冲器来充当缓冲作用。
2. 错误或状态监测：通过状态寄存器反馈设备的各种错误、状态信息，供CPU查用
3. 控制和定时：接收从控制总线发来的控制信号、时钟信号
4. 数据格式转换：串转换并、 并转换串等格式转换。很多设备输入或输出数据时都是串行输出的，而CPU通过数据总线取$/$放数据都是并行方式传输的，因此$I/O$接口需要进行格式转换。
5. 与主机和设备通信：实现主机$——I/O$接口$——I/O$设备之间的通信。

### 3.1 接口工作原理

根据以上作用可以对$I/O$接口内部做更进一步的细化：

<img src="https://image.sybblogs.fun/img-common/202401281615856.png" alt="IO接口内部的细化" style="zoom:33%;" />

上图主机侧是内部接口与系统总线相连，实质上是与内存、CPU相连。数据的传输方式可能是串行也可能是并行传输。

设备侧是外部接口通过接口电缆与外设相连，外部接口的数据传输可能是串行方式，因此$I/O$接口需具有串$/$并转换功能。

图中右边有很多个外设界面控制逻辑，也就是说这样一个$I/O$接口，有可能会连接多个外设。

$I/O$接口工作步骤：

1. 发命令：发送命令字到$I/O$控制寄存器，向设备发送命令(需要驱动程序的协助)

   CPU连接在主机侧，外设连接在设备侧。CPU如果要操控打印机完成打印任务，首先CPU需要把打印机所对应的命令输入到控制寄存器当中。由于命令字千差万别，因此通常需要驱动程序协助。

2. 读命令：从状态寄存器读取状态字，获得设备或$I/O$控制器的状态信息

   CPU从状态寄存器中读取状态字，同这种方式确认设备是否就绪，或者工作是否完成。

3. 读$/$写数据：从数据缓冲寄存器发送或读取数据，完成主机与外设的数据交换。

   接下来CPU需要通过数据总线，往数据缓冲寄存器中写入想要打印的数据，之后在控制逻辑的控制下将这些要打印的数据逐个输出到打印机当中。打印机完成工作后就可以给$I/O$接口一个状态的反馈，当$I/O$接口检测到设备工作完成后就会修改状态寄存器当中相应的比特位，这样CPU就可以通过状态寄存器的标志位得知打印机打印完成。

   这里的<a href="#7-1.1-1">CPU检查方式</a>就是之前提到过的三种。

上图状态寄存器和控制寄存器写在一起原因是控制寄存器、状态寄存器在使用时间上是错开的，因此有的$I/O$接口中可将二者合二为一。即当CPU要控制一个设备进行输入或者输出时，一定是CPU先向设备发出一个命令，将这个命令信息放到控制寄存器当中，之后当$I/O$控制逻辑取出这条命令后这个控制寄存器就空闲了，接着就没有必要将命令字一直存放控制寄存器中。另一方面$I/O$控制逻辑启动设备工作之后，需要随时给CPU反馈工作状态，因此可以将设备的状态信息和控制指令存放在一个寄存器中。

注意：$I/O$控制器中的各种寄存器称为$I/O$端口。比如数据缓冲寄存器可以称为数据端口，状态$/$控制寄存器可以称为状态$/$控制端口。因此CPU在对端口数据进行读写时需要指明要读写的是哪个端口的信息，这就是地址线的作用，CPU会通过地址线来指明要往哪个寄存器中读写数据。

$I/O$总线包括数据总线、地址总线和控制总线。地址总线是指明CPU要读写数据的端口是哪个。控制总线发出读写命令，还会用于给CPU反馈中断请求信号。数据总线CPU要输出或者从外设输入的数据都会通过数据总线传送放到数据缓冲寄存器当中，还会用于传输状态$/$命令字相关的信息，最后数据总线还会用于传输中断类信号。

上面的$I/O$接口可以接入多个设备，CPU对设备确实方式是可以对每个设备对应一组寄存器，操作不同的寄存器就是在操作不同的设备。

### 3.2 接口与端口

接口与端口之间的关系如下：

<img src="https://image.sybblogs.fun/img-common/202401281710488.png" alt="接口与端口" style="zoom:33%;" />

接口包括端口和控制逻辑，其中端口又包含数据端口(用于读写)、控制端口(用于写)和状态端口(用于读)。

由于接口内部有多个端口多个寄存器，为了表明CPU要访问的是哪个寄存器，因此需要给这些寄存器进行编址。编址方式有两种：

- ==统一编址==

  有称为存储器映射方式。统一编址是指$I/O$端口地址和内存的地址是一整套的。

  <img src="https://image.sybblogs.fun/img-common/202401281716858.png" alt="统一编址" style="zoom:33%;" />

  如上图内存占据$0\sim N-1$，从$N$完后都是被$I/O$端口占用。因此地址译码器可以根据地址信号来确定当前要访问的是内存里的某个单元还是要访问$I/O$控制器中的某一个端口。

  这种编址方式靠不同的地址码区分内存和$I/O$设备。访存类的指令($LOAD,STORE$)都可以访问$I/O$端口。$RISC$精简指令集机器常用。

  如系统总线中地址线共$10$根，则可以访问的存储单元个数为$2^{10}=1024$个，假设给$10$个$I/O$端口编址：可以$0\sim9$表示$I/O$地址，$10\sim1023$为主存单元地址。也可以$0\sim1013$表示主存单元地址，$1014\sim1023$为$IO$地址。方式多种多样但是一旦确定$I/O$端口和主存单元的地址分布后就不可以随意更改。

  优点：不需要专门的输入$/$输出指令，所有访存指令都可直接访问端口，程序设计灵活性高。由于主存和$I/O$端口共享所以有较大的编址空间。读写控制逻辑电路简单。

  缺点：端口占用了主存地址空间，使主存地址空间变小。外设寻址时间长(地址位数多，地址译码速度慢)。

- ==独立编址==

  $I/O$接口和内存的编址是相互独立的。

  <img src="https://image.sybblogs.fun/img-common/202401281719583.png" alt="独立编址" style="zoom:33%;" />

  这种编址方式靠不同的指令区分内存和$I/O$设备。只能用专门的$I/O$指令访问$I/O$端口。Intel处理器常用，IN、OUT指令用来处理$I/O$设备。

  优点：使用专用$I/O$指令，程序编制清晰。$I/O$端口地址位数少，地址译码速度快。$I/O$端口的地址不占用主存地址空间。

  缺点：$I/O$指令类型少，一般只能对端口进行传送操作，程序设计灵活性差。并且需要CPU提供存储器读$/$写、$I/O$设备读$/$写两组控制信号，增加了控制逻辑电路的复杂性。

### 3.3 $I/O$接口的类型

按数据传送方式可分为：并行接口、串行接口。

- 并行接口：一个字节或一个字所有位同时传送。
- 串行接口：一位一位地传送。

注：这里所说的数据传送方式指的是外设和接口一侧的传送方式，而在主机和接口一侧，数据总是并行传送的。接口要完成数据格式转换。

按主机访问$I/O$设备的控制方式可分为：

- 程序查询接口
- 中断接口
- DMA接口

按功能选择的灵活性可分为：可编程接口、不可编程接口

## 4. $I/O$方式

之前介绍过<a href="#7-1.1-1">$I/O$控制方式</a>其控制方式三种：程序查询方式、程序中断方式和DMA方式。下面会详细讲述每一种方式的具体实现与执行原理。

### 4.1 程序查询方式

结合x86架构中的$I/O$指令演示执行过程。用到的x86$I/O$命令如下：

|  指令格式  |                 功能                 |
| :--------: | :----------------------------------: |
| IN Rd, Rs  | 把$I/O$端口Rs的数据输入到CPU寄存器Rd |
| OUT Rd, Rs | 把CPU寄存器Rs的数据输出到$I/O$端口Rd |

<img src="https://image.sybblogs.fun/img-common/202401291544333.png" alt="程序查询方式具体执行" style="zoom: 33%;" />

由上图可以模拟打印$3$个字符。假设这三个字符存放在主存中，需要先从主存里读出这三个字符。之后通过OUT指令CPU就会通过地址线指明此时要输出的端口是$R_{n+1}$再通过控制线指明此次是对这个$I/O$端口进行写操作，之后要写的命令字数据只需要通过数据传送即可。所以当前的OUT指令会保存再$I/O$控制器中，通过控制总线传送给外部设备，此时外部设备会反馈一个状态信息，这个状态信息会通过$I/O$控制器放到状态寄存器中。由采用程序查询方式，所以CPU会一直检查状态寄存器，而CPU检查状态是公告IN指令实现的。最后三个字符充分上述操作，打印完毕后CPU需要向控制寄存器发送停机命令，之后在驱动程序帮助下$I/O$控制器会将停机信号传给外部设备。

<img src="https://image.sybblogs.fun/img-common/202401291604924.png" alt="程序查询方式流程图" style="zoom:33%;" />

这种方式优点：接口设计简单、设备量少。
缺点：CPU在信息传送过程中要花费很多时间用于查询和等待，而且在一段时间内只能和一台外设交换信息，效率大大降低。

例题：在程序查询方式的输入$/$输出系统中，假设不考虑处理时间，每一个查询操作需要$100$个时钟周期，CPU的时钟频率为$50$MHz。现有鼠标和硬盘两个设备，而且CPU必须每秒对鼠标进行$30$次查询，硬盘以$32$位字长为单位传输数据，即每$32$位被CPU查询一次，传输率为$2\times2^{20}B/s$。求CPU对这两个设备查询所花费的时间比率，由此可得出什么结论？

- 从时间角度计算

  一个时钟周期为$1/50$MHz=$20$ns。所以一个查询操作耗时为$100\times 20ns=2000ns$。

  鼠标：每秒查询鼠标耗时$30\times2000ns=6000ns$，对查询鼠标所花费的时间比率$=60000ns/1s=0.006%$。所以对于鼠标的查询基本不影响CPU性能。

  硬盘：

  每$32$位需要查询一次，每秒传送给$2\times2^{20}B$，并且$32$位$=4B$，所以每秒需要查询$(2\times2^{20}B)/4B=2^{19}$次。

  最终查询硬盘耗时为$2^{19}\times2000ns=512\times1024\times2000ns\approx1.05\times10^9ns$。

  则查询硬盘所花费的时间比率$=(1.05\times10^9ns)/1s=105%$。

  所以对硬盘的查询即使CPU将全部时间都用于对硬盘的查询也不能满足磁盘的传输要求。

- 从频率的角度计算

  <img src="https://image.sybblogs.fun/img-common/202401291622923.png" alt="频率角度计算" style="zoom:33%;" />

根据上面例题可以知道这种程序查询方式也可以采用这种定时查询，在保证数据不丢失的情况下，每隔一段时间CPU就查询一次$I/O$状态。查询的间隔内CPU可以执行其他程序。

而之前所说的CPU会一直检查状态寄存器方式称为独占查询，这种独占查询就意味着CPU会花$100%$时间等待$I/O$的完成。

### 4.2 程序中断方式

程序中断是指在计算机执行现行程序的过程中，出现某些急需处理的异常情况或特殊请求，CPU暂时中止现行程序，而转去对这些异常情况或特殊请求进行处理，在处理完毕后CPU又自动返回到现行程序的断点处，继续执行原程序。

CPU响应处理中断基本流程是：

1. 中断请求

   中断源(鼠标、键盘等外设)向CPU发送中断请求信号。CPU在每个指令周期的末位都是例行检查是否有中断请求。

2. 中断响应

   响应中断的条件。如果检测到中断CPU会响应中断请求，首先会判断当前CPU自己的状态是否是可以响应中断的。如执行关中断指令后CPU就不会响应中断请求信号。

   中断判优：多个中断源同时提出请求时通过中断判优逻辑响应一个中断源。如果CPU当前可以相应中断，就需要中断判优，即同一时刻如果有多个外设发出中断信号，CPU会判断执行中断信号的顺序。

3. 中断处理

   中断隐指令。将CPU的执行流$PC$转移到正确的中断服务程序的位置。

   中断服务程序。修改PC值后就可以执行中断服务程序了。

#### 单中断

上面介绍一个关中断指令，CPU检测当前是否处于关中断指令方法是可以将是否处于关中断状态的信息存放在PSW寄存器中，其在PSW中关中断指令的标志位是$IF$，当$IF=1$表示开中断(允许处理中断信号)；当$IF=0$时表示关中断(不允许处理中断信号)。

所以如果当前指令的PSW中$IF=0$，则当前指令是原子操作，即一次性完成，不处理任何外部中断信号。在该指令完成后需要执行开中断指令。所以被关中断和开中断包裹的程序代码再执行过程中不会处理外部中断信号。但是也有一些优先级很高的中断信号必须被响应，即非屏蔽中断信号(如掉电)。而大多数中断信号都是可屏蔽中断信号。下面如果没有特殊说明中断信号默认为可屏蔽中断。

如果此时CPU处于开中断状态，当检测到一个中断请求信号时判断这个中断请求信号是哪个设备发出的方法是可以设置一个中断请求标记。

<img src="https://image.sybblogs.fun/img-common/202401291658829.png" alt="中断请求标记寄存器" style="zoom:33%;" />

这个中断请求标记寄存器是由一个一个触发器组成的。每个触发器记录一个二进制$0/1$，当某一个$I/O$设备所对应的触发器比特位是$1$时，就意味着此时有来自于这个$I/O$设备的中断请求需要处理。对于外部设备中断，CPU是在统一的时刻即每条指令执行阶段结束前向接口发出中断查询信号，以获取$I/O$的中断请求，也就是说，CPU响应中断的时间是在每条指令执行阶段的结束时刻(中断周期)。

CPU响应中断源必须满足三个条件：中断源有中断请求、CPU允许中断即开中断、一条指令执行完毕，且没有更紧迫的任务。

如果此时有多个外部设备发出中断信号，此时就需要中断判优操作。中断判优既可以用硬件实现，也可用软件实现：

- 硬件实现是通过硬件排队器实现的，它既可以设置在CPU中，也可以分散在各个中断源中

  <img src="https://image.sybblogs.fun/img-common/202401291707669.png" alt="中断判优" style="zoom:33%;" />

  上图假设有多个设备的触发器是$1$，可以用硬件排队器实现中断处理的优先级。

  <img src="https://image.sybblogs.fun/img-common/202401291708663.png" alt="硬件排队器" style="zoom:33%;" />

  上图最左边中断信号优先级最高，往右边越来越低。可以给多个中断信号进行优先级排序，优先级最高的会先执行。

- 软件实现是通过查询程序实现的。

  <img src="https://image.sybblogs.fun/img-common/202401291710227.png" alt="查询程序" style="zoom:33%;" />

  需要判断触发器中每一位是否为$1$，来选择。显然用软件方式判断需要写一系列的指令来判断，所以要比硬件实现速度上慢很多。所以现在计算机通常是用硬件排队器实现的。

上面讲了如何判断优先级，而关于优先级设置定义如下：

1. 硬件故障中断属于最高级(如掉电)，其次是软件中断(如用户程序发起系统调用)
2. 非屏蔽中断优于可屏蔽中断
3. DMA请求优于$I/O$设备传送的中断请求
4. 高速设备优于低速设备，因为高速设备中断请求响应越慢，越单独高速外设的执行效率。
5. 输入设备优于输出设备
6. 实时设备(反馈要及时的设备)优于普通设备。

上面对解决优先级问题后，还需要找到与中断信号相对应的中断服务程序去执行。也就是要找到中断服务程序的入口地址。即进入中断服务程序的方法是把该程序第一条指令的地址放入PC。之后处理完中断程序后，需要将PC的值恢复到执行之前指向的位置。所以在执行中断程序之前还需要保留PC的值。

保存PC值的工作可以交给中断隐指令。中断隐指令是保存原程序的PC值，并让PC指向中断服务程序的第一条指令。

中断隐指令具体任务：

1. 关中断。在中断服务程序中，为了保护中断现场(即CPU主要寄存器中的内容)期间不被新的中断所打断，必须关中断，从而保证被中断的程序在中断服务程序执行完毕之后能接着正确地执行下去。

2. 保存断点。为了保证在中断服务程序执行完毕后能正确地返回到原来的程序，必须将原来程序的断点(即程序计数器(PC)值的内容)保存起来。通常来说PC的值可以放到堆栈中，也可以存入指定的单元。

3. 引出中断服务程序。引出中断服务程序的实质就是取出中断服务程序的入口地址并传送给程序计数器(PC)。

   可以用两种方式确定中断程序入口地址：

   - 软件查询法

   - ==硬件向量法==

     首先可以给每个中断请求信号进行编号。

     <img src="https://image.sybblogs.fun/img-common/202401291742671.png" alt="硬件向量法" style="zoom:33%;" />

     如上图$12H$地址对应的主存单元内容包含了一个无条件转移指令JMP。这个JMP指令指明了当前中断请求所对应的中断服务程序入口地址。把指向中断入口起始地址，即JMP后面的值为中断向量。

     整体工作过程是先线通过硬件排队器实现中断判优，中断判优会导致只有一个中断信号所对应的输出线会输出$1$，之后引入中断向量地址形成部件，生成向量地址。

     <img src="https://image.sybblogs.fun/img-common/202401291821816.png" alt="中断向量地址形成部件" style="zoom:33%;" />

     上面向量地址还有一个别名叫中断类型号。用这种向量地址指向中断向量(入口地址)方式是因为，如果当某个入口地址发生改变只需要修改向量地址指向的中断向量值即可，不用修改硬件电路。

这里的中断隐指令其实并不是一条指令，指的是一系列的任务，而不是某一条指令。这些一系列的请求都是CPU检测到中断信号后一定会完成的指令。

现在找到中断程序入口地址后会执行中断程序。中断程序主要任务是：

1. 保存原来程序的运行环境

   保存通用寄存器和状态寄存器的内容(如：保存ACC寄存器的值)，以便返回原程序后可以恢复CPU环境。可使用堆栈，也可以使用特定存储单元。

2. 中断服务(设备服务)

   主体部分，如通过程序控制需打印的字符代码送入打印机的缓冲存储器中(如：中断服务的过程中有可能修改ACC寄存器的值)

3. 恢复环境

   通过出栈指令或取数指令把之前保存的信息送回寄存器中(如：把原程序算到一般的ACC值恢复原样)

4. 中断返回

   弹出栈顶保存的程序断点信息，使PC回到源程序断点处。

中断处理过程总结：

<img src="https://image.sybblogs.fun/img-common/202401291910013.png" alt="中断处理过程总结" style="zoom:33%;" />

上图关中断到开中断之间的指令不会被其他中断信号打断，知道最后执行开中断指令后才会响应中断请求信号。这种执行中断方式称为单重中断，即执行中断服务程序时不响应新的中断请求。

#### 多重中断

多重中断指的是当在执行某一个中断服务程序时，这个中断服务程序执行还有可能再次被中断。所以多重中断又称中断嵌套，执行中断服务程序时可响应新的中断请求。

实现多重中断当中断隐指令处理完保存断点和送中断向量一些列指令后，进入中断服务程序，此时在保护环境和屏蔽字后执行开中断，之后执行中断服务程序过程中就可以接受其他中断信号。最后再执行完中断服务程序后再次关中断恢复环境和屏蔽字。

<img src="https://image.sybblogs.fun/img-common/202401301339902.png" alt="单中断与多重中断" style="zoom:33%;" />

这里把开中断指令放在保护环境和屏蔽字后面是为了主程序在执行保护指令时不被其他外设中断信号打断造成保存失败情况。同理，恢复环境和屏蔽字原理类似。

上图屏蔽字的全程叫做中断屏蔽字。其作用是给CPU指明哪些中断信号应该先执行。本质上也是在解决请求信号优先级的问题。之前的硬件排队器作用是当收到多个中断请求时，只响应其中一个固定优先级。可以调整这个硬件排队器使，增加中断屏蔽功能，这样硬件排队器可以更加灵活地调节各种中断之间的优先级。

<img src="https://image.sybblogs.fun/img-common/202401301356211.png" alt="中断屏蔽技术" style="zoom:33%;" />

这种中断屏蔽技术主要用于多重中断，CPU要具备多重中断的功能，须满足下列条件：

1. 在中断服务程序中提前设置开中断指令。
2. 优先级别高的中断源有权中断优先级别低的中断源。

每个中断源都有一个屏蔽触发器，$1$表示屏蔽该中断源的请求，$0$表示可以正常申请，所有屏蔽触发器组合在一起，便构成一个屏蔽字寄存器，屏蔽字寄存器的内容称为屏蔽字。如上图的$\overline{MASK_1}$。

屏蔽字设置的规律：

1. 一般用$1$表示屏蔽(不处理该设备发送的中断信号)，$0$表示正常申请。
2. 每个中断源对应一个屏蔽字(在处理该中断源的中断服务程序时，屏蔽寄存器中的内容为该中断源对应的屏蔽字)。
3. 屏蔽字中$1$越多，优先级越高。每个屏蔽字中至少有一个$1$(至少要能屏蔽自身的中断)。

例题：设某机有$4$个中断源$A、B、C、D$，其硬件排队优先次序为$A>B>C>D$，现要求将中断处理次序改为$D>A>C>B$

(1)写出每个中断源对应的屏蔽字。

<img src="https://image.sybblogs.fun/img-common/202401301424073.png" alt="中断屏蔽字" style="zoom:33%;" />

由于$A$中断源只能被$D$中断，所以$D$屏蔽字$0$，以此类推中断源$A$的屏蔽字为$1110$，中断源$B$的屏蔽字为$0100$，中断源$C$的屏蔽字为$0110$，中断源$D$的屏蔽字为$1111$。

(2)按下图所示的时间轴给出的$4$个中断源的请求时刻，画出CPU执行程序的轨迹。设每个中断源的中断服务程序时间均为$20$us

<img src="https://image.sybblogs.fun/img-common/202401301426679.png" alt="中断程序" style="zoom:33%;" />

$B$在执行$5$ns后被$D$中断；之后运行$20$ns到$30$位置，此时$D$的中断程序已经执行完毕。之后再回到$B$运行$5$ns后又被$A$打断；$A$程序运行$20$ns后到$55$；之后再回到$B$运行$5$ns后被$C$打断；$C$执行$20$ns后回到$B$，直到$B$程序执行完毕。

<img src="https://image.sybblogs.fun/img-common/202401301431532.png" alt="中断程序2" style="zoom:33%;" />

#### 程序中断

<img src="https://image.sybblogs.fun/img-common/202401301452066.png" alt="程序中断方式深入探讨" style="zoom:33%;" />

当CPU在运行某个程序时，此程序需要用到用到外部设备输入。CPU会通过$I/O$指令向外部设备发送启动输入的命令，之后外部设备就可以准备CPU想要的数据和信息。在外部设备准备数据的过程总，CPU可以继续执行之前的程序。当$I/O$设备完成工作后会给CPU发送一个中断请求信号，假设之前CPU运行的指令地址是$K$，在$K$指令运行周期末尾检测到中断信号，接下来要对中断信号进行处理。当CPU处理完中断信号后要返回到$K+1$那条指令。当CPU取走外部设备第一个数据后，可以继续给外部设备发送$I/O$指令，之后重复上述操作。

<img src="https://image.sybblogs.fun/img-common/202401301501949.png" alt="程序中断方式深入探讨2" style="zoom:33%;" />

例题：假定CPU主频为$50$MHz，CPI(一个指令需要时钟周期数)为$4$。设备D采用异步串行通信方式向主机传送$7$位ASCII字符，通信规程中有$1$位奇校验位和$1$位停止位，从D接收启动命令到字符送入$I/O$端口需要$0.5$ms。请回答下列问题，要求说明理由。

设备D采用中断方式进行输入$/$输出，示意图如下：

<img src="https://image.sybblogs.fun/img-common/202401301503008.png" alt="程序中断方式例题" style="zoom:33%;" />

$I/O$端口每收到一个字符申请一次中断，中断响应需$10$个时钟周期，中断服务程序共有$20$条指令，其中第$15$条指令启动D工作。

1. 若CPU需从D读取$1000$个字符，则完成这一任务所需时间大约是多少个时钟周期？

   主频$50$MHz，时钟周期为$\frac{1}{50MHz}=20$ns

   $0.5$ms对应时钟周期数为$\frac{0.5ms}{20ns}=25000$

   传送$1$个字符需要的时钟周期数为$25000+10+15\times4=25070$

   传送$1000$个字符需要的时钟周期数为$25070\times1000=25070000$

2. CPU用于完成$1000$个字符这一任务的时间大约是多少个时钟周期？

   CPU用于该任务的时间大约为$1000\times(10+20\times4)=9\times10^4$个时钟周期

3. 在中断响应阶段CPU进行了哪些操作？

   中断指令：关中断、保存断点(PC)、引出中断服务程序

### 4.3 DMA控制方式

DMA控制器通常是以块为单位进行读写的设备，如磁盘。

<img src="https://image.sybblogs.fun/img-common/202401301547682.png" alt="DMA控制器" style="zoom:33%;" />

假设现在CPU要从磁盘中读入一整块的数据，采用DMA控制方式，CPU可以向DMA控制器指明要输入还是输出操作；要传送多少个数据；数据在主存、外设中的地址。接着由于数据的输入是要把磁盘一整块数据放入主存中，所以CPU需要给DMA控制器指明存放地址，此外CPU还要指明这些数据在磁盘中哪个位置。当CPU给DMA控制器发送完这些参数后，假设要输入的这一整块在磁盘中只占$5$个字。接着磁盘数据是一个字一个字发送给DMA控制器的，所以DMA控制器中要有一个数据缓冲寄存器，用来接受磁盘送来的一个字的数据。每收到一个字之后DMA控制器就可以根据里面保存的主存读写地址，把这整个字的数据内容通过系统总线传送给主存。

<img src="https://image.sybblogs.fun/img-common/202401301622131.png" alt="DMA控制器执行" style="zoom:33%;" />

接着对DMA控制器传送数据过程进行细化：

- DMA控制器接收外设发出的DMA请求(外设传送一个字的请求)，并向CPU发出总线请求。
- CPU响应此总线请求，发出总线响应信号，接管总线控制权，进入DMA操作周期。DMA操作周期就是将缓存器中一个字的内容通过系统总线写到主存中的过程。
- 确定传送数据的主存单元地址及长度，并能自动修改主存地址计数和传送长度计数。
- DMA控制器需要规定数据在主存和外设间的传送方向，发出读写等控制信号，执行数据传送操作。
- 最后等一整块数据传送完成后需要向CPU报告DMA操作结束。

在对DMA控制器内部结构进行细化：

<img src="https://image.sybblogs.fun/img-common/202401301637375.png" alt="DMA控制器细化" style="zoom:33%;" />

控制$/$状态逻辑：由控制和时序电路及状态标志组成，用于指定传送方向，修改传送参数，并对DMA请求信号和CPU响应信号进行协调和同步。

DMA请求触发器：每当$I/O$设备准备好数据后给出一个控制信号，使DMA请求触发器置位。具体工作原理是如果设备输入完一整个字的数据后，会通过总线将DMA请求触发器改为$1$，表示已经完成一个字的输入了。之后控制$/$状态逻辑会受到一个高电平信号，于是控制电路就可以接着把数据缓冲寄存器中的数据放入主存中。

主存地址计数器：简称AR，存放要交换数据的主存地址。

传送长度寄存器：简称WC，用来记录传送数据的长度，计数溢出时，数据即传送完毕，自动发中断请求信号。

数据缓冲寄存器：用于暂存每次传送的数据。

中断机构：当一个数据块传送完毕后触发中断机构，向CPU提出中断请求。DMA控制器完成一整块的数据传输之后，需要给CPU一个反馈，因此需要有一个中断机构发出中断请求信号。中断机构右侧连接了传送长度计数器，当传送长度计数器溢出后会给中断机构发送溢出信号。

注：在DMA传送过程中，DMA控制器将接管CPU的地址总线、数据总线和控制总线，CPU的主存控制信号被禁止使用。而当DMA传送结束后，将恢复CPU的一切权利并开始执行其操作。

==DMA传送过程==：

- 首先预处理阶段CPU会向DMA控制器指明接下来要读写的数据存放在主存当中的位置，主存地址寄存器指针是$AR$。还有一个寄存器用于指明设备的读写地址，这个寄存器英文缩写是DAR。除此之外还要指明要传送多少个数据，这个寄存器缩写叫WC。

  <img src="https://image.sybblogs.fun/img-common/202401301653093.png" alt="DMA传送过程" style="zoom:33%;" />

- 接着进入由DMA控制器控制数据传送过程。此时对于CPU来说可以接着执行之前的程序。此时如果通过设备输入一个数据，设备首先要把数据送到数据缓冲寄存器中，同时向DMA控制器发送一个高电平信号。当控制$/$状态逻辑检测到DMA请求之后，就会向CPU申请总线控制器权，之后CPU会反馈一个信号给DMA控制器。之后DMA控制器获得系统总线控制权，之后DMA控制器给主存发送一个写命令，同时把数据换种寄存器里的数据打到数据线上，之后再把主存的地址信息再打到地址线上，这样就完成了一个字的数据传输。这个传输完成后需要让主存的地址后移$+1$，同时也需要修改长度计数器的值。当传送完多个字后，传送长度计数器的值会溢出，溢出信号会传送给中断机构，中断机构检测到信号后，会向CPU发送中断请求，之后CPU再对DMA中断信号进行处理，这意味着一整块的数据传输已经完成。
- 数据传送完成后，CPU受到中断请求就会进行后处理，也就是运行相应的中断程序，做DMA结束处理。最后CPU会回到主程序继续执行主程序。

相比于之前的程序中断方式来说，程序中断方式每一个字的传送都需要CPU进行处理。但是DMA控制方式意味着，会由DMA控制着传送完一整块的数据之后再通过CPU进行处理。DMA传送过程流程图如下：

<img src="https://image.sybblogs.fun/img-common/202401301725858.png" alt="DMA传送过程流程图" style="zoom:33%;" />

上面讲述的方式DMA控制器需要经过CPU发送的信号来确定能不能使用系统总线，所以不会发生主存同时访问的问题。但是采用三总线结构：

<img src="https://image.sybblogs.fun/img-common/202401301728185.png" alt="三总线连接方式" style="zoom:33%;" />

可以看到主存和DMA控制器之间会专门用一个DMA总线进行交互，CPU和主存之间会专门用一根主存总线进行交互。在这种情况下DMA总线想要访问主存，就不需要通过CPU决定。所以这种三总线方式会出现CPU和DMA控制器同时访问主存的问题。如果这个主存不是双端口的主存，同一时刻只能支持一个访问请求，此时就产生访问问题。可以用以下三种方案解决==CPU与DMA访存冲突问题：==

- 停止CPU访问主存

  DMA控制器传送一整块数据的过程，CPU不能使用主存。

  这种方式控制简单，但CPU会处于不工作状态或保持状态未充分发挥CPU对主存的利用率。

  <img src="https://image.sybblogs.fun/img-common/202401301733843.png" alt="停止CPU访问主存方式" style="zoom:33%;" />

- 采用DMA和CPU交替访存

  <img src="https://image.sybblogs.fun/img-common/202401301734376.png" alt="CPU与DMA交替访存方式" style="zoom:33%;" />

  主存的工作时间会被分为两段，红色段是$C_1$，黑色段是$C_2$。$C_1$那一段永远都是给DMA控制器使用，$C_2$那一段永远都是给CPU使用。采用这种交替访问主存方式就不需要总线使用权的申请，建立和归还过程。但是这种实现方式硬件逻辑实现更为复杂，另外对于主存利用率也不太好，有可能某一周期CPU需要很频繁访问主存，但DMA不需要。

- 周期挪用(周期窃取)

  <img src="https://image.sybblogs.fun/img-common/202401301741256.png" alt="周期窃取" style="zoom:33%;" />

  DMA访问主存有可能会出现下面三种情况：

  1. CPU此时不妨问主存，所以不冲突
  2. CPU正在访存，则需要等到CPU这个存取周期结束后再去访问主存
  3. CPU与DMA同时访存，优先让DMA控制器进行访存。因为DMA中的数据缓存寄存器可能会被后来外设输入的新数据覆盖，所以要尽快放到主存中。

主存和DMA接口之间有一条直接数据通路。由于DMA方式传送数据不需要经过CPU，因此不必中断现行程序，$I/O$与主机并行工作，程序和传送并行工作。

DMA方式具有下列特点：

1. 它使主存与CPU的固定联系脱钩，主存既可被CPU访问，又可被外设访问。
2. 在数据块传送时，主存地址的确定、传送数据的计数等都由硬件电路直接实现。
3. 主存中要开辟专用缓冲区，及时供给和接收外设的数据。
4. DMA传送速度快，CPU和外设并行工作，提高了系统效率。
5. DMA在传送开始前要通过程序进行预处理，结束后要通过中断方式进行后处理。

DMA控制器方式与中断方式对比

|          |                             中断                             |                          DMA                          |
| :------: | :----------------------------------------------------------: | :---------------------------------------------------: |
| 数据传送 | 需要通过程序控制完成数据传输<br>每次中断都会涉及到程序切换并且需要保存恢复环境 | 由硬件控制数据传输的过程<br>CPU只需进行预处理和后处理 |
| 中断请求 |                           传送数据                           |                        后处理                         |
|   响应   |                  指令执行周期结束后响应中断                  |    每个机器周期结束均可，总线空闲时即可响应DMA请求    |
|   场景   |                      CPU控制，低速设备                       |            DMA控制器控制，高速设备和块设备            |
|  优先级  |                        优先级低于DMA                         |                    优先级高于中断                     |
| 异常处理 |                        能处理异常事件                        |                      仅传送数据                       |

